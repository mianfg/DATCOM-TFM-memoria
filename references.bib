
@article{wiegrebe_deep_2024,
	title = {Deep learning for survival analysis: a review},
	volume = {57},
	issn = {1573-7462},
	shorttitle = {Deep learning for survival analysis},
	url = {https://link.springer.com/10.1007/s10462-023-10681-3},
	doi = {10.1007/s10462-023-10681-3},
	abstract = {Abstract
            
              The influx of deep learning (DL) techniques into the field of survival analysis in recent years has led to substantial methodological progress; for instance, learning from unstructured or high-dimensional data such as images, text or omics data. In this work, we conduct a comprehensive systematic review of DL-based methods for time-to-event analysis, characterizing them according to both survival- and DL-related attributes. In summary, the reviewed methods often address only a small subset of tasks relevant to time-to-event data—e.g., single-risk right-censored data—and neglect to incorporate more complex settings. Our findings are summarized in an editable, open-source, interactive table:
              https://survival-org.github.io/DL4Survival
              . As this research area is advancing rapidly, we encourage community contribution in order to keep this database up to date.},
	language = {en},
	number = {3},
	urldate = {2025-06-11},
	journal = {Artificial Intelligence Review},
	author = {Wiegrebe, Simon and Kopper, Philipp and Sonabend, Raphael and Bischl, Bernd and Bender, Andreas},
	month = feb,
	year = {2024},
	pages = {65},
}

@article{zhang_multiobjective_2017,
	title = {Multiobjective {Deep} {Belief} {Networks} {Ensemble} for {Remaining} {Useful} {Life} {Estimation} in {Prognostics}},
	volume = {28},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2162-237X, 2162-2388},
	url = {http://ieeexplore.ieee.org/document/7508982/},
	doi = {10.1109/TNNLS.2016.2582798},
	number = {10},
	urldate = {2025-06-11},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Zhang, Chong and Lim, Pin and Qin, A. K. and Tan, Kay Chen},
	month = oct,
	year = {2017},
	pages = {2306--2318},
}

@inproceedings{zhai_remaining_2022,
	address = {Harbin, China},
	title = {Remaining {Useful} {Life} {Prediction} of {Aero}-{Engine} {Based} on {Transformer} with {Tendency} {Retainment}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9781665492812},
	url = {https://ieeexplore.ieee.org/document/10058242/},
	doi = {10.1109/ICSMD57530.2022.10058242},
	urldate = {2025-06-11},
	publisher = {IEEE},
	author = {Zhai, Zhi and Wen, Jingcheng and Wang, Fujin and Zhao, Zhibin and Guo, Yanjie and Chen, Xuefeng},
	month = nov,
	year = {2022},
	pages = {1--6},
}

@misc{kinney_mean_2025,
	title = {Mean {Force} {Emission} {Theory} for {Classical} {Bremsstrahlung} in {Electron}-{Ion} {Plasmas}},
	url = {http://arxiv.org/abs/2506.06177},
	doi = {10.48550/arXiv.2506.06177},
	abstract = {This work extends the previously developed mean force emission theory to describe electron-ion plasmas. Results are compared to molecular dynamics simulations. The main extensions are to account for the attractive nature of electron-ion interactions and to model short-range quantum effects using the Kelbg potential. By reducing the electron-ion force inside the deBroglie wavelength, the Kelbg potential causes a decay at high frequencies and a decrease in magnitude of the low frequency bremsstrahlung spectrum. The attractive electron-ion interaction also allows for classically bound states that show up as peaks in the emission spectrum. Results show that the Kelbg potential can capture quantum modifications to classical Gaunt factors, but is limited in describing emission at very high frequencies. This work further supports the notion that there is a peak in emission near the plasma frequency at strong coupling that cannot be captured using the common Drude correction. Importantly, the linear response framework used to calculate the bremsstrahlung emission coefficient is related to both the absorption coefficient and the real part of the dynamic electrical conductivity. This means that the conclusions drawn from this study can be applied to these transport coefficients as well. Finally, this work compares the results with commonly used classical and quantum mechanical Gaunt factors, and discusses the impact of a Fermi-Dirac distribution of electrons on emission and why screening slightly reduces the bremsstrahlung power in weakly coupled and non-degenerate plasmas.},
	urldate = {2025-06-09},
	publisher = {arXiv},
	author = {Kinney, Julian P. and LeFevre, Heath J. and Kuranz, Carolyn C. and Baalrud, Scott D.},
	month = jun,
	year = {2025},
	note = {arXiv:2506.06177 [physics]},
	keywords = {Physics - Plasma Physics},
}

@misc{zhang_large_2024,
	title = {Large {Language} {Models} for {Time} {Series}: {A} {Survey}},
	shorttitle = {Large {Language} {Models} for {Time} {Series}},
	url = {http://arxiv.org/abs/2402.01801},
	doi = {10.48550/arXiv.2402.01801},
	abstract = {Large Language Models (LLMs) have seen significant use in domains such as natural language processing and computer vision. Going beyond text, image and graphics, LLMs present a significant potential for analysis of time series data, benefiting domains such as climate, IoT, healthcare, traffic, audio and finance. This survey paper provides an in-depth exploration and a detailed taxonomy of the various methodologies employed to harness the power of LLMs for time series analysis. We address the inherent challenge of bridging the gap between LLMs' original text data training and the numerical nature of time series data, and explore strategies for transferring and distilling knowledge from LLMs to numerical time series analysis. We detail various methodologies, including (1) direct prompting of LLMs, (2) time series quantization, (3) aligning techniques, (4) utilization of the vision modality as a bridging mechanism, and (5) the combination of LLMs with tools. Additionally, this survey offers a comprehensive overview of the existing multimodal time series and text datasets and delves into the challenges and future opportunities of this emerging field. We maintain an up-to-date Github repository which includes all the papers and datasets discussed in the survey.},
	urldate = {2025-06-09},
	publisher = {arXiv},
	author = {Zhang, Xiyuan and Chowdhury, Ranak Roy and Gupta, Rajesh K. and Shang, Jingbo},
	month = may,
	year = {2024},
	note = {arXiv:2402.01801 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{pan_selector_2024,
	title = {{SELECTOR}: {Heterogeneous} graph network with convolutional masked autoencoder for multimodal robust prediction of cancer survival},
	shorttitle = {{SELECTOR}},
	url = {http://arxiv.org/abs/2403.09290},
	doi = {10.48550/arXiv.2403.09290},
	abstract = {Accurately predicting the survival rate of cancer patients is crucial for aiding clinicians in planning appropriate treatment, reducing cancer-related medical expenses, and significantly enhancing patients' quality of life. Multimodal prediction of cancer patient survival offers a more comprehensive and precise approach. However, existing methods still grapple with challenges related to missing multimodal data and information interaction within modalities. This paper introduces SELECTOR, a heterogeneous graph-aware network based on convolutional mask encoders for robust multimodal prediction of cancer patient survival. SELECTOR comprises feature edge reconstruction, convolutional mask encoder, feature cross-fusion, and multimodal survival prediction modules. Initially, we construct a multimodal heterogeneous graph and employ the meta-path method for feature edge reconstruction, ensuring comprehensive incorporation of feature information from graph edges and effective embedding of nodes. To mitigate the impact of missing features within the modality on prediction accuracy, we devised a convolutional masked autoencoder (CMAE) to process the heterogeneous graph post-feature reconstruction. Subsequently, the feature cross-fusion module facilitates communication between modalities, ensuring that output features encompass all features of the modality and relevant information from other modalities. Extensive experiments and analysis on six cancer datasets from TCGA demonstrate that our method significantly outperforms state-of-the-art methods in both modality-missing and intra-modality information-confirmed cases. Our codes are made available at https://github.com/panliangrui/Selector.},
	urldate = {2025-06-09},
	publisher = {arXiv},
	author = {Pan, Liangrui and Peng, Yijun and Li, Yan and Wang, Xiang and Liu, Wenjuan and Xu, Liwen and Liang, Qingchun and Peng, Shaoliang},
	month = mar,
	year = {2024},
	note = {arXiv:2403.09290 [cs]
version: 1},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}

@misc{ho_graph_2025,
	title = {Graph {Anomaly} {Detection} in {Time} {Series}: {A} {Survey}},
	shorttitle = {Graph {Anomaly} {Detection} in {Time} {Series}},
	url = {http://arxiv.org/abs/2302.00058},
	doi = {10.48550/arXiv.2302.00058},
	abstract = {With the recent advances in technology, a wide range of systems continue to collect a large amount of data over time and thus generate time series. Time-Series Anomaly Detection (TSAD) is an important task in various time-series applications such as e-commerce, cybersecurity, vehicle maintenance, and healthcare monitoring. However, this task is very challenging as it requires considering both the intra-variable dependency (relationships within a variable over time) and the inter-variable dependency (relationships between multiple variables) existing in time-series data. Recent graph-based approaches have made impressive progress in tackling the challenges of this field. In this survey, we conduct a comprehensive and up-to-date review of TSAD using graphs, referred to as G-TSAD. First, we explore the significant potential of graph representation for time-series data and and its contributions to facilitating anomaly detection. Then, we review state-of-the-art graph anomaly detection techniques, mostly leveraging deep learning architectures, in the context of time series. For each method, we discuss its strengths, limitations, and the specific applications where it excels. Finally, we address both the technical and application challenges currently facing the field, and suggest potential future directions for advancing research and improving practical outcomes.},
	urldate = {2025-06-09},
	publisher = {arXiv},
	author = {Ho, Thi Kieu Khanh and Karami, Ali and Armanfard, Narges},
	month = apr,
	year = {2025},
	note = {arXiv:2302.00058 [cs]
version: 6},
	keywords = {Computer Science - Machine Learning},
}

@article{gogoshin_graph_2023,
	title = {Graph {Neural} {Networks} in {Cancer} and {Oncology} {Research}: {Emerging} and {Future} {Trends}},
	volume = {15},
	issn = {2072-6694},
	shorttitle = {Graph {Neural} {Networks} in {Cancer} and {Oncology} {Research}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10742144/},
	doi = {10.3390/cancers15245858},
	abstract = {Simple Summary
Graph Neural Networks are emerging as a powerful tool for structured data analysis, and predictive modeling in massive multimodal datasets. In this review, we survey recent applications of graph neural networks in the setting of cancer and oncology research. We identify currently predominant research areas, and compare graph neural networks with non-graph deep learning methods as well as probabilistic graphical models. We conclude by highlighting emerging trends and pressing challenges, such as developing independent and comprehensive benchmarking frameworks. This review is aimed at cancer and oncology researchers, clinicians and physician-scientists who are interested in applying graph-centered secondary data analysis methods to structured multimodal data.

Abstract
Next-generation cancer and oncology research needs to take full advantage of the multimodal structured, or graph, information, with the graph data types ranging from molecular structures to spatially resolved imaging and digital pathology, biological networks, and knowledge graphs. Graph Neural Networks (GNNs) efficiently combine the graph structure representations with the high predictive performance of deep learning, especially on large multimodal datasets. In this review article, we survey the landscape of recent (2020–present) GNN applications in the context of cancer and oncology research, and delineate six currently predominant research areas. We then identify the most promising directions for future research. We compare GNNs with graphical models and “non-structured” deep learning, and devise guidelines for cancer and oncology researchers or physician-scientists, asking the question of whether they should adopt the GNN methodology in their research pipelines.},
	number = {24},
	urldate = {2025-06-09},
	journal = {Cancers},
	author = {Gogoshin, Grigoriy and Rodin, Andrei S.},
	month = dec,
	year = {2023},
	pmid = {38136405},
	pmcid = {PMC10742144},
	pages = {5858},
}

@misc{noauthor_human_nodate,
	title = {Human in the {Loop}?},
	url = {https://www.hiig.de/en/project/human-in-the-loop/},
	abstract = {The Human in the Loop? (HiLo) project investigates the active involvement of humans in automated decision-making processes.},
	language = {en-US},
	urldate = {2025-06-09},
	journal = {HIIG},
}

@misc{noauthor_human---loop_nodate,
	title = {Human-in-the-{Loop} {Manufacturing}},
	url = {https://www.tencom.com/blog/human-in-the-loop-manufacturing},
	abstract = {This article delves into the dynamics of Human-in-the-loop manufacturing, exploring its definition, control architecture, best practices, and more.},
	language = {en},
	urldate = {2025-06-09},
}

@mastersthesis{laag_risk-averse_2024,
	title = {Risk-{Averse} {Predictive} {Maintenance} {Scheduling} with {Distributional} {Reinforcement} {Learning} using {Data}-{Driven} {Probabilistic} {Prognostics}},
	copyright = {CC-BY-NC-ND},
	url = {https://studenttheses.uu.nl/handle/20.500.12932/48223},
	abstract = {Maintenance scheduling for complex industrial systems, such as turbo jet engines, is critical for ensuring operational efficiency and safety. While data-driven prognostics have shown potential for improving predictive maintenance planning, existing approaches often fail to explicitly account for the safety-critical nature of these systems, typically addressing it through assigning high costs to failures. This thesis proposes a novel risk-averse approach to integrating data-driven probabilistic prognostics into predictive maintenance scheduling.
The proposed methodology is applied to NASA's turbofan engine C-MAPSS data set. A threshold-weighted scoring rule is employed as the loss function in a neural network model to induce aversion to downside-risk when estimating the distribution of the remaining useful life (RUL). Building on these estimates, a Distributional Reinforcement Learning (DRL) model is developed for predictive maintenance scheduling. Here, risk-aversion is introduced by optimizing the agent’s decision-making based on the Conditional Value at Risk (CVaR) of the return distribution, rather than the mean.
Results show that the forecasting model incorporating the threshold-weighted scoring rule demonstrates a tendency to underestimate RUL, effectively inducing the desired risk-averse behavior with only minor losses in overall performance. The risk-averse maintenance scheduling models exhibited a noticeable, though slightly inconsistent, trend towards preventing engine failures more effectively, with marginally higher average RUL at scheduled replacements compared to their risk-neutral counterparts. The scheduling agents learned to optimize the use of two out of three maintenance actions to balance failure prevention and operational efficiency.
This study demonstrates the feasibility of incorporating downside-risk aversion in both RUL estimation and maintenance scheduling, offering a more robust framework for enhancing safety and performance in predictive maintenance strategies.},
	language = {EN},
	urldate = {2025-06-09},
	author = {Laag, Robin van der},
	year = {2024},
	note = {Accepted: 2024-12-12T00:01:21Z},
}

@article{siraskar_reinforcement_2023,
	title = {Reinforcement learning for predictive maintenance: a systematic technical review},
	volume = {56},
	issn = {1573-7462},
	shorttitle = {Reinforcement learning for predictive maintenance},
	url = {https://doi.org/10.1007/s10462-023-10468-6},
	doi = {10.1007/s10462-023-10468-6},
	abstract = {The manufacturing world is subject to ever-increasing cost optimization pressures. Maintenance adds to cost and disrupts production; optimized maintenance is therefore of utmost interest. As an autonomous learning mechanism reinforcement learning (RL) is increasingly used to solve complex tasks. While designing an optimal, model-free RL solution for predictive maintenance (PdM) is an attractive proposition, there are several key steps and design elements to be considered—from modeling degradation of the physical equipment to creating RL formulations. In this article, we survey how researchers have applied RL to optimally predict maintenance in diverse forms—from early diagnosis to computing a “health index” to directly suggesting a maintenance action. Contributions of this article include developing a taxonomy for PdM techniques in general and one specifically for RL applied to PdM. We discovered and studied unique techniques and applications by applying \$\$tf-idf\$\$(a text mining technique). Furthermore, we systematically studied how researchers have mathematically formulated RL concepts and included some detailed case-studies that help demonstrate the complete flow of applying RL to PdM. Finally, in Sect. 14, we summarize the insights for researchers, and for the industrial practitioner we lay out a simple approach for implementing RL for PdM.},
	language = {en},
	number = {11},
	urldate = {2025-06-09},
	journal = {Artificial Intelligence Review},
	author = {Siraskar, Rajesh and Kumar, Satish and Patil, Shruti and Bongale, Arunkumar and Kotecha, Ketan},
	month = nov,
	year = {2023},
	keywords = {Case-studies, Learning Theory, Learning algorithms, Machine Learning, Mathematical treatment, Practitioner, Predictive maintenance, Predictive medicine, Reinforcement learning, Statistical Learning, Stochastic Learning and Adaptive Control, Taxonomy},
	pages = {12885--12947},
}

@misc{wette_oml-ad_2024,
	title = {{OML}-{AD}: {Online} {Machine} {Learning} for {Anomaly} {Detection} in {Time} {Series} {Data}},
	shorttitle = {{OML}-{AD}},
	url = {http://arxiv.org/abs/2409.09742},
	doi = {10.48550/arXiv.2409.09742},
	abstract = {Time series are ubiquitous and occur naturally in a variety of applications -- from data recorded by sensors in manufacturing processes, over financial data streams to climate data. Different tasks arise, such as regression, classification or segmentation of the time series. However, to reliably solve these challenges, it is important to filter out abnormal observations that deviate from the usual behavior of the time series. While many anomaly detection methods exist for independent data and stationary time series, these methods are not applicable to non-stationary time series. To allow for non-stationarity in the data, while simultaneously detecting anomalies, we propose OML-AD, a novel approach for anomaly detection (AD) based on online machine learning (OML). We provide an implementation of OML-AD within the Python library River and show that it outperforms state-of-the-art baseline methods in terms of accuracy and computational efficiency.},
	urldate = {2025-06-09},
	publisher = {arXiv},
	author = {Wette, Sebastian and Heinrichs, Florian},
	month = sep,
	year = {2024},
	note = {arXiv:2409.09742 [cs]
version: 1},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@misc{golchin_anomaly_2025,
	title = {Anomaly {Detection} in {Time} {Series} {Data} {Using} {Reinforcement} {Learning}, {Variational} {Autoencoder}, and {Active} {Learning}},
	url = {http://arxiv.org/abs/2504.02999},
	doi = {10.48550/arXiv.2504.02999},
	abstract = {A novel approach to detecting anomalies in time series data is presented in this paper. This approach is pivotal in domains such as data centers, sensor networks, and finance. Traditional methods often struggle with manual parameter tuning and cannot adapt to new anomaly types. Our method overcomes these limitations by integrating Deep Reinforcement Learning (DRL) with a Variational Autoencoder (VAE) and Active Learning. By incorporating a Long Short-Term Memory (LSTM) network, our approach models sequential data and its dependencies effectively, allowing for the detection of new anomaly classes with minimal labeled data. Our innovative DRL- VAE and Active Learning combination significantly improves existing methods, as shown by our evaluations on real-world datasets, enhancing anomaly detection techniques and advancing time series analysis.},
	urldate = {2025-06-09},
	publisher = {arXiv},
	author = {Golchin, Bahareh and Rekabdar, Banafsheh},
	month = apr,
	year = {2025},
	note = {arXiv:2504.02999 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{palma_large_2025,
	title = {Large {Language} {Models} for {Predictive} {Maintenance} in the {Leather} {Tanning} {Industry}: {Multimodal} {Anomaly} {Detection} in {Compressors}},
	volume = {14},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2079-9292},
	shorttitle = {Large {Language} {Models} for {Predictive} {Maintenance} in the {Leather} {Tanning} {Industry}},
	url = {https://www.mdpi.com/2079-9292/14/10/2061},
	doi = {10.3390/electronics14102061},
	abstract = {Predictive maintenance in industrial settings increasingly demands systems capable of integrating heterogeneous data streams while balancing computational efficiency and contextual reasoning. This paper introduces a novel framework leveraging Large Language Models (LLMs) to address these challenges in compressor monitoring, demonstrating their potential to enhance anomaly detection accuracy and operational cost-effectiveness. We evaluate Qwen 2.5-32B against traditional machine learning models (ANN, CNN, LSTM), achieving superior recall (92.3\%) and AUC-ROC (0.991) through transformer-based architectures optimized for multimodal data fusion. A financial case study reveals operational cost reductions of 18\% via reduced downtime and optimized maintenance schedules, while a real-time monitoring dashboard validates scalability for industrial deployment. Our findings highlight the transformative role of LLMs in bridging technical innovation with domain-specific operational constraints, offering a blueprint for predictive maintenance in niche industries.},
	language = {en},
	number = {10},
	urldate = {2025-06-09},
	journal = {Electronics},
	author = {Palma, Giulia and Cecchi, Gaia and Rizzo, Antonio},
	month = jan,
	year = {2025},
	note = {Number: 10
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {Large Language Models, anomaly detection, industrial compressors, machine learning, multimodal data fusion, predictive maintenance, real-time monitoring},
	pages = {2061},
}

@misc{xiyuanzh_xiyuanzhawesome-llm-time-series_2025,
	title = {xiyuanzh/awesome-llm-time-series},
	url = {https://github.com/xiyuanzh/awesome-llm-time-series},
	abstract = {tracking papers, datasets, and models of "large language model (LLM) for time series"},
	urldate = {2025-06-09},
	author = {xiyuanzh},
	month = jun,
	year = {2025},
	note = {original-date: 2024-02-01T08:40:30Z},
}

@misc{noauthor_algomox_nodate,
	title = {Algomox {Blog} {\textbar} {From} {Reactive} to {Proactive} {Operations}: {The} {Role} of {LLM} in {Predictive} {Maintenance}},
	url = {https://www.algomox.com/resources/blog/reactive_proactive_operations_llm_predictive_maintenance/},
	urldate = {2025-06-09},
}

@article{datt_explainable_nodate,
	title = {Explainable {AI} for {Predictive} {Maintenance} {Applications}},
	volume = {11},
	abstract = {In the ever-evolving industrial landscape, companies must continuously adapt and improve to stay ahead of the curve. Predictive maintenance (PdM) has emerged as a critical strategy to minimize downtime and boost manufacturing efficiency. This paper investigates the performance of various machine learning models using a synthetic dataset: Support Vector Machine (SVM), Random Forest (RF), Gradient Boosting, eXtreme Gradient Boosting (XGBoost), and Multi-Layer Perceptron (MLP). A Voting Classifier ensemble is employed to generate predictions. The article compares the performance of these models based on metrics such as accuracy, precision, recall, F1 score, and Matthews correlation coefficient (MCC). As machine learning models become more intricate, explainable AI (XAI) plays a crucial role in comprehending their predictions and decision-making processes. This paper utilizes eXAI techniques like Partial Dependence Plot (PDP), Local Interpretable Model-agnostic Explanations (LIME), and SHapley Additive exPlanations (SHAP) to shed light on the predicted behavior.},
	language = {en},
	number = {12},
	author = {Datt, Chinmaya and Madan, A K},
}

@misc{noauthor_support_nodate,
	title = {Support vector machine for dynamic survival prediction with time-dependent covariates},
	note = {Context Object: url\_ver=Z39.88-2004\&ctx\_ver=Z39.88-2004\&rft\_val\_fmt=info\%3Aofi\%2Ffmt\%3Akev\%3Amtx\%3Adc\&rfr\_id=info\%3Asid\%2Fblacklight.rubyforge.org\%3Agenerator\&rft.title=Support+vector+machine+for+dynamic+survival+prediction+with+time-dependent+covariates\&rft.publisher=Institute+of+Mathematical+Statistics\&rft.format=Article\&rft.identifier=Dimensions+ID\%3A+pub.1174558657\&rft.identifier=DOI\%3A+https\%3A\%2F\%2Fdx.doi.org\%2F10.1214\%2F24-aoas1875\&rft.relation=covariates\&rft.relation=machine\&rft.relation=prediction\&rft.relation=time-dependent+covariates\&rft.relation=support\&rft.relation=survival+prediction\&rft.relation=support+vector+machine\&rft.relation=vector+machine
Publisher: Institute of Mathematical Statistics},
}

@article{rizopoulos_dynamic_2017,
	title = {Dynamic predictions with time-dependent covariates in survival analysis using joint modeling and landmarking},
	volume = {59},
	copyright = {© 2017 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
	issn = {1521-4036},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201600238},
	doi = {10.1002/bimj.201600238},
	abstract = {A key question in clinical practice is accurate prediction of patient prognosis. To this end, nowadays, physicians have at their disposal a variety of tests and biomarkers to aid them in optimizing medical care. These tests are often performed on a regular basis in order to closely follow the progression of the disease. In this setting, it is of interest to optimally utilize the recorded information and provide medically relevant summary measures, such as survival probabilities, which will aid in decision making. In this work, we present and compare two statistical techniques that provide dynamically updated estimates of survival probabilities, namely landmark analysis and joint models for longitudinal and time-to-event data. Special attention is given to the functional form linking the longitudinal and event time processes, and to measures of discrimination and calibration in the context of dynamic prediction.},
	language = {en},
	number = {6},
	urldate = {2025-06-09},
	journal = {Biometrical Journal},
	author = {Rizopoulos, Dimitris and Molenberghs, Geert and Lesaffre, Emmanuel M.E.H.},
	year = {2017},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.201600238},
	keywords = {Calibration, Discrimination, Prognostic modeling, Random effects, Risk prediction},
	pages = {1261--1276},
}

@inproceedings{khan_predictive_2025,
	title = {Predictive {Maintenance} in {Chemical} {Industries} {Using} {Machine} {Learning}: {A} {Novel} {Approach}},
	shorttitle = {Predictive {Maintenance} in {Chemical} {Industries} {Using} {Machine} {Learning}},
	url = {https://ieeexplore.ieee.org/document/11013163},
	doi = {10.1109/ECCE64574.2025.11013163},
	abstract = {This study details the creation and execution of an economical, real-time safety monitoring system for industrial chemical processes, employing sensor data and machine learning algorithms to forecast dangerous situations, including gas leaks and temperature variations. The system amalgamates diverse sensors with IoT connections, facilitating real-time data acquisition and processing. Machine learning algorithms, such as linear regression, multiple regression, and k-nearest neighbors (KNN), were utilized to forecast system efficiency and identify potential hazards. The system reliably predicts hazardous conditions, with linear regression demonstrating the highest accuracy in gas burner stability. Its cost-effective design makes it suitable for industrial use The system’s efficiency, particularly in delivering early alerts and enabling proactive measures, provides a sense of security. Future efforts will optimize the system to improve resilience in dynamic industrial settings. The proposed approach enhances safety protocols in the chemical industry.},
	urldate = {2025-06-09},
	booktitle = {2025 {International} {Conference} on {Electrical}, {Computer} and {Communication} {Engineering} ({ECCE})},
	author = {Khan, Mohaimen Islam and Raihan Uddin Turzo, Md and Hossain, Md Mujahid and Ismail Hossen, Md. and {Ahmad}},
	month = feb,
	year = {2025},
	keywords = {Accuracy, Chemical Safety, Chemical industry, Diseases, Hazard Prediction, Hazards, Industrial IoT, Machine Learning, Machine learning, Machine learning algorithms, Nearest neighbor methods, Predictive Maintenance, Predictive maintenance, Predictive models, Real-time systems},
	pages = {1--5},
}

@article{wang_deep-learning_2025,
	title = {A {Deep}-{Learning} {Method} for {Remaining} {Useful} {Life} {Prediction} of {Power} {Machinery} via {Dual}-{Attention} {Mechanism}},
	volume = {25},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/25/2/497},
	doi = {10.3390/s25020497},
	abstract = {Remaining useful life (RUL) prediction is a cornerstone of Prognostic and Health Management (PHM) for power machinery, playing a crucial role in ensuring the reliability and safety of these critical systems. In recent years, deep learning techniques have shown great promise in RUL prediction, providing more reliable and accurate outcomes. However, existing models often struggle with comprehensive feature extraction, especially in capturing the complex behavior of power machinery, where non-linear degradation patterns arise under varying operational conditions. To tackle this limitation, we propose a multi-feature fusion model leveraging a dual-attention mechanism. Initially, convolutional neural networks (CNNs) and channel attention mechanisms are employed to preliminarily extract spatial features. Subsequently, a layer combining a Gate Recurrent Unit (GRU) and self-attention mechanisms is used to further extract and integrate temporal features. Finally, RUL values are predicted via regression. The effectiveness of the proposed method was validated on C-MAPSS datasets, and its superior performance in RUL prediction was demonstrated through comparative analysis with other methods.},
	language = {en},
	number = {2},
	urldate = {2025-06-09},
	journal = {Sensors},
	author = {Wang, Fan and Liu, Aihua and Qu, Chunyang and Xiong, Ruolan and Chen, Lu},
	month = jan,
	year = {2025},
	note = {Number: 2
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {GRU, dual-attention mechanism, multi-feature fusion, power machinery, remaining useful life prediction},
	pages = {497},
}

@misc{noauthor_chemical_nodate,
	title = {Chemical {Process} {Fault} {Detection} {Using} {Deep} {Learning} - {MATLAB} \&amp; {Simulink}},
	url = {https://www.mathworks.com/help/deeplearning/ug/chemical-process-fault-detection-using-deep-learning.html},
	abstract = {Use simulation data to train a neural network than can detect faults in a chemical process.},
	language = {en},
	urldate = {2025-06-09},
}

@article{lin_deep_2022,
	title = {Deep learning for the dynamic prediction of multivariate longitudinal and survival data},
	volume = {41},
	issn = {0277-6715},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9232978/},
	doi = {10.1002/sim.9392},
	abstract = {The joint model for longitudinal and survival data improves time-to-event predictions by including longitudinal outcome variables in addition to baseline covariates. However, in practice, joint models may be limited by parametric assumptions in both the longitudinal and survival submodels. In addition, computational difficulties arise when considering multiple longitudinal outcomes due to the large number of random effects to be integrated out in the full likelihood. In this article, we discuss several recent machine learning methods for incorporating multivariate longitudinal data for time-to-event prediction. The presented methods use functional data analysis or convolutional neural networks to model the longitudinal data, both of which scale well to multiple longitudinal outcomes. In addition, we propose a novel architecture based on the transformer neural network, named TransformerJM, which jointly models longitudinal and time-to-event data. The prognostic abilities of each model are assessed and compared through both simulation and real data analysis on Alzheimer’s disease datasets. Specifically, the models were evaluated based on their ability to dynamically update predictions as new longitudinal data becomes available. We showed that TransformerJM improves upon the predictive performance of existing methods across different scenarios.},
	number = {15},
	urldate = {2025-06-09},
	journal = {Statistics in medicine},
	author = {Lin, Jeffrey and Luo, Sheng},
	month = jul,
	year = {2022},
	pmid = {35347750},
	pmcid = {PMC9232978},
	pages = {2894--2907},
}

@inproceedings{li_multi-task_2016,
	address = {New York, NY, USA},
	series = {{KDD} '16},
	title = {A {Multi}-{Task} {Learning} {Formulation} for {Survival} {Analysis}},
	isbn = {978-1-4503-4232-2},
	url = {https://dl.acm.org/doi/10.1145/2939672.2939857},
	doi = {10.1145/2939672.2939857},
	abstract = {Predicting the occurrence of a particular event of interest at future time points is the primary goal of survival analysis. The presence of incomplete observations due to time limitations or loss of data traces is known as censoring which brings unique challenges in this domain and differentiates survival analysis from other standard regression methods. The popularly used survival analysis methods such as Cox proportional hazard model and parametric survival regression suffer from some strict assumptions and hypotheses that are not realistic in most of the real-world applications. To overcome the weaknesses of these two types of methods, in this paper, we reformulate the survival analysis problem as a multi-task learning problem and propose a new multi-task learning based formulation to predict the survival time by estimating the survival status at each time interval during the study duration. We propose an indicator matrix to enable the multi-task learning algorithm to handle censored instances and incorporate some of the important characteristics of survival problems such as non-negative non-increasing list structure into our model through max-heap projection. We employ the L2,1-norm penalty which enables the model to learn a shared representation across related tasks and hence select important features and alleviate over-fitting in high-dimensional feature spaces; thus, reducing the prediction error of each task. To efficiently handle the two non-smooth constraints, in this paper, we propose an optimization method which employs Alternating Direction Method of Multipliers (ADMM) algorithm to solve the proposed multi-task learning problem. We demonstrate the performance of the proposed method using real-world microarray gene expression high-dimensional benchmark datasets and show that our method outperforms state-of-the-art methods.},
	urldate = {2025-06-09},
	booktitle = {Proceedings of the 22nd {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {Association for Computing Machinery},
	author = {Li, Yan and Wang, Jie and Ye, Jieping and Reddy, Chandan K.},
	year = {2016},
	pages = {1715--1724},
}

@article{mesinovic_dysurv_2024,
	title = {{DySurv}: dynamic deep learning model for survival analysis with conditional variational inference},
	issn = {1527-974X},
	shorttitle = {{DySurv}},
	url = {https://doi.org/10.1093/jamia/ocae271},
	doi = {10.1093/jamia/ocae271},
	abstract = {Machine learning applications for longitudinal electronic health records often forecast the risk of events at fixed time points, whereas survival analysis achieves dynamic risk prediction by estimating time-to-event distributions. Here, we propose a novel conditional variational autoencoder-based method, DySurv, which uses a combination of static and longitudinal measurements from electronic health records to estimate the individual risk of death dynamically.DySurv directly estimates the cumulative risk incidence function without making any parametric assumptions on the underlying stochastic process of the time-to-event. We evaluate DySurv on 6 time-to-event benchmark datasets in healthcare, as well as 2 real-world intensive care unit (ICU) electronic health records (EHR) datasets extracted from the eICU Collaborative Research (eICU) and the Medical Information Mart for Intensive Care database (MIMIC-IV).DySurv outperforms other existing statistical and deep learning approaches to time-to-event analysis across concordance and other metrics. It achieves time-dependent concordance of over 60\% in the eICU case. It is also over 12\% more accurate and 22\% more sensitive than in-use ICU scores like Acute Physiology and Chronic Health Evaluation (APACHE) and Sequential Organ Failure Assessment (SOFA) scores. The predictive capacity of DySurv is consistent and the survival estimates remain disentangled across different datasets.Our interdisciplinary framework successfully incorporates deep learning, survival analysis, and intensive care to create a novel method for time-to-event prediction from longitudinal health records. We test our method on several held-out test sets from a variety of healthcare datasets and compare it to existing in-use clinical risk scoring benchmarks.While our method leverages non-parametric extensions to deep learning-guided estimations of the survival distribution, further deep learning paradigms could be explored.},
	urldate = {2025-06-09},
	journal = {Journal of the American Medical Informatics Association},
	author = {Mesinovic, Munib and Watkinson, Peter and Zhu, Tingting},
	month = nov,
	year = {2024},
	pages = {ocae271},
}

@article{yang_deep_2025,
	title = {Deep {Gated} {Neural} {Network} {With} {Self}-{Attention} {Mechanism} for {Survival} {Analysis}},
	volume = {29},
	issn = {2168-2208},
	url = {https://ieeexplore.ieee.org/document/10769011},
	doi = {10.1109/JBHI.2024.3507109},
	abstract = {Survival analysis is commonly used to model the time distributions of the first occurrences of events of interest, and it has widespread medical applications. Many previous studies learned the relationship between risk and covariates by making strong assumptions such as proportional hazards. However, these assumptions limit the performance somewhat. Moreover, few studies consider the temporal patterns in feature effects. This paper proposed the novel framework of a deep gated neural network with self-attention mechanism (SA-DGNet) for survival analysis with single risk and competing risks. SA-DGNet transforms the problem of survival analysis into a time-series forecasting problem that treats time as an additional input covariate and estimates the probability mass function of the first hitting time. No assumptions are made about the distribution of survival times, and a deep gated neural network module is used to calculate the time-dependent and nonlinear effects of covariates on survival outcomes. Meanwhile, for enhanced data perception, a self-attention module comprising multi-scale time-aware self-attention and scaled dot-product self-attention is designed. The results of performance evaluation on multiple real-world datasets indicate that SA-DGNet significantly outperforms previous state-of-the-art methods. This study demonstrates the potential of gated neural networks and self-attention mechanisms in survival analysis, and it provides an effective method for risk prediction based on structured data.},
	number = {4},
	urldate = {2025-06-09},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Yang, Xulin and Qiu, Hang},
	month = apr,
	year = {2025},
	keywords = {Analytical models, Bioinformatics, Context modeling, Deep learning, Hazards, Logic gates, Long short term memory, Neural networks, Predictive models, Transformers, gated neural network, self-attention, survival analysis},
	pages = {2945--2956},
}

@inproceedings{marinos_survey_2025,
	title = {A {Survey} of {Survival} {Analysis} {Techniques}},
	isbn = {978-989-758-490-9},
	url = {https://www.scitepress.org/Link.aspx?doi=10.5220/0010382307160723},
	abstract = {Digital Library},
	urldate = {2025-06-09},
	author = {Marinos, George and Kyriazis, Dimosthenis},
	month = jun,
	year = {2025},
	pages = {716--723},
}

@misc{noauthor_survival_nodate,
	title = {Survival {Models} {\textbar} {EBSCO} {Research} {Starters}},
	url = {https://www.ebsco.com/research-starters/business-and-management/survival-models},
	abstract = {Survival models are statistical tools used in survival analysis to estimate the likelihood of an event occurring beyond a specific point in time, often related to life expectancy or the duration until an event such as failure or death. These models incorporate concepts such as the survival function, which indicates the probability of surviving past a certain time, and the hazard function, which quantifies the risk of event occurrence over time. Survival analysis is commonly applied in various fields, including healthcare, engineering, and finance, for decision-making related to longevity, risk assessment, and resource management. A common assumption in survival analysis is that survival times may follow an exponential probability distribution, leading to insights into how survival probabilities can change over time. Analysts can explore various factors that influence survival, such as age or other characteristics, to enhance understanding and potentially improve outcomes. Additionally, survival models can address situations with incomplete data, known as censored observations, which is particularly relevant in real-world applications. Overall, survival analysis encompasses a range of techniques and complexities, making it a valuable method for researchers and practitioners seeking to understand temporal dynamics in survival and failure rates. The field continues to evolve, reflecting ongoing interests and advancements in statistical analysis.},
	language = {en},
	urldate = {2025-06-09},
}

@article{de_santi_explainable_2025,
	title = {Explainable {Survival} {Analysis} of {Censored} {Clinical} {Data} {Using} a {Neural} {Network} {Approach}},
	volume = {5},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2673-7426},
	url = {https://www.mdpi.com/2673-7426/5/2/17},
	doi = {10.3390/biomedinformatics5020017},
	abstract = {Survival analysis is a statistical approach widely employed to model the time of an event, such as a patient’s death. Classical approaches include the Kaplan–Meier estimator and Cox proportional hazards regression, which assume a linear relationship between the model’s covariates. However, the linearity assumption might pose challenges with high-dimensional data, thus stimulating interest in performing survival analysis using neural network models. In the present work, we implemented a deep Cox neural network (Cox-net) to predict the time of a cardiac event using patient data collected from the Myocardial Iron Overload in Thalassemia (MIOT) project. Cox-net achieved a concordance index (c-index) of 0.812 ± 0.036, outperforming the classical Cox regression (0.790 ± 0.040), and it demonstrated resilience to varying levels of censored patients. A permutation feature importance analysis identified fibrosis and sex as the most significant predictors, aligning with clinical knowledge. Cox-net was able to represent the nonlinear relationships between covariates and maintain reliable survival curve predictions in datasets with a large number of censored patients, making it a promising tool for determining the appropriate clinical pathway for thalassemic patients.},
	language = {en},
	number = {2},
	urldate = {2025-06-09},
	journal = {BioMedInformatics},
	author = {De Santi, Lisa Anita and Orlandini, Francesca and Positano, Vincenzo and Pistoia, Laura and Sorrentino, Francesco and Messina, Giuseppe and Roberti, Maria Grazia and Missere, Massimiliano and Schicchi, Nicolò and Vallone, Antonino and Santarelli, Maria Filomena and Clemente, Alberto and Meloni, Antonella},
	month = mar,
	year = {2025},
	pages = {17},
}

@article{mao_remaining_2024,
	title = {Remaining useful life prediction based on time-series features and conformalized quantile regression},
	volume = {35},
	issn = {0957-0233, 1361-6501},
	url = {https://iopscience.iop.org/article/10.1088/1361-6501/ad762c},
	doi = {10.1088/1361-6501/ad762c},
	abstract = {Abstract
            The remaining useful life (RUL) prediction is a key task in the field of prognostics and health management (PHM) and plays a crucial role in preventive maintenance tasks. Traditional prediction methods have mostly focused on point prediction issues, neglecting the uncertain factors in the prediction task, thus failing to ensure the credibility of the prediction. In light of this, this paper focuses on improving the accuracy of point prediction models for RUL and interval prediction issues, proposing the introduction of multi-scale convolutional neural networks (MCNN), decomposed time-sequential linear layers (DL), and conformal quantile regression (CQR) techniques into the RUL prediction task of aero engines. The aim is to provide timely and accurate failure warnings for aero-engines, effectively ensure their reliability and safety, and reduce maintenance costs throughout their life cycle. In response to the limitations of current point prediction models in capturing the temporal features of life data, a MCNN-DL-based RUL prediction model is proposed to capture life data’s long-term trends and local variations for precise point predictions. Furthermore, an interval estimation approach for RUL is presented, which integrates the MCNN-DL model with CQR to account for prediction uncertainty. Finally, the method in this paper is verified using the commercial modular aero-propulsion system simulation (CMAPSS) dataset, and the results show that the method has achieved excellent results in both RUL point prediction and interval prediction tasks.},
	number = {12},
	urldate = {2025-06-09},
	journal = {Measurement Science and Technology},
	author = {Mao, Song and Li, Xiaofeng and Zhao, Boyang},
	month = dec,
	year = {2024},
	pages = {126113},
}

@article{abad_explainable_nodate,
	title = {Explainable {Predictive} {Maintenance} using {Survival} {Analysis}},
	abstract = {To address the first research sub question, three ML-based-SA were developed and evaluated by concordance Index (C\_index) as evaluation metric. The results revealed that Random Survival Forest (RSF) outperformed Gradient Boosting Survival Analysis (GBSA) and Cox Proportional Hazards (CPH). Therefore RSF undergoes explainability analysis. To explore the second sub question, we utilized SHAP analysis as XAI technique, that is capable of performing both global and local explanations in addition to offering insights into the direction, amount, and dependency of features. The influential features significantly affecting the overall predictions of RSF model are identified as [666\_0, 837\_0, 158\_9, 167\_2, 167\_6, 167\_3, 272\_1, 397\_33, 272\_0, 459\_15, 397\_26, 272\_2, 309\_0, 167\_7, 272\_4, 158\_7, 397\_27, 397\_34, 397\_32, 158\_3], and their impact on the prediction output of two individual vehicles were discussed. These findings contribute to enhancing trust, understanding, and ultimately improving maintenance strategies in industrial settings.},
	language = {en},
	author = {Abad, Monireh Kargar Sharif},
}

@article{aminzadeh_machine_2025,
	title = {A {Machine} {Learning} {Implementation} to {Predictive} {Maintenance} and {Monitoring} of {Industrial} {Compressors}},
	volume = {25},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/25/4/1006},
	doi = {10.3390/s25041006},
	abstract = {Integrating machine learning algorithms leveraged by advanced data acquisition systems is emerging as a pivotal approach in predictive maintenance. This paper presents the deployment of such an integration on an industrial air compressor unit. This research combines updated concepts from the Internet of Things, machine learning, multi-sensor data collection, structured data mining, and cloud-based data analysis. To this end, temperature, pressure, and flow rate data were acquired from sensors in contact with the compressor. The observed data were sent to the Structured Query Language database. Then, a Linear Regression model was fitted to the training data, and the optimized model was stored for real-time inference. Afterward, structured data were passed through the model, and if the data exceeded the determined threshold, a warning email was sent to an operator. Adopting the Internet of Things enhances surveillance for specialists, decreasing the failure and damage probabilities. The model achieved 98\% accuracy in the Mean Squared Error metric for our regression model. By analyzing the gathered data, the implemented system demonstrates the capabilities to predict potential equipment failures with promising accuracy, facilitating a shift from reactive to proactive maintenance strategies. The findings reveal substantial potential for improvements in maintenance efficiency, equipment uptime, and cost savings.},
	language = {en},
	number = {4},
	urldate = {2025-06-09},
	journal = {Sensors},
	author = {Aminzadeh, Ahmad and Sattarpanah Karganroudi, Sasan and Majidi, Soheil and Dabompre, Colin and Azaiez, Khalil and Mitride, Christopher and Sénéchal, Eric},
	month = feb,
	year = {2025},
	pages = {1006},
}

@article{esteban_data_2022,
	title = {Data mining in predictive maintenance systems: {A} taxonomy and systematic review},
	volume = {12},
	issn = {1942-4787, 1942-4795},
	shorttitle = {Data mining in predictive maintenance systems},
	url = {https://wires.onlinelibrary.wiley.com/doi/10.1002/widm.1471},
	doi = {10.1002/widm.1471},
	abstract = {Abstract
            Predictive maintenance is a field of study whose main objective is to optimize the timing and type of maintenance to perform on various industrial systems. This aim involves maximizing the availability time of the monitored system and minimizing the number of resources used in maintenance. Predictive maintenance is currently undergoing a revolution thanks to advances in industrial systems monitoring within the Industry 4.0 paradigm. Likewise, advances in artificial intelligence and data mining allow the processing of a great amount of data to provide more accurate and advanced predictive models. In this context, many actors have become interested in predictive maintenance research, becoming one of the most active areas of research in computing, where academia and industry converge. The objective of this paper is to conduct a systematic literature review that provides an overview of the current state of research concerning predictive maintenance from a data mining perspective. The review presents a first taxonomy that implies different phases considered in any data mining process to solve a predictive maintenance problem, relating the predictive maintenance tasks with the main data mining tasks to solve them. Finally, the paper presents significant challenges and future research directions in terms of the potential of data mining applied to predictive maintenance.
            
              This article is categorized under:
              
                
                  Application Areas {\textgreater} Industry Specific Applications
                
                
                  Technologies {\textgreater} Internet of Things},
	language = {en},
	number = {5},
	urldate = {2025-06-09},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Esteban, Aurora and Zafra, Amelia and Ventura, Sebastián},
	month = sep,
	year = {2022},
	pages = {e1471},
}

@article{yerokun_development_2025,
	title = {Development of {Operational} {Predictive} {Maintenance} {System} in {Oil} and {Gas} {Industry} {Case} {Study} of {Warri} {Refining} and {Petrochemical} {Company}},
	volume = {11},
	abstract = {The oil and gas industry is critical to global energy supply and national economic development, particularly in resource-rich countries like Nigeria. One of the major reasons for the collapse and total shutting down of all refineries in Nigeria is lack of maintenance culture. In the fastpaced digital world, it is imperative to employ emerging technologies in addressing such national issues like refinery maintenance, this study therefore focuses on developing an operational predictive maintenance (PdM) system for Warri Refining and Petrochemical Company (WRPC). The system utilized advanced data analytics and condition-based monitoring technologies to predict equipment failures before they occur. Predictive maintenance offers advantages over traditional reactive and preventive maintenance approaches by optimizing maintenance schedules, reducing downtime, and lowering operational costs. The study highlighted challenges such as aging infrastructure, resource constraints, and regulatory pressures WRPC faces and demonstrated how PdM system addressed the issues. Implementation results showed improved equipment reliability, enhanced safety, and optimized operational efficiency. Recommendations for future initiatives include technological upgrades, staff training, and collaborative efforts among industry stakeholders.},
	language = {en},
	number = {3},
	author = {Yerokun, Dr Oluwatoyin Mary},
	year = {2025},
}

@article{han_trustworthy_2025,
	title = {Trustworthy interval prediction method with uncertainty estimation based on evidence neural networks},
	volume = {261},
	issn = {09518320},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S095183202500287X},
	doi = {10.1016/j.ress.2025.111086},
	language = {en},
	urldate = {2025-06-04},
	journal = {Reliability Engineering \& System Safety},
	author = {Han, Peng and Huang, Zhiqiu and Li, Weiwei and He, Wei and Cao, You},
	month = sep,
	year = {2025},
	pages = {111086},
}

@article{ayed_remaining_2025,
	title = {Remaining {Useful} {Life} {Prediction} with {Uncertainty} {Quantification} {Using} {Evidential} {Deep} {Learning}},
	volume = {15},
	copyright = {http://creativecommons.org/licenses/by-nc-nd/4.0},
	issn = {2449-6499},
	url = {https://www.sciendo.com/article/10.2478/jaiscr-2025-0003},
	doi = {10.2478/jaiscr-2025-0003},
	abstract = {Abstract
            Predictive Maintenance presents an important and challenging task in Industry 4.0. It aims to prevent premature failures and reduce costs by avoiding unnecessary maintenance tasks. This involves estimating the Remaining Useful Life (RUL), which provides critical information for decision makers and planners of future maintenance activities. However, RUL prediction is not simple due to the imperfections in monitoring data, making effective Predictive Maintenance challenging. To address this issue, this article proposes an Evidential Deep Learning (EDL) based method to predict the RUL and to quantify both data uncertainties and prediction model uncertainties. An experimental analysis conducted on the C-MAPSS dataset of aero-engine degradation affirms that EDL based method outperforms alternative machine learning approaches. Moreover, the accompanying uncertainty quantification analysis demonstrates sound methodology and reliable results.},
	language = {en},
	number = {1},
	urldate = {2025-06-04},
	journal = {Journal of Artificial Intelligence and Soft Computing Research},
	author = {Ayed, Safa Ben and Broujeny, Roozbeh Sadeghian and Hamza, Rachid Tahar},
	month = jan,
	year = {2025},
	pages = {37--55},
}

@article{lyu_interval_2023,
	title = {Interval {Prediction} of {Remaining} {Useful} {Life} based on {Convolutional} {Auto}-{Encode} and {Lower} {Upper} {Bound} {Estimation}},
	volume = {25},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1507-2711, 2956-3860},
	url = {https://ein.org.pl/Interval-Prediction-of-Remaining-Useful-Life-based-on-Convolutional-Auto-Encode-and,165811,0,2.html},
	doi = {10.17531/ein/165811},
	abstract = {Deep learning is widely used in remaining useful life (RUL) prediction
because it does not require prior knowledge and has strong nonlinear
fitting ability. However, most of the existing prediction methods are
point prediction. In practical engineering applications, confidence
interval of RUL prediction is more important for maintenance strategies.
This paper proposes an interval prediction model based on Long ShortTerm Memory (LSTM) and lower upper bound estimation (LUBE) for
RUL prediction. First, convolutional auto-encode network is used to
encode the multi-dimensional sensor data into one-dimensional features,
which can well represent the main degradation trend. Then, the features
are input into the prediction framework composed of LSTM and LUBE
for RUL interval prediction, which effectively solves the defect that the
traditional LUBE network cannot analyze the internal time dependence
of time series. In the experiment section, a case study is conducted using
the turbofan engine data set CMAPSS, and the advantage is validated by
carrying out a comparison with other methods.},
	number = {2},
	urldate = {2025-06-04},
	journal = {Eksploatacja i Niezawodność – Maintenance and Reliability},
	author = {Lyu, Yi and Zhang, Qichen and Chen, Aiguo and Wen, Zhenfei},
	month = apr,
	year = {2023},
}

@article{caetano_transformer-based_2025,
	title = {Transformer-{Based} {Models} for {Probabilistic} {Time} {Series} {Forecasting} with {Explanatory} {Variables}},
	volume = {13},
	issn = {2227-7390},
	url = {https://www.mdpi.com/2227-7390/13/5/814},
	doi = {10.3390/math13050814},
	abstract = {Accurate demand forecasting is essential for retail operations as it directly impacts supply chain efficiency, inventory management, and financial performance. However, forecasting retail time series presents significant challenges due to their irregular patterns, hierarchical structures, and strong dependence on external factors such as promotions, pricing strategies, and socio-economic conditions. This study evaluates the effectiveness of Transformer-based architectures, specifically Vanilla Transformer, Informer, Autoformer, ETSformer, NSTransformer, and Reformer, for probabilistic time series forecasting in retail. A key focus is the integration of explanatory variables, such as calendar-related indicators, selling prices, and socio-economic factors, which play a crucial role in capturing demand fluctuations. This study assesses how incorporating these variables enhances forecast accuracy, addressing a research gap in the comprehensive evaluation of explanatory variables within multiple Transformer-based models. Empirical results, based on the M5 dataset, show that incorporating explanatory variables generally improves forecasting performance. Models leveraging these variables achieve up to 12.4\% reduction in Normalized Root Mean Squared Error (NRMSE) and 2.9\% improvement in Mean Absolute Scaled Error (MASE) compared to models that rely solely on past sales. Furthermore, probabilistic forecasting enhances decision making by quantifying uncertainty, providing more reliable demand predictions for risk management. These findings underscore the effectiveness of Transformer-based models in retail forecasting and emphasize the importance of integrating domain-specific explanatory variables to achieve more accurate, context-aware predictions in dynamic retail environments.},
	number = {5},
	journal = {Mathematics},
	author = {Caetano, Ricardo and Oliveira, José Manuel and Ramos, Patrícia},
	year = {2025},
}

@misc{rizvi_bridging_2025,
	title = {Bridging {Simplicity} and {Sophistication} using {GLinear}: {A} {Novel} {Architecture} for {Enhanced} {Time} {Series} {Prediction}},
	shorttitle = {Bridging {Simplicity} and {Sophistication} using {GLinear}},
	url = {http://arxiv.org/abs/2501.01087},
	doi = {10.48550/arXiv.2501.01087},
	abstract = {Time Series Forecasting (TSF) is an important application across many fields. There is a debate about whether Transformers, despite being good at understanding long sequences, struggle with preserving temporal relationships in time series data. Recent research suggests that simpler linear models might outperform or at least provide competitive performance compared to complex Transformer-based models for TSF tasks. In this paper, we propose a novel data-efficient architecture, GLinear, for multivariate TSF that exploits periodic patterns to provide better accuracy. It also provides better prediction accuracy by using a smaller amount of historical data compared to other state-of-the-art linear predictors. Four different datasets (ETTh1, Electricity, Traffic, and Weather) are used to evaluate the performance of the proposed predictor. A performance comparison with state-of-the-art linear architectures (such as NLinear, DLinear, and RLinear) and transformer-based time series predictor (Autoformer) shows that the GLinear, despite being parametrically efficient, significantly outperforms the existing architectures in most cases of multivariate TSF. We hope that the proposed GLinear opens new fronts of research and development of simpler and more sophisticated architectures for data and computationally efficient time-series analysis.},
	urldate = {2025-06-04},
	publisher = {arXiv},
	author = {Rizvi, Syed Tahir Hussain and Kanwal, Neel and Naeem, Muddasar and Cuzzocrea, Alfredo and Coronato, Antonio},
	month = jan,
	year = {2025},
	note = {arXiv:2501.01087 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Emerging Technologies, Computer Science - Machine Learning},
}

@article{srinivasan_ensemble_2023,
	title = {Ensemble {Neural} {Networks} for {Remaining} {Useful} {Life} ({RUL}) {Prediction}},
	volume = {4},
	issn = {2994-7219, 2994-7219},
	url = {http://arxiv.org/abs/2309.12445},
	doi = {10.36001/phmap.2023.v4i1.3611},
	abstract = {A core part of maintenance planning is a monitoring system that provides a good prognosis on health and degradation, often expressed as remaining useful life (RUL). Most of the current data-driven approaches for RUL prediction focus on single-point prediction. These point prediction approaches do not include the probabilistic nature of the failure. The few probabilistic approaches to date either include the aleatoric uncertainty (which originates from the system), or the epistemic uncertainty (which originates from the model parameters), or both simultaneously as a total uncertainty. Here, we propose ensemble neural networks for probabilistic RUL predictions which considers both uncertainties and decouples these two uncertainties. These decoupled uncertainties are vital in knowing and interpreting the confidence of the predictions. This method is tested on NASA's turbofan jet engine CMAPSS data-set. Our results show how these uncertainties can be modeled and how to disentangle the contribution of aleatoric and epistemic uncertainty. Additionally, our approach is evaluated on different metrics and compared against the current state-of-the-art methods.},
	number = {1},
	urldate = {2025-06-04},
	journal = {PHM Society Asia-Pacific Conference},
	author = {Srinivasan, Ahbishek and Andresen, Juan Carlos and Holst, Anders},
	month = sep,
	year = {2023},
	note = {arXiv:2309.12445 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{nemani_ensembles_2022,
	title = {Ensembles of probabilistic {LSTM} predictors and correctors for bearing prognostics using industrial standards},
	volume = {491},
	issn = {09252312},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0925231221018737},
	doi = {10.1016/j.neucom.2021.12.035},
	language = {en},
	urldate = {2025-06-04},
	journal = {Neurocomputing},
	author = {Nemani, Venkat P. and Lu, Hao and Thelen, Adam and Hu, Chao and Zimmerman, Andrew T.},
	month = jun,
	year = {2022},
	pages = {575--596},
}

@article{mateus_comparing_2021,
	title = {Comparing {LSTM} and {GRU} {Models} to {Predict} the {Condition} of a {Pulp} {Paper} {Press}},
	volume = {14},
	issn = {1996-1073},
	url = {https://www.mdpi.com/1996-1073/14/21/6958},
	doi = {10.3390/en14216958},
	abstract = {The accuracy of a predictive system is critical for predictive maintenance and to support the right decisions at the right times. Statistical models, such as ARIMA and SARIMA, are unable to describe the stochastic nature of the data. Neural networks, such as long short-term memory (LSTM) and the gated recurrent unit (GRU), are good predictors for univariate and multivariate data. The present paper describes a case study where the performances of long short-term memory and gated recurrent units are compared, based on different hyperparameters. In general, gated recurrent units exhibit better performance, based on a case study on pulp paper presses. The final result demonstrates that, to maximize the equipment availability, gated recurrent units, as demonstrated in the paper, are the best options.},
	number = {21},
	journal = {Energies},
	author = {Mateus, Balduíno César and Mendes, Mateus and Farinha, José Torres and Assis, Rui and Cardoso, António Marques},
	year = {2021},
}

@article{vago_predicting_2024,
	title = {Predicting machine failures from multivariate time series: an industrial case study},
	volume = {12},
	issn = {2075-1702},
	shorttitle = {Predicting machine failures from multivariate time series},
	url = {http://arxiv.org/abs/2402.17804},
	doi = {10.3390/machines12060357},
	abstract = {Non-neural Machine Learning (ML) and Deep Learning (DL) models are often used to predict system failures in the context of industrial maintenance. However, only a few researches jointly assess the effect of varying the amount of past data used to make a prediction and the extension in the future of the forecast. This study evaluates the impact of the size of the reading window and of the prediction window on the performances of models trained to forecast failures in three data sets concerning the operation of (1) an industrial wrapping machine working in discrete sessions, (2) an industrial blood refrigerator working continuously, and (3) a nitrogen generator working continuously. The problem is formulated as a binary classification task that assigns the positive label to the prediction window based on the probability of a failure to occur in such an interval. Six algorithms (logistic regression, random forest, support vector machine, LSTM, ConvLSTM, and Transformers) are compared using multivariate telemetry time series. The results indicate that, in the considered scenarios, the dimension of the prediction windows plays a crucial role and highlight the effectiveness of DL approaches at classifying data with diverse time-dependent patterns preceding a failure and the effectiveness of ML approaches at classifying similar and repetitive patterns preceding a failure.},
	number = {6},
	urldate = {2025-06-04},
	journal = {Machines},
	author = {Vago, Nicolò Oreste Pinciroli and Forbicini, Francesca and Fraternali, Piero},
	month = may,
	year = {2024},
	note = {arXiv:2402.17804 [cs]},
	keywords = {Computer Science - Machine Learning},
	pages = {357},
}

@misc{parii_predicting_2025,
	title = {Predicting the {Lifespan} of {Industrial} {Printheads} with {Survival} {Analysis}},
	url = {http://arxiv.org/abs/2504.07638},
	doi = {10.48550/arXiv.2504.07638},
	abstract = {Accurately predicting the lifespan of critical device components is essential for maintenance planning and production optimization, making it a topic of significant interest in both academia and industry. In this work, we investigate the use of survival analysis for predicting the lifespan of production printheads developed by Canon Production Printing. Specifically, we focus on the application of five techniques to estimate survival probabilities and failure rates: the Kaplan-Meier estimator, Cox proportional hazard model, Weibull accelerated failure time model, random survival forest, and gradient boosting. The resulting estimates are further refined using isotonic regression and subsequently aggregated to determine the expected number of failures. The predictions are then validated against real-world ground truth data across multiple time windows to assess model reliability. Our quantitative evaluation using three performance metrics demonstrates that survival analysis outperforms industry-standard baseline methods for printhead lifespan prediction.},
	urldate = {2025-06-04},
	publisher = {arXiv},
	author = {Parii, Dan and Janssen, Evelyne and Tang, Guangzhi and Kouzinopoulos, Charalampos and Pietrasik, Marcin},
	month = apr,
	year = {2025},
	note = {arXiv:2504.07638 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{g_cnn-lstm_2024,
	title = {{CNN}-{LSTM} {Hybrid} {Deep} {Learning} {Model} for {Remaining} {Useful} {Life} {Estimation}},
	url = {http://arxiv.org/abs/2412.15998},
	doi = {10.2015/IJIRMF/ICSETI-2024/P04},
	abstract = {Remaining Useful Life (RUL) of a component or a system is defined as the length from the current time to the end of the useful life. Accurate RUL estimation plays a crucial role in Predictive Maintenance applications. Traditional regression methods, both linear and non-linear, have struggled to achieve high accuracy in this domain. While Convolutional Neural Networks (CNNs) have shown improved accuracy, they often overlook the sequential nature of the data, relying instead on features derived from sliding windows. Since RUL prediction inherently involves multivariate time series analysis, robust sequence learning is essential. In this work, we propose a hybrid approach combining Convolutional Neural Networks with Long Short-Term Memory (LSTM) networks for RUL estimation. Although CNN-based LSTM models have been applied to sequence prediction tasks in financial forecasting, this is the first attempt to adopt this approach for RUL estimation in prognostics. In this approach, CNN is first employed to efficiently extract features from the data, followed by LSTM, which uses these extracted features to predict RUL. This method effectively leverages sensor sequence information, uncovering hidden patterns within the data, even under multiple operating conditions and fault scenarios. Our results demonstrate that the hybrid CNN-LSTM model achieves the highest accuracy, offering a superior score compared to the other methods.},
	urldate = {2025-06-04},
	author = {G, Muthukumar and Philip, Jyosna},
	month = dec,
	year = {2024},
	note = {arXiv:2412.15998 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{reneau_feature_2023,
	title = {Feature {Programming} for {Multivariate} {Time} {Series} {Prediction}},
	url = {http://arxiv.org/abs/2306.06252},
	doi = {10.48550/arXiv.2306.06252},
	abstract = {We introduce the concept of programmable feature engineering for time series modeling and propose a feature programming framework. This framework generates large amounts of predictive features for noisy multivariate time series while allowing users to incorporate their inductive bias with minimal effort. The key motivation of our framework is to view any multivariate time series as a cumulative sum of fine-grained trajectory increments, with each increment governed by a novel spin-gas dynamical Ising model. This fine-grained perspective motivates the development of a parsimonious set of operators that summarize multivariate time series in an abstract fashion, serving as the foundation for large-scale automated feature engineering. Numerically, we validate the efficacy of our method on several synthetic and real-world noisy time series datasets.},
	urldate = {2025-06-04},
	publisher = {arXiv},
	author = {Reneau, Alex and Hu, Jerry Yao-Chieh and Xu, Chenwei and Li, Weijian and Gilani, Ammar and Liu, Han},
	month = jun,
	year = {2023},
	note = {arXiv:2306.06252 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ibrahim_integrated_2024,
	title = {An {Integrated} {Detection}-{Prognostics} {Methodology} for {Components} {With} {Intermittent} {Faults}},
	volume = {24},
	issn = {1530-9827, 1944-7078},
	url = {https://asmedigitalcollection.asme.org/computingengineering/article/24/6/061003/1199041/An-Integrated-Detection-Prognostics-Methodology},
	doi = {10.1115/1.4065212},
	abstract = {Abstract
            Some industrial components, such as valves, relay switches, and motors, occasionally experience intermittent faults (IFs) that usually disappear without any repair or intervention. This phenomenon occurs at a relatively low frequency even in components that are in an “as-good-as-new” state. However, an increase in the frequency of IFs often indicates the onset of degradation. We develop an integrated detection-prognostics model for components that exhibit IFs and whose degradation data are high-dimensional. We discuss the use of dynamic time warping (DTW) and a variational autoencoder (VAE) to perform feature engineering on the data. We then propose a hidden Markov model (HMM)-based monitoring strategy composed of two parts: (1) a detection model that tracks and flags changes in the intermittent fault frequency (IFF) and (2) a prognostic model that leverages how the transition probabilities of the HMM evolve with progressive degradation to compute the remaining life distribution (RLD) of the component. We examine the performance of our modeling framework using high-dimensional data generated from a vehicular electrical system testbed designed to accelerate the degradation of a vehicle starter motor.},
	language = {en},
	number = {6},
	urldate = {2025-06-04},
	journal = {Journal of Computing and Information Science in Engineering},
	author = {Ibrahim, Michael and Rozas, Heraldo and Gebraeel, Nagi},
	month = jun,
	year = {2024},
	pages = {061003},
}

@article{pinciroli_vago_predicting_2024,
	title = {Predicting {Machine} {Failures} from {Multivariate} {Time} {Series}: {An} {Industrial} {Case} {Study}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2075-1702},
	shorttitle = {Predicting {Machine} {Failures} from {Multivariate} {Time} {Series}},
	url = {https://www.mdpi.com/2075-1702/12/6/357},
	doi = {10.3390/machines12060357},
	abstract = {Non-neural machine learning (ML) and deep learning (DL) are used to predict system failures in industrial maintenance. However, only a few studies have assessed the effect of varying the amount of past data used to make a prediction and the extension in the future of the forecast. This study evaluates the impact of the size of the reading window and of the prediction window on the performances of models trained to forecast failures in three datasets of (1) an industrial wrapping machine working in discrete sessions, (2) an industrial blood refrigerator working continuously, and (3) a nitrogen generator working continuously. A binary classification task assigns the positive label to the prediction window based on the probability of a failure to occur in such an interval. Six algorithms (logistic regression, random forest, support vector machine, LSTM, ConvLSTM, and Transformers) are compared on multivariate time series. The dimension of the prediction windows plays a crucial role and the results highlight the effectiveness of DL approaches in classifying data with diverse time-dependent patterns preceding a failure and the effectiveness of ML approaches in classifying similar and repetitive patterns preceding a failure.},
	language = {en},
	number = {6},
	urldate = {2025-06-04},
	journal = {Machines},
	author = {Pinciroli Vago, Nicolò Oreste and Forbicini, Francesca and Fraternali, Piero},
	month = may,
	year = {2024},
	pages = {357},
}

@article{birihanu_explainable_2025,
	title = {Explainable correlation-based anomaly detection for {Industrial} {Control} {Systems}},
	volume = {Volume 7 - 2024},
	issn = {2624-8212},
	url = {https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1508821},
	doi = {10.3389/frai.2024.1508821},
	journal = {Frontiers in Artificial Intelligence},
	author = {Birihanu, Ermiyas and Lendák, Imre},
	year = {2025},
}

@article{pan_remaining_2025,
	title = {Remaining useful life prediction methods of equipment components based on deep learning for sustainable manufacturing: a literature review},
	volume = {39},
	doi = {10.1017/S0890060424000271},
	journal = {Artificial Intelligence for Engineering Design, Analysis and Manufacturing},
	author = {Pan, Yao and Kang, Shijia and Kong, Linggang and Wu, Jiaju and Yang, Yonghui and Zuo, Hongfu},
	year = {2025},
	pages = {e4},
}

@article{fu_prognostic_2023,
	title = {Prognostic and {Health} {Management} of {Critical} {Aircraft} {Systems} and {Components}: {An} {Overview}},
	volume = {23},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/23/19/8124},
	doi = {10.3390/s23198124},
	abstract = {Prognostic and health management (PHM) plays a vital role in ensuring the safety and reliability of aircraft systems. The process entails the proactive surveillance and evaluation of the state and functional effectiveness of crucial subsystems. The principal aim of PHM is to predict the remaining useful life (RUL) of subsystems and proactively mitigate future breakdowns in order to minimize consequences. The achievement of this objective is helped by employing predictive modeling techniques and doing real-time data analysis. The incorporation of prognostic methodologies is of utmost importance in the execution of condition-based maintenance (CBM), a strategic approach that emphasizes the prioritization of repairing components that have experienced quantifiable damage. Multiple methodologies are employed to support the advancement of prognostics for aviation systems, encompassing physics-based modeling, data-driven techniques, and hybrid prognosis. These methodologies enable the prediction and mitigation of failures by identifying relevant health indicators. Despite the promising outcomes in the aviation sector pertaining to the implementation of PHM, there exists a deficiency in the research concerning the efficient integration of hybrid PHM applications. The primary aim of this paper is to provide a thorough analysis of the current state of research advancements in prognostics for aircraft systems, with a specific focus on prominent algorithms and their practical applications and challenges. The paper concludes by providing a detailed analysis of prospective directions for future research within the field.},
	number = {19},
	journal = {Sensors},
	author = {Fu, Shuai and Avdelidis, Nicolas P.},
	year = {2023},
}

@misc{abshari_llm-assisted_2024,
	title = {{LLM}-assisted {Physical} {Invariant} {Extraction} for {Cyber}-{Physical} {Systems} {Anomaly} {Detection}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2411.10918},
	doi = {10.48550/ARXIV.2411.10918},
	abstract = {Modern industrial infrastructures rely heavily on Cyber-Physical Systems (CPS), but these are vulnerable to cyber-attacks with potentially catastrophic effects. To reduce these risks, anomaly detection methods based on physical invariants have been developed. However, these methods often require domain-specific expertise to manually define invariants, making them costly and difficult to scale. To address this limitation, we propose a novel approach to extract physical invariants from CPS testbeds for anomaly detection. Our insight is that CPS design documentation often contains semantically rich descriptions of physical procedures, which can profile inter-correlated dynamics among system components. Leveraging the built-in physics and engineering knowledge of recent generative AI models, we aim to automate this traditionally manual process, improving scalability and reducing costs. This work focuses on designing and optimizing a Retrieval-Augmented-Generation (RAG) workflow with a customized prompting system tailored for CPS documentation, enabling accurate extraction of semantic information and inference of physical invariants from complex, multimodal content. Then, rather than directly applying the inferred invariants for anomaly detection, we introduce an innovative statistics-based learning approach that integrates these invariants into the training dataset. This method addresses limitations such as hallucination and concept drift, enhancing the reliability of the model. We evaluate our approach on real-world public CPS security dataset which contains 86 data points and 58 attacking cases. The results show that our approach achieves a high precision of 0.923, accurately detecting anomalies while minimizing false alarms.},
	urldate = {2025-06-02},
	publisher = {arXiv},
	author = {Abshari, Danial and Fu, Chenglong and Sridhar, Meera},
	year = {2024},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.AI), Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Cryptography and Security (cs.CR), FOS: Computer and information sciences},
}

@inproceedings{jose_bridging_2024,
	address = {Boston, MA, USA},
	title = {Bridging expert knowledge and sensor measurements for machine fault quantification with large language models},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-5536-9},
	url = {https://ieeexplore.ieee.org/document/10637229/},
	doi = {10.1109/AIM55361.2024.10637229},
	urldate = {2025-06-03},
	booktitle = {2024 {IEEE} {International} {Conference} on {Advanced} {Intelligent} {Mechatronics} ({AIM})},
	publisher = {IEEE},
	author = {Jose, Sagar and Nguyen, Khanh T.P and Medjaher, Kamal and Zemouri, Ryad and Lévesque, Mélanie and Tahan, Antoine},
	month = jul,
	year = {2024},
	pages = {530--535},
}

@misc{xia_control_2024,
	title = {Control {Industrial} {Automation} {System} with {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2409.18009},
	doi = {10.48550/arXiv.2409.18009},
	abstract = {Traditional industrial automation systems require specialized expertise to operate and complex reprogramming to adapt to new processes. Large language models offer the intelligence to make them more flexible and easier to use. However, LLMs' application in industrial settings is underexplored. This paper introduces a framework for integrating LLMs to achieve end-to-end control of industrial automation systems. At the core of the framework are an agent system designed for industrial tasks, a structured prompting method, and an event-driven information modeling mechanism that provides real-time data for LLM inference. The framework supplies LLMs with real-time events on different context semantic levels, allowing them to interpret the information, generate production plans, and control operations on the automation system. It also supports structured dataset creation for fine-tuning on this downstream application of LLMs. Our contribution includes a formal system design, proof-of-concept implementation, and a method for generating task-specific datasets for LLM fine-tuning and testing. This approach enables a more adaptive automation system that can respond to spontaneous events, while allowing easier operation and configuration through natural language for more intuitive human-machine interaction. We provide demo videos and detailed data on GitHub: https://github.com/YuchenXia/LLM4IAS},
	urldate = {2025-06-03},
	publisher = {arXiv},
	author = {Xia, Yuchen and Jazdi, Nasser and Zhang, Jize and Shah, Chaitanya and Weyrich, Michael},
	month = sep,
	year = {2024},
	note = {arXiv:2409.18009 [eess]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction, Computer Science - Multiagent Systems, Computer Science - Robotics, Computer Science - Systems and Control, Electrical Engineering and Systems Science - Systems and Control},
}

@misc{gill_leveraging_2025,
	title = {Leveraging {LLM} {Agents} and {Digital} {Twins} for {Fault} {Handling} in {Process} {Plants}},
	url = {http://arxiv.org/abs/2505.02076},
	doi = {10.48550/arXiv.2505.02076},
	abstract = {Advances in Automation and Artificial Intelligence continue to enhance the autonomy of process plants in handling various operational scenarios. However, certain tasks, such as fault handling, remain challenging, as they rely heavily on human expertise. This highlights the need for systematic, knowledge-based methods. To address this gap, we propose a methodological framework that integrates Large Language Model (LLM) agents with a Digital Twin environment. The LLM agents continuously interpret system states and initiate control actions, including responses to unexpected faults, with the goal of returning the system to normal operation. In this context, the Digital Twin acts both as a structured repository of plant-specific engineering knowledge for agent prompting and as a simulation platform for the systematic validation and verification of the generated corrective control actions. The evaluation using a mixing module of a process plant demonstrates that the proposed framework is capable not only of autonomously controlling the mixing module, but also of generating effective corrective actions to mitigate a pipe clogging with only a few reprompts.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Gill, Milapji Singh and Vyas, Javal and Markaj, Artan and Gehlhoff, Felix and Mercangöz, Mehmet},
	month = may,
	year = {2025},
	note = {arXiv:2505.02076 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems},
}

@inproceedings{fakih_llm4plc_2024,
	address = {Lisbon Portugal},
	title = {{LLM4PLC}: {Harnessing} {Large} {Language} {Models} for {Verifiable} {Programming} of {PLCs} in {Industrial} {Control} {Systems}},
	isbn = {979-8-4007-0501-4},
	shorttitle = {{LLM4PLC}},
	url = {https://dl.acm.org/doi/10.1145/3639477.3639743},
	doi = {10.1145/3639477.3639743},
	language = {en},
	urldate = {2025-06-02},
	booktitle = {Proceedings of the 46th {International} {Conference} on {Software} {Engineering}: {Software} {Engineering} in {Practice}},
	publisher = {ACM},
	author = {Fakih, Mohamad and Dharmaji, Rahul and Moghaddas, Yasamin and Quiros, Gustavo and Ogundare, Oluwatosin and Al Faruque, Mohammad Abdullah},
	month = apr,
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Programming Languages, Computer Science - Software Engineering},
	pages = {192--203},
}

@misc{russell-gilbert_raad-llm_2025,
	title = {{RAAD}-{LLM}: {Adaptive} {Anomaly} {Detection} {Using} {LLMs} and {RAG} {Integration}},
	shorttitle = {{RAAD}-{LLM}},
	url = {http://arxiv.org/abs/2503.02800},
	doi = {10.48550/arXiv.2503.02800},
	abstract = {Anomaly detection in complex industrial environments poses unique challenges, particularly in contexts characterized by data sparsity and evolving operational conditions. Predictive maintenance (PdM) in such settings demands methodologies that are adaptive, transferable, and capable of integrating domain-specific knowledge. In this paper, we present RAAD-LLM, a novel framework for adaptive anomaly detection, leveraging large language models (LLMs) integrated with Retrieval-Augmented Generation (RAG). This approach addresses the aforementioned PdM challenges. By effectively utilizing domain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time series data without requiring fine-tuning on specific datasets. The framework's adaptability mechanism enables it to adjust its understanding of normal operating conditions dynamically, thus increasing detection accuracy. We validate this methodology through a real-world application for a plastics manufacturing plant and the Skoltech Anomaly Benchmark (SKAB). Results show significant improvements over our previous model with an accuracy increase from 70.7\% to 88.6\% on the real-world dataset. By allowing for the enriching of input series data with semantics, RAAD-LLM incorporates multimodal capabilities that facilitate more collaborative decision-making between the model and plant operators. Overall, our findings support RAAD-LLM's ability to revolutionize anomaly detection methodologies in PdM, potentially leading to a paradigm shift in how anomaly detection is implemented across various industries.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Russell-Gilbert, Alicia and Mittal, Sudip and Rahimi, Shahram and Seale, Maria and Jabour, Joseph and Arnold, Thomas and Church, Joshua},
	month = mar,
	year = {2025},
	note = {arXiv:2503.02800 [cs]},
	keywords = {Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning},
}

@misc{alimin_talking_2025,
	title = {Talking like {Piping} and {Instrumentation} {Diagrams} ({P}\&{IDs})},
	url = {http://arxiv.org/abs/2502.18928},
	doi = {10.48550/arXiv.2502.18928},
	abstract = {We propose a methodology that allows communication with Piping and Instrumentation Diagrams (P\&IDs) using natural language. In particular, we represent P\&IDs through the DEXPI data model as labeled property graphs and integrate them with Large Language Models (LLMs). The approach consists of three main parts: 1) P\&IDs are cast into a graph representation from the DEXPI format using our pyDEXPI Python package. 2) A tool for generating P\&ID knowledge graphs from pyDEXPI. 3) Integration of the P\&ID knowledge graph to LLMs using graph-based retrieval augmented generation (graph-RAG). This approach allows users to communicate with P\&IDs using natural language. It extends LLM's ability to retrieve contextual data from P\&IDs and mitigate hallucinations. Leveraging the LLM's large corpus, the model is also able to interpret process information in PIDs, which could help engineers in their daily tasks. In the future, this work will also open up opportunities in the context of other generative Artificial Intelligence (genAI) solutions on P\&IDs, and AI-assisted HAZOP studies.},
	urldate = {2025-05-08},
	publisher = {arXiv},
	author = {Alimin, Achmad Anggawirya and Goldstein, Dominik P. and Balhorn, Lukas Schulze and Schweidtmann, Artur M.},
	month = feb,
	year = {2025},
	note = {arXiv:2502.18928 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@article{pagano_predictive_2023,
	title = {A predictive maintenance model using {Long} {Short}-{Term} {Memory} {Neural} {Networks} and {Bayesian} inference},
	volume = {6},
	issn = {27726622},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2772662223000140},
	doi = {10.1016/j.dajour.2023.100174},
	language = {en},
	urldate = {2025-06-04},
	journal = {Decision Analytics Journal},
	author = {Pagano, Davide},
	month = mar,
	year = {2023},
	pages = {100174},
}

@misc{brown_enhancing_2024,
	title = {Enhancing {Trust} in {LLMs}: {Algorithms} for {Comparing} and {Interpreting} {LLMs}},
	shorttitle = {Enhancing {Trust} in {LLMs}},
	url = {http://arxiv.org/abs/2406.01943},
	doi = {10.48550/arXiv.2406.01943},
	abstract = {This paper surveys evaluation techniques to enhance the trustworthiness and understanding of Large Language Models (LLMs). As reliance on LLMs grows, ensuring their reliability, fairness, and transparency is crucial. We explore algorithmic methods and metrics to assess LLM performance, identify weaknesses, and guide development towards more trustworthy applications. Key evaluation metrics include Perplexity Measurement, NLP metrics (BLEU, ROUGE, METEOR, BERTScore, GLEU, Word Error Rate, Character Error Rate), Zero-Shot and Few-Shot Learning Performance, Transfer Learning Evaluation, Adversarial Testing, and Fairness and Bias Evaluation. We introduce innovative approaches like LLMMaps for stratified evaluation, Benchmarking and Leaderboards for competitive assessment, Stratified Analysis for in-depth understanding, Visualization of Blooms Taxonomy for cognitive level accuracy distribution, Hallucination Score for quantifying inaccuracies, Knowledge Stratification Strategy for hierarchical analysis, and Machine Learning Models for Hierarchy Generation. Human Evaluation is highlighted for capturing nuances that automated metrics may miss. These techniques form a framework for evaluating LLMs, aiming to enhance transparency, guide development, and establish user trust. Future papers will describe metric visualization and demonstrate each approach on practical examples.},
	urldate = {2025-06-04},
	publisher = {arXiv},
	author = {Brown, Nik Bear},
	month = jun,
	year = {2024},
	note = {arXiv:2406.01943 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{awasthi_humanely_2023,
	title = {{HumanELY}: {Human} evaluation of {LLM} yield, using a novel web-based evaluation tool},
	copyright = {http://creativecommons.org/licenses/by-nd/4.0/},
	shorttitle = {{HumanELY}},
	url = {http://medrxiv.org/lookup/doi/10.1101/2023.12.22.23300458},
	doi = {10.1101/2023.12.22.23300458},
	abstract = {A
            bstract
          
          Large language models (LLMs) have caught the imagination of researchers,developers and public in general the world over with their potential for transformation. Vast amounts of research and development resources are being provided to implement these models in all facets of life. Trained using billions of parameters, various measures of their accuracy and performance have been proposed and used in recent times. While many of the automated natural language assessment parameters measure LLM output performance for use of language, contextual outputs are still hard to measure and quantify. Hence, human evaluation is still an important measure of LLM performance,even though it has been applied variably and inconsistently due to lack of guidance and resource limitations.
          To provide a structured way to perform comprehensive human evaluation of LLM output, we propose the first guidance and tool called HumanELY. Our approach and tool built using prior knowledge helps perform evaluation of LLM outputs in a comprehensive, consistent, measurable and comparable manner. HumanELY comprises of five key evaluation metrics: relevance, coverage, coherence, harm and comparison. Additional submetrics within these five key metrics provide for Likert scale based human evaluation of LLM outputs. Our related webtool uses this HumanELY guidance to enable LLM evaluation and provide data for comparison against different users performing human evaluation. While all metrics may not be relevant and pertinent to all outputs, it is important to assess and address their use.
          Lastly, we demonstrate comparison of metrics used in HumanELY against some of the recent publications in the healthcare domain. We focused on the healthcare domain due to the need to demonstrate highest levels of accuracy and lowest levels of harm in a comprehensive manner. We anticipate our guidance and tool to be used for any domain where LLMs find an use case.
          
            Link to the HumanELY Tool
            
              https://www.brainxai.com/humanely},
	language = {en},
	urldate = {2025-06-04},
	publisher = {Health Informatics},
	author = {Awasthi, Raghav and Mishra, Shreya and Mahapatra, Dwarikanath and Khanna, Ashish and Maheshwari, Kamal and Cywinski, Jacek and Papay, Frank and Mathur, Piyush},
	month = dec,
	year = {2023},
}

@misc{haag_training_2024,
	title = {Training {LLMs} for {Generating} {IEC} 61131-3 {Structured} {Text} with {Online} {Feedback}},
	url = {http://arxiv.org/abs/2410.22159},
	doi = {10.48550/arXiv.2410.22159},
	abstract = {IEC 61131-3 Structured Text (ST) is a widely used programming language for programmable logic controllers (PLCs) in automation systems. However, generating ST code with LLMs poses unique challenges due to limited data in public training datasets and the complexity of ST language syntax. This paper proposes an approach to fine-tune LLMs for the generation of ST code that leverages a preference-based learning method through an online process involving compiler feedback and evaluation from an LLM-based ST expert. In this framework, the model is iteratively refined and generates new training samples, which are subsequently evaluated by a compiler for syntactical correctness and by a specialized LLM that excels at assessing semantic accuracy, though it is not optimized for code generation itself. This approach results in marked improvements for the trained LLM, leading to higher compilation success rates and better semantic precision. As a result, the framework proves highly suitable for industrial automation applications and outperforms state-of-the-art models.},
	urldate = {2025-06-04},
	publisher = {arXiv},
	author = {Haag, Aaron and Fuchs, Bertram and Kacan, Altay and Lohse, Oliver},
	month = dec,
	year = {2024},
	note = {arXiv:2410.22159 [cs]},
	keywords = {Computer Science - Software Engineering},
}

@misc{steenhoek_reinforcement_2025,
	title = {Reinforcement {Learning} from {Automatic} {Feedback} for {High}-{Quality} {Unit} {Test} {Generation}},
	url = {http://arxiv.org/abs/2310.02368},
	doi = {10.48550/arXiv.2310.02368},
	abstract = {Software testing is a crucial aspect of software development, and the creation of high-quality tests that adhere to best practices is essential for effective maintenance. Recently, Large Language Models (LLMs) have gained popularity for code generation, including the automated creation of test cases. However, these LLMs are often trained on vast amounts of publicly available code, which may include test cases that do not adhere to best practices and may even contain test smells (anti-patterns). To address this issue, we propose a novel technique called Reinforcement Learning from Static Quality Metrics (RLSQM). To begin, we analyze the anti-patterns generated by the LLM and show that LLMs can generate undesirable test smells. Thus, we train specific reward models for each static quality metric, then utilize Proximal Policy Optimization (PPO) to train models for optimizing a single quality metric at a time. Furthermore, we amalgamate these rewards into a unified reward model aimed at capturing different best practices and quality aspects of tests. By comparing RL-trained models with those trained using supervised learning, we provide insights into how reliably utilize RL to improve test generation quality and into the effects of various training strategies. Our experimental results demonstrate that the RL-optimized model consistently generated high-quality test cases compared to the base LLM, improving the model by up to 21\%, and successfully generates nearly 100\% syntactically correct code. RLSQM also outperformed GPT-4 on four out of seven metrics. This represents a significant step towards enhancing the overall efficiency and reliability of software testing through Reinforcement Learning and static quality metrics. Our data are available at https://figshare.com/s/ded476c8d4c221222849.},
	urldate = {2025-06-04},
	publisher = {arXiv},
	author = {Steenhoek, Benjamin and Tufano, Michele and Sundaresan, Neel and Svyatkovskiy, Alexey},
	month = jan,
	year = {2025},
	note = {arXiv:2310.02368 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Software Engineering},
}

@misc{zhang_wider_2023,
	title = {Wider and {Deeper} {LLM} {Networks} are {Fairer} {LLM} {Evaluators}},
	url = {http://arxiv.org/abs/2308.01862},
	doi = {10.48550/arXiv.2308.01862},
	abstract = {Measuring the quality of responses generated by LLMs is a challenging task, particularly when it comes to evaluating whether the response is aligned with human preference. A novel approach involves using the LLM itself to make evaluation and stabilizing the results through multiple independent evaluations, similar to a single-layer narrow LLM network. This network consists of a fixed number of neurons, with each neuron being the same LLM. In this paper, we draw upon the extensive research on deep neural networks to explore whether deeper and wider networks can lead to fairer evaluations. Specifically, inspired by the observation that different neurons in a neural network are responsible for detecting different concepts, we first adaptively generate as many neuron roles as possible for each evaluation sample. Each perspective corresponds to the role of a specific LLM neuron in the first layer. In subsequent layers, we follow the idea that higher layers in deep networks are responsible for more comprehensive features, each layer receives representations from all neurons in the previous layer, integrating the locally learned evaluation information to obtain a more comprehensive evaluation result. Interestingly, this network design resembles the process of academic paper reviewing. To validate the effectiveness of our method, we construct the largest and most diverse English evaluation benchmark LLMEval\${\textasciicircum}2\$ for LLM evaluators, comprising 15 tasks, 8 abilities, and 2,553 samples. Experimental results demonstrate that a wider network (involving many reviewers) with 2 layers (one round of discussion) performs the best, improving kappa correlation coefficient from 0.28 to 0.34. We also leverage WideDeep to aid in the assessment of Chinese LLMs, which has accelerated the evaluation time by 4.6 times, resulting in a 60\% cost saving. WideDeep achieves a remarkable 93\% agreement level among humans.},
	urldate = {2025-06-04},
	publisher = {arXiv},
	author = {Zhang, Xinghua and Yu, Bowen and Yu, Haiyang and Lv, Yangyu and Liu, Tingwen and Huang, Fei and Xu, Hongbo and Li, Yongbin},
	month = aug,
	year = {2023},
	note = {arXiv:2308.01862 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@misc{yang_rl2_2024,
	title = {{RL2}: {Reinforce} {Large} {Language} {Model} to {Assist} {Safe} {Reinforcement} {Learning} for {Energy} {Management} of {Active} {Distribution} {Networks}},
	shorttitle = {{RL2}},
	url = {http://arxiv.org/abs/2412.01303},
	doi = {10.48550/arXiv.2412.01303},
	abstract = {As large-scale distributed energy resources are integrated into the active distribution networks (ADNs), effective energy management in ADNs becomes increasingly prominent compared to traditional distribution networks. Although advanced reinforcement learning (RL) methods, which alleviate the burden of complicated modelling and optimization, have greatly improved the efficiency of energy management in ADNs, safety becomes a critical concern for RL applications in real-world problems. Since the design and adjustment of penalty functions, which correspond to operational safety constraints, requires extensive domain knowledge in RL and power system operation, the emerging ADN operators call for a more flexible and customized approach to address the penalty functions so that the operational safety and efficiency can be further enhanced. Empowered with strong comprehension, reasoning, and in-context learning capabilities, large language models (LLMs) provide a promising way to assist safe RL for energy management in ADNs. In this paper, we introduce the LLM to comprehend operational safety requirements in ADNs and generate corresponding penalty functions. In addition, we propose an RL2 mechanism to refine the generated functions iteratively and adaptively through multi-round dialogues, in which the LLM agent adjusts the functions' pattern and parameters based on training and test performance of the downstream RL agent. The proposed method significantly reduces the intervention of the ADN operators. Comprehensive test results demonstrate the effectiveness of the proposed method.},
	urldate = {2025-06-04},
	publisher = {arXiv},
	author = {Yang, Xu and Lin, Chenhui and Liu, Haotian and Wu, Wenchuan},
	month = dec,
	year = {2024},
	note = {arXiv:2412.01303 [eess]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Systems and Control, Electrical Engineering and Systems Science - Systems and Control},
}

@article{al-turki_human---loop_2024,
	title = {Human-in-the-{Loop} {Learning} with {LLMs} for {Efficient} {RASE} {Tagging} in {Building} {Compliance} {Regulations}},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10778545/},
	doi = {10.1109/ACCESS.2024.3512434},
	urldate = {2025-06-04},
	journal = {IEEE Access},
	author = {Al-Turki, Dhoyazan and Hettiarachchi, Hansi and Gaber, Mohamed Medhat and Abdelsamea, Mohammed M. and Basurra, Shadi and Iranmanesh, Sima and Saadany, Hadeel and Vakaj, Edlira},
	year = {2024},
	pages = {1--1},
}

@misc{vasilatos_llmpot_2025,
	title = {{LLMPot}: {Dynamically} {Configured} {LLM}-based {Honeypot} for {Industrial} {Protocol} and {Physical} {Process} {Emulation}},
	shorttitle = {{LLMPot}},
	url = {http://arxiv.org/abs/2405.05999},
	doi = {10.48550/arXiv.2405.05999},
	abstract = {Industrial Control Systems (ICS) are extensively used in critical infrastructures ensuring efficient, reliable, and continuous operations. However, their increasing connectivity and addition of advanced features make them vulnerable to cyber threats, potentially leading to severe disruptions in essential services. In this context, honeypots play a vital role by acting as decoy targets within ICS networks, or on the Internet, helping to detect, log, analyze, and develop mitigations for ICS-specific cyber threats. Deploying ICS honeypots, however, is challenging due to the necessity of accurately replicating industrial protocols and device characteristics, a crucial requirement for effectively mimicking the unique operational behavior of different industrial systems. Moreover, this challenge is compounded by the significant manual effort required in also mimicking the control logic the PLC would execute, in order to capture attacker traffic aiming to disrupt critical infrastructure operations. In this paper, we propose LLMPot, a novel approach for designing honeypots in ICS networks harnessing the potency of Large Language Models (LLMs). LLMPot aims to automate and optimize the creation of realistic honeypots with vendor-agnostic configurations, and for any control logic, aiming to eliminate the manual effort and specialized knowledge traditionally required in this domain. We conducted extensive experiments focusing on a wide array of parameters, demonstrating that our LLM-based approach can effectively create honeypot devices implementing different industrial protocols and diverse control logic.},
	urldate = {2025-06-03},
	publisher = {arXiv},
	author = {Vasilatos, Christoforos and Mahboobeh, Dunia J. and Lamri, Hithem and Alam, Manaar and Maniatakos, Michail},
	month = may,
	year = {2025},
	note = {arXiv:2405.05999 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@misc{koziolek_llm-based_2023,
	title = {{LLM}-based {Control} {Code} {Generation} using {Image} {Recognition}},
	url = {http://arxiv.org/abs/2311.10401},
	doi = {10.48550/arXiv.2311.10401},
	abstract = {LLM-based code generation could save significant manual efforts in industrial automation, where control engineers manually produce control logic for sophisticated production processes. Previous attempts in control logic code generation lacked methods to interpret schematic drawings from process engineers. Recent LLMs now combine image recognition, trained domain knowledge, and coding skills. We propose a novel LLM-based code generation method that generates IEC 61131-3 Structure Text control logic source code from Piping-and-Instrumentation Diagrams (P\&IDs) using image recognition. We have evaluated the method in three case study with industrial P\&IDs and provide first evidence on the feasibility of such a code generation besides experiences on image recognition glitches.},
	urldate = {2025-06-03},
	publisher = {arXiv},
	author = {Koziolek, Heiko and Koziolek, Anne},
	month = nov,
	year = {2023},
	note = {arXiv:2311.10401 [cs]},
	keywords = {Computer Science - Software Engineering},
}

@article{huang_physics_2024,
	title = {Physics and {Data} {Collaborative} {Root} {Cause} {Analysis}: {Integrating} {Pretrained} {Large} {Language} {Models} and {Data}-{Driven} {AI} for {Trustworthy} {Asset} {Health} {Management}},
	volume = {16},
	copyright = {http://creativecommons.org/licenses/by/3.0/us/},
	issn = {2325-0178, 2325-0178},
	shorttitle = {Physics and {Data} {Collaborative} {Root} {Cause} {Analysis}},
	url = {http://www.papers.phmsociety.org/index.php/phmconf/article/view/3881},
	doi = {10.36001/phmconf.2024.v16i1.3881},
	abstract = {Data-driven tools for asset health management face significant challenges, including a lack of understanding of physical principles, difficulty incorporating domain experts’ experiences, and consequently low detection accuracy, leading to trustworthiness issues. Automatically integrating data-driven analysis with human knowledge and experience, as found in literature and maintenance logs, is critically needed. Recent progress in large language models (LLMs) offers opportunities to achieve this goal. However, there is still a lack of work that effectively combines pretrained LLMs with data-driven models for asset health management using industrial time series data as input. This paper presents a framework that integrates our recently proposed data-driven AI with pretrained LLMs to address root cause detection in industrial failure analysis. The framework employs LLMs to analyze outputs from our data-driven root cause analysis models, filtering out less relevant results and prioritizing those that align closely with physical principles and domain expertise. Our innovative approach leverages advanced data-driven analytics and a multi-LLM debate for collaborative decision-making, seamlessly merging data-driven insights with domain knowledge. Specifically, through our proposed self-exclusionary debates among multiple LLMs, biases inherent in single-LLM systems are effectively mitigated, enhancing reliability and stability. Crucially, the framework bridges the gap between data-driven models and physics-informed LLMs, accelerating the interaction between data and knowledge for more informed and realistic decision-making processes.},
	number = {1},
	urldate = {2025-06-03},
	journal = {Annual Conference of the PHM Society},
	author = {Huang, Hao and Shah, Tapan and Karigiannis, John and Evans, Scott},
	month = nov,
	year = {2024},
}

@article{xie_knowledge_2024,
	title = {Knowledge {Graph}-{Based} {In}-{Context} {Learning} for {Advanced} {Fault} {Diagnosis} in {Sensor} {Networks}},
	volume = {24},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/24/24/8086},
	doi = {10.3390/s24248086},
	abstract = {This paper introduces a novel approach for enhancing fault diagnosis in industrial equipment systems through the application of sensor network-driven knowledge graph-based in-context learning (KG-ICL). By focusing on the critical role of sensor data in detecting and isolating faults, we construct a domain-specific knowledge graph (DSKG) that encapsulates expert knowledge relevant to industrial equipment. Utilizing a long-length entity similarity (LES) measure, we retrieve relevant information from the DSKG. Our method leverages large language models (LLMs) to conduct causal analysis on textual data related to equipment faults derived from sensor networks, thereby significantly enhancing the accuracy and efficiency of fault diagnosis. This paper details a series of experiments that validate the effectiveness of the KG-ICL method in accurately diagnosing fault causes and locations of industrial equipment systems. By leveraging LLMs and structured knowledge, our approach offers a robust tool for condition monitoring and fault management, thereby improving the reliability and efficiency of operations in industrial sectors.},
	language = {en},
	number = {24},
	urldate = {2025-06-03},
	journal = {Sensors},
	author = {Xie, Xin and Wang, Junbo and Han, Yu and Li, Wenjuan},
	month = dec,
	year = {2024},
	pages = {8086},
}

@misc{srinivas_knowledge_2024,
	title = {Knowledge {Graph} {Modeling}-{Driven} {Large} {Language} {Model} {Operating} {System} ({LLM} {OS}) for {Task} {Automation} in {Process} {Engineering} {Problem}-{Solving}},
	copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International},
	url = {https://arxiv.org/abs/2408.14494},
	doi = {10.48550/ARXIV.2408.14494},
	abstract = {We present the Process Engineering Operations Assistant (PEOA), an AI-driven framework designed to solve complex problems in the chemical and process industries. The framework employs a modular architecture orchestrated by a meta-agent, which serves as the central coordinator, managing an action generator and instruction-tuned small-scale language models (expert models). The action generator decomposes complex problems into sub-tasks and identifies suitable expert models to execute each, delivering precise solutions for multi-step problem-solving. Key techniques include advanced knowledge modeling using property graphs for improved information retrieval, facilitating more accurate and contextually relevant solutions. Additionally, the framework utilizes a teacher-student transfer-learning approach with GPT-4 (Omni) to fine-tune the action generator and expert models for domain adaptation, alongside an iterative problem-solving mechanism with sophisticated error handling. Custom datasets were developed to evaluate the framework against leading proprietary language models on various engineering tasks. The results demonstrate the framework effectiveness in automating calculations, accelerating prototyping, and providing AI-augmented decision support for industrial processes, marking a significant advancement in process engineering capabilities.},
	urldate = {2025-06-03},
	publisher = {arXiv},
	author = {Srinivas, Sakhinana Sagar and Vaikunth, Vijay Sri and Runkana, Venkataramana},
	year = {2024},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@inproceedings{tan_large_2024,
	address = {Tokyo, Japan},
	title = {Large {Language} {Model} based {Framework} for {Secure} {Operation} of {Power} {Systems}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-5320-4},
	url = {https://ieeexplore.ieee.org/document/10808693/},
	doi = {10.1109/PSET62496.2024.10808693},
	urldate = {2025-06-03},
	booktitle = {2024 3rd {International} {Conference} on {Power} {Systems} and {Electrical} {Technology} ({PSET})},
	publisher = {IEEE},
	author = {Tan, Ling and Xiang, Yue and Tang, Binhua and Li, Haoxuan and Du, Zequan and Lu, Yida and Ma, Huangqi and Xi, Zirui and Yang, Jianping and Wang, Shiqian and Li, Lingtao},
	month = aug,
	year = {2024},
	pages = {695--699},
}

@article{deng_prediction_2024,
	title = {From {Prediction} to {Prescription}: {Large} {Language} {Model} {Agent} for {Context}-{Aware} {Maintenance} {Decision} {Support}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/us/},
	issn = {2325-016X, 2325-016X},
	shorttitle = {From {Prediction} to {Prescription}},
	url = {https://papers.phmsociety.org/index.php/phme/article/view/4114},
	doi = {10.36001/phme.2024.v8i1.4114},
	abstract = {Predictive analytics with machine learning approaches has widely penetrated and shown great success in system health management over the decade. However, how to convert the prediction to an actionable plan for maintenance is still far from mature. This study investigates how to narrow the gapbetween predictive outcomes and prescriptive descriptions for system maintenance using an agentic approach based on the large language model (LLM). Additionally, with the retrieval-augmented generation (RAG) technique and tool usage capability, the LLM can be context-aware when making decisions in maintenance strategy proposals considering predictions from machine learning. In this way, the proposed method can push forward the boundary of current machine-learning methods from a predictor to an advisor for decision-making workload offload. For verification, a case study on linear actuator fault diagnosis is conducted with the GPT-4 model. The result demonstrates that the proposed method can perform fault detection without extra training or fine-tuning with comparable performance to baseline methods and deliver more informatic diagnosis analysis and suggestions. This research can shed light on the application of large language models in the construction of versatile and flexible artificial intelligence agents for maintenance tasks.},
	number = {1},
	urldate = {2025-06-03},
	journal = {PHM Society European Conference},
	author = {Deng, Haoxuan and Namoano, Bernadin and Zheng, Bohao and Khan, Samir and Ahmet Erkoyuncu, John},
	month = jun,
	year = {2024},
	pages = {10},
}

@misc{dave_integrating_2024,
	title = {Integrating {LLMs} for {Explainable} {Fault} {Diagnosis} in {Complex} {Systems}},
	copyright = {arXiv.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2402.06695},
	doi = {10.48550/ARXIV.2402.06695},
	abstract = {This paper introduces an integrated system designed to enhance the explainability of fault diagnostics in complex systems, such as nuclear power plants, where operator understanding is critical for informed decision-making. By combining a physics-based diagnostic tool with a Large Language Model, we offer a novel solution that not only identifies faults but also provides clear, understandable explanations of their causes and implications. The system's efficacy is demonstrated through application to a molten salt facility, showcasing its ability to elucidate the connections between diagnosed faults and sensor data, answer operator queries, and evaluate historical sensor anomalies. Our approach underscores the importance of merging model-based diagnostics with advanced AI to improve the reliability and transparency of autonomous systems.},
	urldate = {2025-06-03},
	publisher = {arXiv},
	author = {Dave, Akshay J. and Nguyen, Tat Nghia and Vilim, Richard B.},
	year = {2024},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, Machine Learning (cs.LG), Systems and Control (eess.SY)},
}

@inproceedings{reddicharla_innovating_2024,
	address = {Abu Dhabi, UAE},
	title = {Innovating {Oil} and {Gas} {Field} {Operations} - {Harnessing} the {Power} of {Generative} {Ai} for {Supporting} {Workforce} {Towards} {Achieving} {Autonomous} {Operations}},
	url = {https://onepetro.org/SPEADIP/proceedings/24ADIP/24ADIP/D011S020R005/585634},
	doi = {10.2118/222046-MS},
	abstract = {Abstract
            In today's dynamic and competitive oil and gas industry, the integration of Artificial Intelligence (AI) has emerged as a game-changer, offering unparalleled opportunities for optimization, cost reduction, and operational excellence. The main objective of autonomous operations is to minimize manual interactions and maximize self-directed plant operations. ADNOC Onshore has implemented generative AI agents in daily maintenance and production operations to boost workforce productivity in the journey of achieving autonomous operations. This paper explains the use cases, challenges, AI architecture \& data security in deployment.
            Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. GPT-4 Turbo is a large multimodal model (accepting text or image inputs and generating text) that can solve difficult problems with greater accuracy and advanced reasoning capabilities. The scope includes empowering reliability, maintenance, and operations professionals to draw insights from equipment manuals, asset operating manuals and operating procedures, maintenance records, and safety \& integrity manuals. This in-house solution with support across structured and unstructured data, an LLM-agnostic architecture, deterministic responses with source references, and granular access controls. The solution has been integrated ERP SAP system and sensor time series PI system, data historians for integrated context. A unique automated contextualization engine has been used based on oil and gas specific vocabulary to bring context to their operations. A conversational interactive agent has been built for user interactions.
            The maintenance and operations engineer can receive suggestions on the proper steps to identify the root cause based on OEM product manuals, previous events, and current performance. This Generative AI solution accelerates time to insight for operators by equipping teams to streamline maintenance operations and Investigate maintenance records with generative AI to troubleshoot operations challenges more efficiently. The internal study showed that operational productivity has increased by 20\% after this solution's implementation. For the model to understand industrial environments, it would require retraining the model on industrial data. Using existing models on uncontextualized, unstructured industrial data significantly increases the risk of incorrect and untrustworthy answers – referred to as AI hallucinations. Another significant challenge lies in the dependence on the quality and quantity of available data for training. AI models require extensive and representative datasets to produce accurate and reliable predictions.
            Large language models are a type of artificial intelligence (AI) model designed to understand and generate human language. These models are built upon deep learning architectures, particularly transformer architectures. Generative AI can play a significant role in oil and gas asset operations towards the goal of achieving autonomous operations.},
	urldate = {2025-06-03},
	booktitle = {{ADIPEC}},
	publisher = {SPE},
	author = {Reddicharla, Nagaraju and Ali, Mayada Sultan},
	month = nov,
	year = {2024},
	pages = {D011S020R005},
}

@misc{tong_soft_2025,
	title = {A {Soft} {Sensor} {Method} with {Uncertainty}-{Awareness} and {Self}-{Explanation} {Based} on {Large} {Language} {Models} {Enhanced} by {Domain} {Knowledge} {Retrieval}},
	url = {http://arxiv.org/abs/2501.03295},
	doi = {10.48550/arXiv.2501.03295},
	abstract = {Data-driven soft sensors are crucial in predicting key performance indicators in industrial systems. However, current methods predominantly rely on the supervised learning paradigms of parameter updating, which inherently faces challenges such as high development costs, poor robustness, training instability, and lack of interpretability. Recently, large language models (LLMs) have demonstrated significant potential across various domains, notably through In-Context Learning (ICL), which enables high-performance task execution with minimal input-label demonstrations and no prior training. This paper aims to replace supervised learning with the emerging ICL paradigm for soft sensor modeling to address existing challenges and explore new avenues for advancement. To achieve this, we propose a novel framework called the Few-shot Uncertainty-aware and self-Explaining Soft Sensor (LLM-FUESS), which includes the Zero-shot Auxiliary Variable Selector (LLM-ZAVS) and the Uncertainty-aware Few-shot Soft Sensor (LLM-UFSS). The LLM-ZAVS retrieves from the Industrial Knowledge Vector Storage to enhance LLMs' domain-specific knowledge, enabling zero-shot auxiliary variable selection. In the LLM-UFSS, we utilize text-based context demonstrations of structured data to prompt LLMs to execute ICL for predicting and propose a context sample retrieval augmentation strategy to improve performance. Additionally, we explored LLMs' AIGC and probabilistic characteristics to propose self-explanation and uncertainty quantification methods for constructing a trustworthy soft sensor. Extensive experiments demonstrate that our method achieved state-of-the-art predictive performance, strong robustness, and flexibility, effectively mitigates training instability found in traditional methods. To the best of our knowledge, this is the first work to establish soft sensor utilizing LLMs.},
	urldate = {2025-06-03},
	publisher = {arXiv},
	author = {Tong, Shuo and Liu, Han and Guo, Runyuan and Wang, Wenqing and Tian, Xueqiong and Wei, Lingyun and Zhang, Lin and Wu, Huayong and Liu, Ding and Zhang, Youmin},
	month = jan,
	year = {2025},
	note = {arXiv:2501.03295 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Signal Processing},
}

@inproceedings{lee_retrieving_2024,
	address = {Abu Dhabi, UAE},
	title = {Retrieving {Operation} {Insights} with {GenAI} {LLM}: {Comparative} {Analysis} and {Workflow} {Enhancement}},
	shorttitle = {Retrieving {Operation} {Insights} with {GenAI} {LLM}},
	url = {https://onepetro.org/SPEADIP/proceedings/24ADIP/24ADIP/D011S020R004/585552},
	doi = {10.2118/222023-MS},
	abstract = {Abstract
            Identifying drilling risks for upcoming wells demands insights from offset wells. While some risks may lead to non-productive time (NPT), others remain latent within daily drilling reports (DDRs), which is crucial for comprehensive analysis. Manual extraction from DDRs is often time-consuming. In this paper, we systematically explore the methods to leverage the Large Language Models (LLMs) with enhanced workflows to automate insights extraction and improve risk identification accuracy. We compared LLMs customization approaches and state-of-the-art NLP models to validate LLMs efficiency in the drilling domain. We show that the adaptation of prompt optimization, Retrieval Augmented Generation (RAG) with the pre-trained LLMs before fine-tuning the model, already shows a significant improvement, achieving an accuracy ranging from 80-85\%, with precision and recall surging from less than 50\%, as observed from our benchmark oil and gas finetuned GPT-2 model (Marlot et al., 2023), to over 70\% with our customized model. We addressed the challenge of imbalance training examples during the finetuning of the state-of-the-art GPT-2 model, which caused the underperformance of the benchmark model, particularly in addressing rare drilling event classes.
            This paper demonstrates LLMs able to improve the generalization and reliability of the imbalance drilling risks, with proper workflow enhancements. Subsequently, we also finetuned both on-premises LLMs (Llama2, Llama3, Mistral), and cloud LLM GPT-3.5 Turbo, which exhibits promising outcomes, achieving better performance to over 90\% accuracy, and over 80\% precision and recall, compared to the earlier approach using prompt and RAG. This paper contributes to advancing the application of LLMs in the oil and gas industry, for domain-specific tasks, addressing the common challenge of imbalance operation training data, and demonstrating our enhanced workflow outperforms both the benchmark finetuned GPT-2 model, pretrained GPT-4 model, and the finetuned GPT-3.5 Turbo.},
	urldate = {2025-06-03},
	booktitle = {{ADIPEC}},
	publisher = {SPE},
	author = {Lee, M. X. and Wang, Z.},
	month = nov,
	year = {2024},
	pages = {D011S020R004},
}

@inproceedings{vidyaratne_generating_2024,
	address = {Spokane, WA, USA},
	title = {Generating {Troubleshooting} {Trees} for {Industrial} {Equipment} using {Large} {Language} {Models} ({LLM})},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-7447-6},
	url = {https://ieeexplore.ieee.org/document/10626823/},
	doi = {10.1109/ICPHM61352.2024.10626823},
	urldate = {2025-06-03},
	booktitle = {2024 {IEEE} {International} {Conference} on {Prognostics} and {Health} {Management} ({ICPHM})},
	publisher = {IEEE},
	author = {Vidyaratne, Lasitha and Lee, Xian Yeow and Kumar, Aman and Watanabe, Tsubasa and Farahat, Ahmed and Gupta, Chetan},
	month = jun,
	year = {2024},
	pages = {116--125},
}

@inproceedings{schoch_engineering_2024,
	address = {Padova, Italy},
	title = {Engineering {Data} {Funnel} ({WIP}) – {An} {Ontology}-{Enhanced} {LLM}-{Based} {Agent} and {MoE} {System} for {Engineering} {Data} {Processing}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {979-8-3503-6123-0},
	url = {https://ieeexplore.ieee.org/document/10710789/},
	doi = {10.1109/ETFA61755.2024.10710789},
	urldate = {2025-06-03},
	booktitle = {2024 {IEEE} 29th {International} {Conference} on {Emerging} {Technologies} and {Factory} {Automation} ({ETFA})},
	publisher = {IEEE},
	author = {Schoch, Nicolai and Hoernicke, Mario and Strem, Nika and Stark, Katharina},
	month = sep,
	year = {2024},
	pages = {1--5},
}

@inproceedings{rai_generative_2024,
	address = {Abu Dhabi, UAE},
	title = {Generative {AI} and {Large} {Language} {Model} {Assisted} {Causal} {Discovery} and {Inference} for {Driving} {Process} {Improvements}},
	url = {https://onepetro.org/SPEADIP/proceedings/24ADIP/24ADIP/D011S008R003/585031},
	doi = {10.2118/221872-MS},
	abstract = {Data-driven process management coupled with machine learning have been successful in driving commercial value to oil and gas operators by offering insights into process disruptions and their root causes. One frequently used approach is to analyze causes of process disruptions exclusively from historical data. In general, specific insights in the form of high correlation between certain process performance indicators and a well-defined measure of production inefficiency is often confounded as responsible causal factors. While this may yield some insights, the complexity of processes, measured in terms of number of entities involved and their interrelationships, requires a more nuanced approach that must include the context of the specific process. Thus, data analysis must be augmented with significant inputs from experts. Causal Inference provides a conceptual framework and tools for doing such analysis.
            In causal analysis, we embed this specific knowledge of subject matter experts using causal graphs consisting of process features (nodes) and their dependency (directed edges). For complex processes however, constructing causal graphs could be non-trivial due to ambiguity over which nodes to include and the plausible direction of their relationships. With the advent of foundational Large Language Models (LLM), there is an opportunity to mitigate this problem by utilizing the enormous information it encodes. Tools and technologies now exist to customize the response of LLM using retrieval of information from a corpus of specific high-quality knowledge in the form of related literature and data. It can therefore be used to assist the domain expert in building and finetuning the causal graph, and in simpler cases, can completely automate this step.
            In this work, we propose a two-step approach to combine the power of LLMs and Causal Analysis for analyzing inefficiencies in production processes. In the first step, we implement a Retrieval Augmented Generation (RAG) enhanced LLM prompting on a curated dataset designed to answer specific questions on relationship between process performance indicators. The outcome of this step is a directed acyclic graph encoding dependency of process performance indicators. Domain experts can validate or potentially refine the LLM-generated causal graph based on their domain knowledge for eliminating spurious hallucinations. In the second step, we use an appropriate causal inference method on the refined causal diagram and historical production data to estimate the causal effect of process variable contributing to disruptions or inefficiencies. Thus, by combining human expertise with machine learning, this framework offers a comprehensive approach for optimizing production processes.},
	urldate = {2025-06-03},
	booktitle = {{ADIPEC}},
	publisher = {SPE},
	author = {Rai, P. and Jain, A. and Anand, A.},
	month = nov,
	year = {2024},
	pages = {D011S008R003},
}

@inproceedings{sun_root_2024,
	address = {Kunming, China},
	title = {Root {Cause} {Analysis} for {Industrial} {Process} {Anomalies} through the {Integration} of {Knowledge} {Graph} and {Large} {Language} {Model}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {978-988-75815-8-1},
	url = {https://ieeexplore.ieee.org/document/10662704/},
	doi = {10.23919/CCC63176.2024.10662704},
	urldate = {2025-06-03},
	booktitle = {2024 43rd {Chinese} {Control} {Conference} ({CCC})},
	publisher = {IEEE},
	author = {Sun, Qi and Li, Yahui and Zhou, Chunjie and Tian, Yu-Chu},
	month = jul,
	year = {2024},
	pages = {6855--6860},
}

@inproceedings{koziolek_llm-based_2024,
	address = {Lisbon Portugal},
	title = {{LLM}-based and {Retrieval}-{Augmented} {Control} {Code} {Generation}},
	isbn = {979-8-4007-0579-3},
	url = {https://dl.acm.org/doi/10.1145/3643795.3648384},
	doi = {10.1145/3643795.3648384},
	language = {en},
	urldate = {2025-06-02},
	booktitle = {Proceedings of the 1st {International} {Workshop} on {Large} {Language} {Models} for {Code}},
	publisher = {ACM},
	author = {Koziolek, Heiko and Grüner, Sten and Hark, Rhaban and Ashiwal, Virendra and Linsbauer, Sofia and Eskandani, Nafise},
	month = apr,
	year = {2024},
	pages = {22--29},
}

@misc{qaid_fd-llm_2024,
	title = {{FD}-{LLM}: {Large} {Language} {Model} for {Fault} {Diagnosis} of {Machines}},
	copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
	shorttitle = {{FD}-{LLM}},
	url = {https://arxiv.org/abs/2412.01218},
	doi = {10.48550/ARXIV.2412.01218},
	abstract = {Large language models (LLMs) are effective at capturing complex, valuable conceptual representations from textual data for a wide range of real-world applications. However, in fields like Intelligent Fault Diagnosis (IFD), incorporating additional sensor data-such as vibration signals, temperature readings, and operational metrics-is essential but it is challenging to capture such sensor data information within traditional text corpora. This study introduces a novel IFD approach by effectively adapting LLMs to numerical data inputs for identifying various machine faults from time-series sensor data. We propose FD-LLM, an LLM framework specifically designed for fault diagnosis by formulating the training of the LLM as a multi-class classification problem. We explore two methods for encoding vibration signals: the first method uses a string-based tokenization technique to encode vibration signals into text representations, while the second extracts statistical features from both the time and frequency domains as statistical summaries of each signal. We assess the fault diagnosis capabilities of four open-sourced LLMs based on the FD-LLM framework, and evaluate the models' adaptability and generalizability under various operational conditions and machine components, namely for traditional fault diagnosis, cross-operational conditions, and cross-machine component settings. Our results show that LLMs such as Llama3 and Llama3-instruct demonstrate strong fault detection capabilities and significant adaptability across different operational conditions, outperforming state-of-the-art deep learning (DL) approaches in many cases.},
	urldate = {2025-06-02},
	publisher = {arXiv},
	author = {Qaid, Hamzah A. A. M. and Zhang, Bo and Li, Dan and Ng, See-Kiong and Li, Wei},
	year = {2024},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.AI), FOS: Computer and information sciences, Machine Learning (cs.LG)},
}

@inproceedings{yi_applications_2024,
	address = {Galveston, Texas, USA},
	title = {Applications of {Large} {Language} {Models} in {Well} {Construction} {Planning} and {Real}-{Time} {Operation}},
	url = {https://onepetro.org/SPEDC/proceedings/24DC/24DC/D021S014R003/542888},
	doi = {10.2118/217700-MS},
	abstract = {Abstract
            In today's well construction operations, a substantial volume of data is generated and stored across multiple databases. The primary objective being to use them as a guide for future well construction optimization. However, much of this data gets lost in computer storage, and appropriate information is difficult to find at the right time. This paper shows the results of deploying a generative pre-trained transformer (GPT) large language model on an operator's dataset to alleviate this problem.
            The process starts with gathering all relevant data into a common database. In this case, the dataset included sensor data, processed data, morning reports, end of well reports, after-action reviews of non-productive times, bit forensics data and publicly available data from wells drilled by other operators. The files were pre-processed, and metadata was added appropriately to ensure appropriate indexing and training of the information. This data is then fed to the cloud platform on which the model is learnt. The model is then integrated into the data platform so that the end users can pose queries.
            The dataset consisted of more than 200 wells of the operator in a region that the operator is actively drilling. Data curation was a time-consuming task that had to be performed to ensure only quality and organized information was fed to the model. Documents containing well construction related subject matter were also used in the training to provide the end user assistance with core concepts. During the test stage, a multitude of questions were posed to the platform, including questions such as: What happened the last time there was a stuck pipe in this region? What is the best ROP that could be attained in the lateral section? Significant time savings were recorded due to the ease with which information could be retrieved. A big concern was the potential for wrongs answers being provided to the questions. To alleviate this concern, all answers were accompanied by references found in the database, to give the person reviewing the answers confidence in the answers.
            This paper introduces the benefits that large language models (LLMs) bring to both well planning and real-time operations. LLM offers the capability to be able to retrieve information extremely quickly and provide answers in a conversational format to user questions. This paper also provides recommendations to the industry and details some of the challenges to adopting LLMs.},
	urldate = {2025-06-02},
	booktitle = {{IADC}/{SPE} {International} {Drilling} {Conference} and {Exhibition}},
	publisher = {SPE},
	author = {Yi, Michael and Ceglinski, Kamil and Ashok, Pradeepkumar and Behounek, Michael and White, Spencer and Peroyea, Trey and Thetford, Taylor},
	month = feb,
	year = {2024},
	pages = {D021S014R003},
}

@misc{long_llm-tabflow_2025,
	title = {{LLM}-{TabFlow}: {Synthetic} {Tabular} {Data} {Generation} with {Inter}-column {Logical} {Relationship} {Preservation}},
	shorttitle = {{LLM}-{TabFlow}},
	url = {http://arxiv.org/abs/2503.02161},
	doi = {10.48550/arXiv.2503.02161},
	abstract = {Synthetic tabular data have widespread applications in industrial domains such as healthcare, finance, and supply chains, owing to their potential to protect privacy and mitigate data scarcity. However, generating realistic synthetic tabular data while preserving inter-column logical relationships remains a significant challenge for the existing generative models. To address these challenges, we propose LLM-TabFlow, a novel approach that leverages Large Language Model (LLM) reasoning to capture complex inter-column relationships and compress tabular data, while using Score-based Diffusion to model the distribution of the compressed data in latent space. Additionally, we introduce an evaluation framework, which is absent in literature, to fairly assess the performance of synthetic tabular data generation methods in real-world contexts. Using this framework, we conduct extensive experiments on two real-world industrial datasets, evaluating LLM-TabFlow against other five baseline methods, including SMOTE (an interpolation-based approach) and other state-of-the-art generative models. Our results show that LLM-TabFlow outperforms all baselines, fully preserving inter-column relationships while achieving the best balance between data fidelity, utility, and privacy. This study is the first to explicitly address inter-column relationship preservation in synthetic tabular data generation, offering new insights for developing more realistic and reliable tabular data generation methods.},
	urldate = {2025-06-02},
	publisher = {arXiv},
	author = {Long, Yunbo and Xu, Liming and Brintrup, Alexandra},
	month = mar,
	year = {2025},
	note = {arXiv:2503.02161 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{zoller_automated_2023,
	title = {Automated {Machine} {Learning} for {Remaining} {Useful} {Life} {Predictions}},
	url = {http://arxiv.org/abs/2306.12215},
	doi = {10.1109/SMC53992.2023.10394031},
	abstract = {Being able to predict the remaining useful life (RUL) of an engineering system is an important task in prognostics and health management. Recently, data-driven approaches to RUL predictions are becoming prevalent over model-based approaches since no underlying physical knowledge of the engineering system is required. Yet, this just replaces required expertise of the underlying physics with machine learning (ML) expertise, which is often also not available. Automated machine learning (AutoML) promises to build end-to-end ML pipelines automatically enabling domain experts without ML expertise to create their own models. This paper introduces AutoRUL, an AutoML-driven end-to-end approach for automatic RUL predictions. AutoRUL combines fine-tuned standard regression methods to an ensemble with high predictive power. By evaluating the proposed method on eight real-world and synthetic datasets against state-of-the-art hand-crafted models, we show that AutoML provides a viable alternative to hand-crafted data-driven RUL predictions. Consequently, creating RUL predictions can be made more accessible for domain experts using AutoML by eliminating ML expertise from data-driven model construction.},
	urldate = {2025-06-02},
	booktitle = {2023 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {Zöller, Marc-André and Mauthe, Fabian and Zeiler, Peter and Lindauer, Marius and Huber, Marco F.},
	month = oct,
	year = {2023},
	note = {arXiv:2306.12215 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	pages = {2907--2912},
}

@misc{lee_timecap_2025,
	title = {{TimeCAP}: {Learning} to {Contextualize}, {Augment}, and {Predict} {Time} {Series} {Events} with {Large} {Language} {Model} {Agents}},
	shorttitle = {{TimeCAP}},
	url = {http://arxiv.org/abs/2502.11418},
	doi = {10.48550/arXiv.2502.11418},
	abstract = {Time series data is essential in various applications, including climate modeling, healthcare monitoring, and financial analytics. Understanding the contextual information associated with real-world time series data is often essential for accurate and reliable event predictions. In this paper, we introduce TimeCAP, a time-series processing framework that creatively employs Large Language Models (LLMs) as contextualizers of time series data, extending their typical usage as predictors. TimeCAP incorporates two independent LLM agents: one generates a textual summary capturing the context of the time series, while the other uses this enriched summary to make more informed predictions. In addition, TimeCAP employs a multi-modal encoder that synergizes with the LLM agents, enhancing predictive performance through mutual augmentation of inputs with in-context examples. Experimental results on real-world datasets demonstrate that TimeCAP outperforms state-of-the-art methods for time series event prediction, including those utilizing LLMs as predictors, achieving an average improvement of 28.75\% in F1 score.},
	urldate = {2025-06-02},
	publisher = {arXiv},
	author = {Lee, Geon and Yu, Wenchao and Shin, Kijung and Cheng, Wei and Chen, Haifeng},
	month = mar,
	year = {2025},
	note = {arXiv:2502.11418 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{tang_time_2025,
	title = {Time {Series} {Forecasting} with {LLMs}: {Understanding} and {Enhancing} {Model} {Capabilities}},
	volume = {26},
	issn = {1931-0145, 1931-0153},
	shorttitle = {Time {Series} {Forecasting} with {LLMs}},
	url = {https://dl.acm.org/doi/10.1145/3715073.3715083},
	doi = {10.1145/3715073.3715083},
	abstract = {Large language models (LLMs) have been applied in many fields and have developed rapidly in recent years. As a classic machine learning task, time series forecasting has recently been boosted by LLMs. Recent works treat large language models as zero-shot time series reasoners without further fine-tuning, which achieves remarkable performance. However, some unexplored research problems exist when applying LLMs for time series forecasting under the zero-shot setting. For instance, the LLMs' preferences for the input time series are less understood. In this paper, by comparing LLMs with traditional time series forecasting models, we observe many interesting properties of LLMs in the context of time series forecasting. First, our study shows that LLMs perform well in predicting time series with clear patterns and trends but face challenges with datasets lacking periodicity. This observation can be explained by the ability of LLMs to recognize the underlying period within datasets, which is supported by our experiments. In addition, the input strategy is investigated, and it is found that incorporating external knowledge and adopting natural language paraphrases substantially improves the predictive performance of LLMs for time series. Our study contributes insight into LLMs' advantages and limitations in time series forecasting under different conditions.},
	language = {en},
	number = {2},
	urldate = {2025-06-02},
	journal = {ACM SIGKDD Explorations Newsletter},
	author = {Tang, Hua and Zhang, Chong and Jin, Mingyu and Yu, Qinkai and Wang, Zhenting and Jin, Xiaobo and Zhang, Yongfeng and Du, Mengnan},
	month = jan,
	year = {2025},
	pages = {109--118},
}

@misc{khan_faultexplainer_2024,
	title = {{FaultExplainer}: {Leveraging} {Large} {Language} {Models} for {Interpretable} {Fault} {Detection} and {Diagnosis}},
	shorttitle = {{FaultExplainer}},
	url = {http://arxiv.org/abs/2412.14492},
	doi = {10.48550/arXiv.2412.14492},
	abstract = {Machine learning algorithms are increasingly being applied to fault detection and diagnosis (FDD) in chemical processes. However, existing data-driven FDD platforms often lack interpretability for process operators and struggle to identify root causes of previously unseen faults. This paper presents FaultExplainer, an interactive tool designed to improve fault detection, diagnosis, and explanation in the Tennessee Eastman Process (TEP). FaultExplainer integrates real-time sensor data visualization, Principal Component Analysis (PCA)-based fault detection, and identification of top contributing variables within an interactive user interface powered by large language models (LLMs). We evaluate the LLMs' reasoning capabilities in two scenarios: one where historical root causes are provided, and one where they are not to mimic the challenge of previously unseen faults. Experimental results using GPT-4o and o1-preview models demonstrate the system's strengths in generating plausible and actionable explanations, while also highlighting its limitations, including reliance on PCA-selected features and occasional hallucinations.},
	urldate = {2025-06-02},
	publisher = {arXiv},
	author = {Khan, Abdullah and Nahar, Rahul and Chen, Hao and Flores, Gonzalo E. Constante and Li, Can},
	month = dec,
	year = {2024},
	note = {arXiv:2412.14492 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Systems and Control, Electrical Engineering and Systems Science - Systems and Control},
}

@misc{li_hmcf_2025,
	title = {{HMCF}: {A} {Human}-in-the-loop {Multi}-{Robot} {Collaboration} {Framework} {Based} on {Large} {Language} {Models}},
	shorttitle = {{HMCF}},
	url = {http://arxiv.org/abs/2505.00820},
	doi = {10.48550/arXiv.2505.00820},
	abstract = {Rapid advancements in artificial intelligence (AI) have enabled robots to performcomplex tasks autonomously with increasing precision. However, multi-robot systems (MRSs) face challenges in generalization, heterogeneity, and safety, especially when scaling to large-scale deployments like disaster response. Traditional approaches often lack generalization, requiring extensive engineering for new tasks and scenarios, and struggle with managing diverse robots. To overcome these limitations, we propose a Human-in-the-loop Multi-Robot Collaboration Framework (HMCF) powered by large language models (LLMs). LLMs enhance adaptability by reasoning over diverse tasks and robot capabilities, while human oversight ensures safety and reliability, intervening only when necessary. Our framework seamlessly integrates human oversight, LLM agents, and heterogeneous robots to optimize task allocation and execution. Each robot is equipped with an LLM agent capable of understanding its capabilities, converting tasks into executable instructions, and reducing hallucinations through task verification and human supervision. Simulation results show that our framework outperforms state-of-the-art task planning methods, achieving higher task success rates with an improvement of 4.76\%. Real-world tests demonstrate its robust zero-shot generalization feature and ability to handle diverse tasks and environments with minimal human intervention.},
	urldate = {2025-06-02},
	publisher = {arXiv},
	author = {Li, Zhaoxing and Wu, Wenbo and Wang, Yue and Xu, Yanran and Hunt, William and Stein, Sebastian},
	month = may,
	year = {2025},
	note = {arXiv:2505.00820 [cs]},
	keywords = {Computer Science - Robotics},
}

@misc{wang_reinforcement_2025,
	title = {Reinforcement {Learning} {Enhanced} {LLMs}: {A} {Survey}},
	shorttitle = {Reinforcement {Learning} {Enhanced} {LLMs}},
	url = {http://arxiv.org/abs/2412.10400},
	doi = {10.48550/arXiv.2412.10400},
	abstract = {Reinforcement learning (RL) enhanced large language models (LLMs), particularly exemplified by DeepSeek-R1, have exhibited outstanding performance. Despite the effectiveness in improving LLM capabilities, its implementation remains highly complex, requiring complex algorithms, reward modeling strategies, and optimization techniques. This complexity poses challenges for researchers and practitioners in developing a systematic understanding of RL-enhanced LLMs. Moreover, the absence of a comprehensive survey summarizing existing research on RL-enhanced LLMs has limited progress in this domain, hindering further advancements. In this work, we are going to make a systematic review of the most up-to-date state of knowledge on RL-enhanced LLMs, attempting to consolidate and analyze the rapidly growing research in this field, helping researchers understand the current challenges and advancements. Specifically, we (1) detail the basics of RL; (2) introduce popular RL-enhanced LLMs; (3) review researches on two widely-used reward model-based RL techniques: Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning from AI Feedback (RLAIF); and (4) explore Direct Preference Optimization (DPO), a set of methods that bypass the reward model to directly use human preference data for aligning LLM outputs with human expectations. We will also point out current challenges and deficiencies of existing methods and suggest some avenues for further improvements. Project page of this work can be found at https://github.com/ShuheWang1998/Reinforcement-Learning-Enhanced-LLMs-A-Survey.},
	urldate = {2025-06-02},
	publisher = {arXiv},
	author = {Wang, Shuhe and Zhang, Shengyu and Zhang, Jie and Hu, Runyi and Li, Xiaoya and Zhang, Tianwei and Li, Jiwei and Wu, Fei and Wang, Guoyin and Hovy, Eduard},
	month = feb,
	year = {2025},
	note = {arXiv:2412.10400 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{xu_rlthf_2025,
	title = {{RLTHF}: {Targeted} {Human} {Feedback} for {LLM} {Alignment}},
	shorttitle = {{RLTHF}},
	url = {http://arxiv.org/abs/2502.13417},
	doi = {10.48550/arXiv.2502.13417},
	abstract = {Fine-tuning large language models (LLMs) to align with user preferences is challenging due to the high cost of quality human annotations in Reinforcement Learning from Human Feedback (RLHF) and the generalizability limitations of AI Feedback. To address these challenges, we propose RLTHF, a human-AI hybrid framework that combines LLM-based initial alignment with selective human annotations to achieve full-human annotation alignment with minimal effort. RLTHF identifies hard-to-annotate samples mislabeled by LLMs using a reward model's reward distribution and iteratively enhances alignment by integrating strategic human corrections while leveraging LLM's correctly labeled samples. Evaluations on HH-RLHF and TL;DR datasets show that RLTHF reaches full-human annotation-level alignment with only 6-7\% of the human annotation effort. Furthermore, models trained on RLTHF's curated datasets for downstream tasks outperform those trained on fully human-annotated datasets, underscoring the effectiveness of RLTHF's strategic data curation.},
	urldate = {2025-06-02},
	publisher = {arXiv},
	author = {Xu, Yifei and Chakraborty, Tusher and Kıcıman, Emre and Aryal, Bibek and Rodrigues, Eduardo and Sharma, Srinagesh and Estevao, Roberto and Balaguer, Maria Angels de Luis and Wolk, Jessica and Padilha, Rafael and Nunes, Leonardo and Balakrishnan, Shobana and Lu, Songwu and Chandra, Ranveer},
	month = feb,
	year = {2025},
	note = {arXiv:2502.13417 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{xia_selection_2025,
	title = {From {Selection} to {Generation}: {A} {Survey} of {LLM}-based {Active} {Learning}},
	shorttitle = {From {Selection} to {Generation}},
	url = {http://arxiv.org/abs/2502.11767},
	doi = {10.48550/arXiv.2502.11767},
	abstract = {Active Learning (AL) has been a powerful paradigm for improving model efficiency and performance by selecting the most informative data points for labeling and training. In recent active learning frameworks, Large Language Models (LLMs) have been employed not only for selection but also for generating entirely new data instances and providing more cost-effective annotations. Motivated by the increasing importance of high-quality data and efficient model training in the era of LLMs, we present a comprehensive survey on LLM-based Active Learning. We introduce an intuitive taxonomy that categorizes these techniques and discuss the transformative roles LLMs can play in the active learning loop. We further examine the impact of AL on LLM learning paradigms and its applications across various domains. Finally, we identify open challenges and propose future research directions. This survey aims to serve as an up-to-date resource for researchers and practitioners seeking to gain an intuitive understanding of LLM-based AL techniques and deploy them to new applications.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Xia, Yu and Mukherjee, Subhojyoti and Xie, Zhouhang and Wu, Junda and Li, Xintong and Aponte, Ryan and Lyu, Hanjia and Barrow, Joe and Chen, Hongjie and Dernoncourt, Franck and Kveton, Branislav and Yu, Tong and Zhang, Ruiyi and Gu, Jiuxiang and Ahmed, Nesreen K. and Wang, Yu and Chen, Xiang and Deilamsalehy, Hanieh and Kim, Sungchul and Hu, Zhengmian and Zhao, Yue and Lipka, Nedim and Yoon, Seunghyun and Huang, Ting-Hao Kenneth and Wang, Zichao and Mathur, Puneet and Pal, Soumyabrata and Mukherjee, Koyel and Zhang, Zhehao and Park, Namyong and Nguyen, Thien Huu and Luo, Jiebo and Rossi, Ryan A. and McAuley, Julian},
	month = feb,
	year = {2025},
	note = {arXiv:2502.11767 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{bilal_llms_2025,
	title = {{LLMs} for {Explainable} {AI}: {A} {Comprehensive} {Survey}},
	shorttitle = {{LLMs} for {Explainable} {AI}},
	url = {http://arxiv.org/abs/2504.00125},
	doi = {10.48550/arXiv.2504.00125},
	abstract = {Large Language Models (LLMs) offer a promising approach to enhancing Explainable AI (XAI) by transforming complex machine learning outputs into easy-to-understand narratives, making model predictions more accessible to users, and helping bridge the gap between sophisticated model behavior and human interpretability. AI models, such as state-of-the-art neural networks and deep learning models, are often seen as "black boxes" due to a lack of transparency. As users cannot fully understand how the models reach conclusions, users have difficulty trusting decisions from AI models, which leads to less effective decision-making processes, reduced accountabilities, and unclear potential biases. A challenge arises in developing explainable AI (XAI) models to gain users' trust and provide insights into how models generate their outputs. With the development of Large Language Models, we want to explore the possibilities of using human language-based models, LLMs, for model explainabilities. This survey provides a comprehensive overview of existing approaches regarding LLMs for XAI, and evaluation techniques for LLM-generated explanation, discusses the corresponding challenges and limitations, and examines real-world applications. Finally, we discuss future directions by emphasizing the need for more interpretable, automated, user-centric, and multidisciplinary approaches for XAI via LLMs.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Bilal, Ahsan and Ebert, David and Lin, Beiyu},
	month = mar,
	year = {2025},
	note = {arXiv:2504.00125 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{zhou_steerconf_2025,
	title = {{SteerConf}: {Steering} {LLMs} for {Confidence} {Elicitation}},
	shorttitle = {{SteerConf}},
	url = {http://arxiv.org/abs/2503.02863},
	doi = {10.48550/arXiv.2503.02863},
	abstract = {Large Language Models (LLMs) exhibit impressive performance across diverse domains but often suffer from overconfidence, limiting their reliability in critical applications. We propose SteerConf, a novel framework that systematically steers LLMs' confidence scores to improve their calibration and reliability. SteerConf introduces three key components: (1) a steering prompt strategy that guides LLMs to produce confidence scores in specified directions (e.g., conservative or optimistic) by leveraging prompts with varying steering levels; (2) a steered confidence consistency measure that quantifies alignment across multiple steered confidences to enhance calibration; and (3) a steered confidence calibration method that aggregates confidence scores using consistency measures and applies linear quantization for answer selection. SteerConf operates without additional training or fine-tuning, making it broadly applicable to existing LLMs. Experiments on seven benchmarks spanning professional knowledge, common sense, ethics, and reasoning tasks, using advanced LLM models (GPT-3.5, LLaMA 3, GPT-4), demonstrate that SteerConf significantly outperforms existing methods, often by a significant margin. Our findings highlight the potential of steering the confidence of LLMs to enhance their reliability for safer deployment in real-world applications.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Zhou, Ziang and Jin, Tianyuan and Shi, Jieming and Li, Qing},
	month = may,
	year = {2025},
	note = {arXiv:2503.02863 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@misc{abbasli_comparing_2025,
	title = {Comparing {Uncertainty} {Measurement} and {Mitigation} {Methods} for {Large} {Language} {Models}: {A} {Systematic} {Review}},
	shorttitle = {Comparing {Uncertainty} {Measurement} and {Mitigation} {Methods} for {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2504.18346},
	doi = {10.48550/arXiv.2504.18346},
	abstract = {Large Language Models (LLMs) have been transformative across many domains. However, hallucination -- confidently outputting incorrect information -- remains one of the leading challenges for LLMs. This raises the question of how to accurately assess and quantify the uncertainty of LLMs. Extensive literature on traditional models has explored Uncertainty Quantification (UQ) to measure uncertainty and employed calibration techniques to address the misalignment between uncertainty and accuracy. While some of these methods have been adapted for LLMs, the literature lacks an in-depth analysis of their effectiveness and does not offer a comprehensive benchmark to enable insightful comparison among existing solutions. In this work, we fill this gap via a systematic survey of representative prior works on UQ and calibration for LLMs and introduce a rigorous benchmark. Using two widely used reliability datasets, we empirically evaluate six related methods, which justify the significant findings of our review. Finally, we provide outlooks for key future directions and outline open challenges. To the best of our knowledge, this survey is the first dedicated study to review the calibration methods and relevant metrics for LLMs.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Abbasli, Toghrul and Toyoda, Kentaroh and Wang, Yuan and Witt, Leon and Ali, Muhammad Asif and Miao, Yukai and Li, Dan and Wei, Qingsong},
	month = apr,
	year = {2025},
	note = {arXiv:2504.18346 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{pei_flow--action_2025,
	title = {Flow-of-{Action}: {SOP} {Enhanced} {LLM}-{Based} {Multi}-{Agent} {System} for {Root} {Cause} {Analysis}},
	shorttitle = {Flow-of-{Action}},
	url = {http://arxiv.org/abs/2502.08224},
	doi = {10.48550/arXiv.2502.08224},
	abstract = {In the realm of microservices architecture, the occurrence of frequent incidents necessitates the employment of Root Cause Analysis (RCA) for swift issue resolution. It is common that a serious incident can take several domain experts hours to identify the root cause. Consequently, a contemporary trend involves harnessing Large Language Models (LLMs) as automated agents for RCA. Though the recent ReAct framework aligns well with the Site Reliability Engineers (SREs) for its thought-action-observation paradigm, its hallucinations often lead to irrelevant actions and directly affect subsequent results. Additionally, the complex and variable clues of the incident can overwhelm the model one step further. To confront these challenges, we propose Flow-of-Action, a pioneering Standard Operation Procedure (SOP) enhanced LLM-based multi-agent system. By explicitly summarizing the diagnosis steps of SREs, SOP imposes constraints on LLMs at crucial junctures, guiding the RCA process towards the correct trajectory. To facilitate the rational and effective utilization of SOPs, we design an SOP-centric framework called SOP flow. SOP flow contains a series of tools, including one for finding relevant SOPs for incidents, another for automatically generating SOPs for incidents without relevant ones, and a tool for converting SOPs into code. This significantly alleviates the hallucination issues of ReAct in RCA tasks. We also design multiple auxiliary agents to assist the main agent by removing useless noise, narrowing the search space, and informing the main agent whether the RCA procedure can stop. Compared to the ReAct method's 35.50\% accuracy, our Flow-of-Action method achieves 64.01\%, meeting the accuracy requirements for RCA in real-world systems.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Pei, Changhua and Wang, Zexin and Liu, Fengrui and Li, Zeyan and Liu, Yang and He, Xiao and Kang, Rong and Zhang, Tieying and Chen, Jianjun and Li, Jianhui and Xie, Gaogang and Pei, Dan},
	month = feb,
	year = {2025},
	note = {arXiv:2502.08224 [cs]},
	keywords = {Computer Science - Software Engineering},
}

@misc{song_pre-trained_2023,
	title = {Pre-{Trained} {Large} {Language} {Models} for {Industrial} {Control}},
	url = {http://arxiv.org/abs/2308.03028},
	doi = {10.48550/arXiv.2308.03028},
	abstract = {For industrial control, developing high-performance controllers with few samples and low technical debt is appealing. Foundation models, possessing rich prior knowledge obtained from pre-training with Internet-scale corpus, have the potential to be a good controller with proper prompts. In this paper, we take HVAC (Heating, Ventilation, and Air Conditioning) building control as an example to examine the ability of GPT-4 (one of the first-tier foundation models) as the controller. To control HVAC, we wrap the task as a language game by providing text including a short description for the task, several selected demonstrations, and the current observation to GPT-4 on each step and execute the actions responded by GPT-4. We conduct series of experiments to answer the following questions: 1){\textasciitilde}How well can GPT-4 control HVAC? 2){\textasciitilde}How well can GPT-4 generalize to different scenarios for HVAC control? 3) How different parts of the text context affect the performance? In general, we found GPT-4 achieves the performance comparable to RL methods with few samples and low technical debt, indicating the potential of directly applying foundation models to industrial control tasks.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Song, Lei and Zhang, Chuheng and Zhao, Li and Bian, Jiang},
	month = aug,
	year = {2023},
	note = {arXiv:2308.03028 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@misc{atf_challenge_2025,
	title = {The challenge of uncertainty quantification of large language models in medicine},
	url = {http://arxiv.org/abs/2504.05278},
	doi = {10.48550/arXiv.2504.05278},
	abstract = {This study investigates uncertainty quantification in large language models (LLMs) for medical applications, emphasizing both technical innovations and philosophical implications. As LLMs become integral to clinical decision-making, accurately communicating uncertainty is crucial for ensuring reliable, safe, and ethical AI-assisted healthcare. Our research frames uncertainty not as a barrier but as an essential part of knowledge that invites a dynamic and reflective approach to AI design. By integrating advanced probabilistic methods such as Bayesian inference, deep ensembles, and Monte Carlo dropout with linguistic analysis that computes predictive and semantic entropy, we propose a comprehensive framework that manages both epistemic and aleatoric uncertainties. The framework incorporates surrogate modeling to address limitations of proprietary APIs, multi-source data integration for better context, and dynamic calibration via continual and meta-learning. Explainability is embedded through uncertainty maps and confidence metrics to support user trust and clinical interpretability. Our approach supports transparent and ethical decision-making aligned with Responsible and Reflective AI principles. Philosophically, we advocate accepting controlled ambiguity instead of striving for absolute predictability, recognizing the inherent provisionality of medical knowledge.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Atf, Zahra and Safavi-Naini, Seyed Amir Ahmad and Lewis, Peter R. and Mahjoubfar, Aref and Naderi, Nariman and Savage, Thomas R. and Soroush, Ali},
	month = apr,
	year = {2025},
	note = {arXiv:2504.05278 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@misc{zhang_fuzzy_2025,
	title = {Fuzzy {Rule}-based {Differentiable} {Representation} {Learning}},
	url = {http://arxiv.org/abs/2503.13548},
	doi = {10.48550/arXiv.2503.13548},
	abstract = {Representation learning has emerged as a crucial focus in machine and deep learning, involving the extraction of meaningful and useful features and patterns from the input data, thereby enhancing the performance of various downstream tasks such as classification, clustering, and prediction. Current mainstream representation learning methods primarily rely on non-linear data mining techniques such as kernel methods and deep neural networks to extract abstract knowledge from complex datasets. However, most of these methods are black-box, lacking transparency and interpretability in the learning process, which constrains their practical utility. To this end, this paper introduces a novel representation learning method grounded in an interpretable fuzzy rule-based model. Specifically, it is built upon the Takagi-Sugeno-Kang fuzzy system (TSK-FS) to initially map input data to a high-dimensional fuzzy feature space through the antecedent part of the TSK-FS. Subsequently, a novel differentiable optimization method is proposed for the consequence part learning which can preserve the model's interpretability and transparency while further exploring the nonlinear relationships within the data. This optimization method retains the essence of traditional optimization, with certain parts of the process parameterized corresponding differentiable modules constructed, and a deep optimization process implemented. Consequently, this method not only enhances the model's performance but also ensures its interpretability. Moreover, a second-order geometry preservation method is introduced to further improve the robustness of the proposed method. Extensive experiments conducted on various benchmark datasets validate the superiority of the proposed method, highlighting its potential for advancing representation learning methodologies.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Zhang, Wei and Deng, Zhaohong and Wang, Guanjin and Choi, Kup-Sze},
	month = mar,
	year = {2025},
	note = {arXiv:2503.13548 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{li_anomalygen_2025,
	title = {{AnomalyGen}: {An} {Automated} {Semantic} {Log} {Sequence} {Generation} {Framework} with {LLM} for {Anomaly} {Detection}},
	shorttitle = {{AnomalyGen}},
	url = {http://arxiv.org/abs/2504.12250},
	doi = {10.48550/arXiv.2504.12250},
	abstract = {The scarcity of high-quality public log datasets has become a critical bottleneck in advancing log-based anomaly detection techniques. Current datasets exhibit three fundamental limitations: (1) incomplete event coverage, (2) artificial patterns introduced by static analysis-based generation frameworks, and (3) insufficient semantic awareness. To address these challenges, we present AnomalyGen, the first automated log synthesis framework specifically designed for anomaly detection. Our framework introduces a novel four-phase architecture that integrates enhanced program analysis with Chain-of-Thought reasoning (CoT reasoning), enabling iterative log generation and anomaly annotation without requiring physical system execution. Evaluations on Hadoop and HDFS distributed systems demonstrate that AnomalyGen achieves substantially broader log event coverage (38-95 times improvement over existing datasets) while producing more operationally realistic log sequences compared to static analysis-based approaches. When augmenting benchmark datasets with synthesized logs, we observe maximum F1-score improvements of 3.7\% (average 1.8\% improvement across three state-of-the-art anomaly detection models). This work not only establishes a high-quality benchmarking resource for automated log analysis but also pioneers a new paradigm for applying large language models (LLMs) in software engineering workflows.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Li, Xinyu and Huo, Yingtong and Mao, Chenxi and Shan, Shiwen and Su, Yuxin and Li, Dan and Zheng, Zibin},
	month = apr,
	year = {2025},
	note = {arXiv:2504.12250 [cs]},
	keywords = {Computer Science - Software Engineering},
}

@misc{gorski_integrating_2025,
	title = {Integrating {Expert} {Knowledge} into {Logical} {Programs} via {LLMs}},
	url = {http://arxiv.org/abs/2502.12275},
	doi = {10.48550/arXiv.2502.12275},
	abstract = {This paper introduces ExKLoP, a novel framework designed to evaluate how effectively Large Language Models (LLMs) integrate expert knowledge into logical reasoning systems. This capability is especially valuable in engineering, where expert knowledge-such as manufacturer-recommended operational ranges-can be directly embedded into automated monitoring systems. By mirroring expert verification steps, tasks like range checking and constraint validation help ensure system safety and reliability. Our approach systematically evaluates LLM-generated logical rules, assessing both syntactic fluency and logical correctness in these critical validation tasks. We also explore the models' capacity for self-correction via an iterative feedback loop based on code execution outcomes. ExKLoP presents an extensible dataset comprising 130 engineering premises, 950 prompts, and corresponding validation points. It enables comprehensive benchmarking while allowing control over task complexity and scalability of experiments. We leverage the synthetic data creation methodology to conduct extensive empirical evaluation on a diverse set of LLMs including Llama3, Gemma3, Codestral and QwenCoder. The results reveal that most models generate nearly perfect syntactically correct code and exhibit strong performance in translating expert knowledge into correct code. At the same time, while most LLMs produce nearly flawless syntactic output, their ability to correctly implement logical rules varies, as does their capacity for self-improvement. Overall, ExKLoP serves as a robust evaluation platform that streamlines the selection of effective models for self-correcting systems while clearly delineating the types of errors encountered.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Górski, Franciszek and Wysocki, Oskar and Valentino, Marco and Freitas, Andre},
	month = may,
	year = {2025},
	note = {arXiv:2502.12275 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Multiagent Systems},
}

@misc{chandra_applications_2025,
	title = {Applications of {Large} {Language} {Model} {Reasoning} in {Feature} {Generation}},
	url = {http://arxiv.org/abs/2503.11989},
	doi = {10.48550/arXiv.2503.11989},
	abstract = {Large Language Models (LLMs) have revolutionized natural language processing through their state of art reasoning capabilities. This paper explores the convergence of LLM reasoning techniques and feature generation for machine learning tasks. We examine four key reasoning approaches: Chain of Thought, Tree of Thoughts, Retrieval-Augmented Generation, and Thought Space Exploration. Our analysis reveals how these approaches can be used to identify effective feature generation rules without having to manually specify search spaces. The paper categorizes LLM-based feature generation methods across various domains including finance, healthcare, and text analytics. LLMs can extract key information from clinical notes and radiology reports in healthcare, by enabling more efficient data utilization. In finance, LLMs facilitate text generation, summarization, and entity extraction from complex documents. We analyze evaluation methodologies for assessing feature quality and downstream performance, with particular attention to OCTree's decision tree reasoning approach that provides language-based feedback for iterative improvements. Current challenges include hallucination, computational efficiency, and domain adaptation. As of March 2025, emerging approaches include inference-time compute scaling, reinforcement learning, and supervised fine-tuning with model distillation. Future directions point toward multimodal feature generation, self-improving systems, and neuro-symbolic approaches. This paper provides a detailed overview of an emerging field that promises to automate and enhance feature engineering through language model reasoning.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Chandra, Dharani},
	month = mar,
	year = {2025},
	note = {arXiv:2503.11989 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{zhang_output_2025,
	title = {Output {Constraints} as {Attack} {Surface}: {Exploiting} {Structured} {Generation} to {Bypass} {LLM} {Safety} {Mechanisms}},
	shorttitle = {Output {Constraints} as {Attack} {Surface}},
	url = {http://arxiv.org/abs/2503.24191},
	doi = {10.48550/arXiv.2503.24191},
	abstract = {Content Warning: This paper may contain unsafe or harmful content generated by LLMs that may be offensive to readers. Large Language Models (LLMs) are extensively used as tooling platforms through structured output APIs to ensure syntax compliance so that robust integration with existing softwares like agent systems, could be achieved. However, the feature enabling functionality of grammar-guided structured output presents significant security vulnerabilities. In this work, we reveal a critical control-plane attack surface orthogonal to traditional data-plane vulnerabilities. We introduce Constrained Decoding Attack (CDA), a novel jailbreak class that weaponizes structured output constraints to bypass safety mechanisms. Unlike prior attacks focused on input prompts, CDA operates by embedding malicious intent in schema-level grammar rules (control-plane) while maintaining benign surface prompts (data-plane). We instantiate this with a proof-of-concept Chain Enum Attack, achieves 96.2\% attack success rates across proprietary and open-weight LLMs on five safety benchmarks with a single query, including GPT-4o and Gemini-2.0-flash. Our findings identify a critical security blind spot in current LLM architectures and urge a paradigm shift in LLM safety to address control-plane vulnerabilities, as current mechanisms focused solely on data-plane threats leave critical systems exposed.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Zhang, Shuoming and Zhao, Jiacheng and Xu, Ruiyuan and Feng, Xiaobing and Cui, Huimin},
	month = mar,
	year = {2025},
	note = {arXiv:2503.24191 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
}

@misc{alvarado-maldonado_natural_2025,
	title = {Natural {Language} {Processing} tools for {Pharmaceutical} {Manufacturing} {Information} {Extraction} from {Patents}},
	url = {http://arxiv.org/abs/2504.20598},
	doi = {10.48550/arXiv.2504.20598},
	abstract = {Abundant and diverse data on medicines manufacturing and other lifecycle components has been made easily accessible in the last decades. However, a significant proportion of this information is characterised by not being tabulated and usable for machine learning purposes. Thus, natural language processing tools have been used to build databases in domains such as biomedical and chemical to address this limitation. This has allowed the development of artificial intelligence applications, which have improved drug discovery and treatments. In the pharmaceutical manufacturing context, some initiatives and datasets for primary processing can be found, but the manufacturing of drug products is an area which is still lacking, to the best of our knowledge. This works aims to explore and adapt NLP tools used in other domains to extract information on both primary and secondary manufacturing, employing patents as the main source of data. Thus, two independent, but complementary, models were developed comprising a method to select fragments of text that contain manufacturing data, and a named entity recognition system that enables extracting information on operations, materials, and conditions of a process. For the first model, the identification of relevant sections was achieved using an unsupervised approach combining Latent Dirichlet Allocation and k-Means clustering. The performance of this model measured as a Cohen's kappa between model output and manual revision was higher than 90\%. NER model consisted of a deep neural network, and an f1-score micro average of 84.2\% was obtained which is comparable to other works. Some considerations for these tools to be used in data extraction are discussed throughout this document.},
	urldate = {2025-06-01},
	publisher = {arXiv},
	author = {Alvarado-Maldonado, Diego and Johnston, Blair and Brown, Cameron J.},
	month = may,
	year = {2025},
	note = {arXiv:2504.20598 [cs]},
	keywords = {Computer Science - Information Retrieval},
}

@misc{ahmed_attackllm_2025,
	title = {{AttackLLM}: {LLM}-based {Attack} {Pattern} {Generation} for an {Industrial} {Control} {System}},
	shorttitle = {{AttackLLM}},
	url = {http://arxiv.org/abs/2504.04187},
	doi = {10.48550/arXiv.2504.04187},
	abstract = {Malicious examples are crucial for evaluating the robustness of machine learning algorithms under attack, particularly in Industrial Control Systems (ICS). However, collecting normal and attack data in ICS environments is challenging due to the scarcity of testbeds and the high cost of human expertise. Existing datasets are often limited by the domain expertise of practitioners, making the process costly and inefficient. The lack of comprehensive attack pattern data poses a significant problem for developing robust anomaly detection methods. In this paper, we propose a novel approach that combines data-centric and design-centric methodologies to generate attack patterns using large language models (LLMs). Our results demonstrate that the attack patterns generated by LLMs not only surpass the quality and quantity of those created by human experts but also offer a scalable solution that does not rely on expensive testbeds or pre-existing attack examples. This multi-agent based approach presents a promising avenue for enhancing the security and resilience of ICS environments.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Ahmed, Chuadhry Mujeeb},
	month = apr,
	year = {2025},
	note = {arXiv:2504.04187 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
}

@misc{mokhtar_detect_2025,
	title = {Detect, {Classify}, {Act}: {Categorizing} {Industrial} {Anomalies} with {Multi}-{Modal} {Large} {Language} {Models}},
	shorttitle = {Detect, {Classify}, {Act}},
	url = {http://arxiv.org/abs/2505.02626},
	doi = {10.48550/arXiv.2505.02626},
	abstract = {Recent advances in visual industrial anomaly detection have demonstrated exceptional performance in identifying and segmenting anomalous regions while maintaining fast inference speeds. However, anomaly classification-distinguishing different types of anomalies-remains largely unexplored despite its critical importance in real-world inspection tasks. To address this gap, we propose VELM, a novel LLM-based pipeline for anomaly classification. Given the critical importance of inference speed, we first apply an unsupervised anomaly detection method as a vision expert to assess the normality of an observation. If an anomaly is detected, the LLM then classifies its type. A key challenge in developing and evaluating anomaly classification models is the lack of precise annotations of anomaly classes in existing datasets. To address this limitation, we introduce MVTec-AC and VisA-AC, refined versions of the widely used MVTec-AD and VisA datasets, which include accurate anomaly class labels for rigorous evaluation. Our approach achieves a state-of-the-art anomaly classification accuracy of 80.4\% on MVTec-AD, exceeding the prior baselines by 5\%, and 84\% on MVTec-AC, demonstrating the effectiveness of VELM in understanding and categorizing anomalies. We hope our methodology and benchmark inspire further research in anomaly classification, helping bridge the gap between detection and comprehensive anomaly characterization.},
	urldate = {2025-05-25},
	publisher = {arXiv},
	author = {Mokhtar, Sassan and Mousakhan, Arian and Galesso, Silvio and Tayyub, Jawad and Brox, Thomas},
	month = may,
	year = {2025},
	note = {arXiv:2505.02626 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{romanov_approach_2025,
	title = {An {Approach} to {Generating} {Fuzzy} {Rules} for a {Fuzzy} {Controller} {Based} on the {Decision} {Tree} {Interpretation}},
	volume = {14},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2075-1680},
	url = {https://www.mdpi.com/2075-1680/14/3/196},
	doi = {10.3390/axioms14030196},
	abstract = {This article describes solutions to control problems using fuzzy logic, which facilitates the development of decision support systems across various fields. However, addressing this task through the manual creation of rules in specific fields necessitates significant expert knowledge. Machine learning methods can identify hidden patterns. A key novelty of this approach is the algorithm for generating fuzzy rules for a fuzzy controller, derived from interpreting a decision tree. The proposed algorithm allows the quality of the control actions in organizational and technical systems to be enhanced. This article presents an example of generating a set of fuzzy rules through the analysis of a decision tree model. The proposed algorithm allows for the creation of a set of fuzzy rules for constructing fuzzy rule-based systems (FRBSs). Additionally, it autogenerates membership functions and linguistic term labels for all of the input and output parameters. The machine learning model and the FRBS obtained were assessed using the coefficient of determination (R2). The experimental results demonstrated that the constructed FRBS performed on average 2\% worse than the original decision tree model. While the quality of the FRBS could be enhanced by optimizing the membership functions, this topic falls outside the scope of the current article.},
	language = {en},
	number = {3},
	urldate = {2025-05-18},
	journal = {Axioms},
	author = {Romanov, Anton A. and Filippov, Aleksey A. and Yarushkina, Nadezhda G.},
	month = mar,
	year = {2025},
	pages = {196},
}

@misc{gu_argos_2025,
	title = {Argos: {Agentic} {Time}-{Series} {Anomaly} {Detection} with {Autonomous} {Rule} {Generation} via {Large} {Language} {Models}},
	shorttitle = {Argos},
	url = {http://arxiv.org/abs/2501.14170},
	doi = {10.48550/arXiv.2501.14170},
	abstract = {Observability in cloud infrastructure is critical for service providers, driving the widespread adoption of anomaly detection systems for monitoring metrics. However, existing systems often struggle to simultaneously achieve explainability, reproducibility, and autonomy, which are three indispensable properties for production use. We introduce Argos, an agentic system for detecting time-series anomalies in cloud infrastructure by leveraging large language models (LLMs). Argos proposes to use explainable and reproducible anomaly rules as intermediate representation and employs LLMs to autonomously generate such rules. The system will efficiently train error-free and accuracy-guaranteed anomaly rules through multiple collaborative agents and deploy the trained rules for low-cost online anomaly detection. Through evaluation results, we demonstrate that Argos outperforms state-of-the-art methods, increasing \$F\_1\$ scores by up to \$9.5{\textbackslash}\%\$ and \$28.3{\textbackslash}\%\$ on public anomaly detection datasets and an internal dataset collected from Microsoft, respectively.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Gu, Yile and Xiong, Yifan and Mace, Jonathan and Jiang, Yuting and Hu, Yigong and Kasikci, Baris and Cheng, Peng},
	month = jan,
	year = {2025},
	note = {arXiv:2501.14170 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
}

@misc{xia_enhance_2024,
	title = {Enhance {FMEA} with {Large} {Language} {Models} for {Assisted} {Risk} {Management} in {Technical} {Processes} and {Products}},
	copyright = {https://creativecommons.org/licenses/by-nc-sa/4.0/},
	url = {https://www.techrxiv.org/users/809561/articles/1211040-enhance-fmea-with-large-language-models-for-assisted-risk-management-in-technical-processes-and-products?commit=4e9627793297f1a582b20a7acfda9f2eb4b69831},
	doi = {10.36227/techrxiv.172254395.58219170/v1},
	urldate = {2025-05-18},
	publisher = {Preprints},
	author = {Xia, Yuchen and Jazdi, Nasser and Weyrich, Michael},
	month = aug,
	year = {2024},
}

@misc{liu_agents4plc_2024,
	title = {{Agents4PLC}: {Automating} {Closed}-loop {PLC} {Code} {Generation} and {Verification} in {Industrial} {Control} {Systems} using {LLM}-based {Agents}},
	shorttitle = {{Agents4PLC}},
	url = {http://arxiv.org/abs/2410.14209},
	doi = {10.48550/arXiv.2410.14209},
	abstract = {In industrial control systems, the generation and verification of Programmable Logic Controller (PLC) code are critical for ensuring operational efficiency and safety. While Large Language Models (LLMs) have made strides in automated code generation, they often fall short in providing correctness guarantees and specialized support for PLC programming. To address these challenges, this paper introduces Agents4PLC, a novel framework that not only automates PLC code generation but also includes code-level verification through an LLM-based multi-agent system. We first establish a comprehensive benchmark for verifiable PLC code generation area, transitioning from natural language requirements to human-written-verified formal specifications and reference PLC code. We further enhance our `agents' specifically for industrial control systems by incorporating Retrieval-Augmented Generation (RAG), advanced prompt engineering techniques, and Chain-of-Thought strategies. Evaluation against the benchmark demonstrates that Agents4PLC significantly outperforms previous methods, achieving superior results across a series of increasingly rigorous metrics. This research not only addresses the critical challenges in PLC programming but also highlights the potential of our framework to generate verifiable code applicable to real-world industrial applications.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Liu, Zihan and Zeng, Ruinan and Wang, Dongxia and Peng, Gengyun and Wang, Jingyi and Liu, Qiang and Liu, Peiyu and Wang, Wenhai},
	month = dec,
	year = {2024},
	note = {arXiv:2410.14209 [cs]},
	keywords = {Computer Science - Software Engineering},
}

@misc{russell-gilbert_aad-llm_2024,
	title = {{AAD}-{LLM}: {Adaptive} {Anomaly} {Detection} {Using} {Large} {Language} {Models}},
	shorttitle = {{AAD}-{LLM}},
	url = {http://arxiv.org/abs/2411.00914},
	doi = {10.48550/arXiv.2411.00914},
	abstract = {For data-constrained, complex and dynamic industrial environments, there is a critical need for transferable and multimodal methodologies to enhance anomaly detection and therefore, prevent costs associated with system failures. Typically, traditional PdM approaches are not transferable or multimodal. This work examines the use of Large Language Models (LLMs) for anomaly detection in complex and dynamic manufacturing systems. The research aims to improve the transferability of anomaly detection models by leveraging Large Language Models (LLMs) and seeks to validate the enhanced effectiveness of the proposed approach in data-sparse industrial applications. The research also seeks to enable more collaborative decision-making between the model and plant operators by allowing for the enriching of input series data with semantics. Additionally, the research aims to address the issue of concept drift in dynamic industrial settings by integrating an adaptability mechanism. The literature review examines the latest developments in LLM time series tasks alongside associated adaptive anomaly detection methods to establish a robust theoretical framework for the proposed architecture. This paper presents a novel model framework (AAD-LLM) that doesn't require any training or finetuning on the dataset it is applied to and is multimodal. Results suggest that anomaly detection can be converted into a "language" task to deliver effective, context-aware detection in data-constrained industrial applications. This work, therefore, contributes significantly to advancements in anomaly detection methodologies.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Russell-Gilbert, Alicia and Sommers, Alexander and Thompson, Andrew and Cummins, Logan and Mittal, Sudip and Rahimi, Shahram and Seale, Maria and Jaboure, Joseph and Arnold, Thomas and Church, Joshua},
	month = nov,
	year = {2024},
	note = {arXiv:2411.00914 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computational Engineering, Finance, and Science, Computer Science - Machine Learning},
}

@article{chen_llm-dr_2025,
	title = {{LLM}-{DR}: {A} {Novel} {LLM}-{Aided} {Diffusion} {Model} for {Rule} {Generation} on {Temporal} {Knowledge} {Graphs}},
	volume = {39},
	issn = {2374-3468, 2159-5399},
	shorttitle = {{LLM}-{DR}},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/33249},
	doi = {10.1609/aaai.v39i11.33249},
	abstract = {Among various temporal knowledge graph (TKG) extrapolation methods, rule-based approaches stand out for their explicit rules and transparent reasoning paths. However, the vast search space for rule extraction poses a challenge in identifying high-quality logic rules. To navigate this challenge, we explore the use of generation models to generate new rules, thereby enriching our rule base and enhancing our reasoning capabilities. In this paper, we introduce LLM-DR, an innovative rule-based method for TKG extrapolation, which harnesses diffusion models to generate rules that are consistent with the distribution of the source data, while also amalgamating the rich semantic insights of Large Language Models (LLMs). Specifically, our LLM-DR generates semantically relevant and high-quality rules, employing conditional diffusion models in a classifier-free guidance fashion and refining them with LLM-based constraints. To assess rule efficacy, we meticulously design a coarse-to-fine evaluation strategy that initiates with coarse-grained filtering to eliminate less plausible rules and proceeds with fine-grained scoring to quantify the reliability of the retained. Extensive experiments demonstrate the promising capacity of our LLM-DR.},
	number = {11},
	urldate = {2025-05-18},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Chen, Kai and Song, Xin and Wang, Ye and Gao, Liqun and Li, Aiping and Zhao, Xiaojuan and Zhou, Bin and Xie, Yalong},
	month = apr,
	year = {2025},
	pages = {11481--11489},
}

@misc{zeng_objects_2025,
	title = {From {Objects} to {Events}: {Unlocking} {Complex} {Visual} {Understanding} in {Object} {Detectors} via {LLM}-guided {Symbolic} {Reasoning}},
	shorttitle = {From {Objects} to {Events}},
	url = {http://arxiv.org/abs/2502.05843},
	doi = {10.48550/arXiv.2502.05843},
	abstract = {Our key innovation lies in bridging the semantic gap between object detection and event understanding without requiring expensive task-specific training. The proposed plug-and-play framework interfaces with any open-vocabulary detector while extending their inherent capabilities across architectures. At its core, our approach combines (i) a symbolic regression mechanism exploring relationship patterns among detected entities and (ii) a LLM-guided strategically guiding the search toward meaningful expressions. These discovered symbolic rules transform low-level visual perception into interpretable event understanding, providing a transparent reasoning path from objects to events with strong transferability across domains.We compared our training-free framework against specialized event recognition systems across diverse application domains. Experiments demonstrate that our framework enhances multiple object detector architectures to recognize complex events such as illegal fishing activities (75\% AUROC, +8.36\% improvement), construction safety violations (+15.77\%), and abnormal crowd behaviors (+23.16\%). The code will be released soon.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Zeng, Yuhui and Wu, Haoxiang and Nie, Wenjie and Zheng, Xiawu and Chen, Guangyao and Shen, Yunhang and Peng, Jun and Tian, Yonghong and Ji, Rongrong},
	month = mar,
	year = {2025},
	note = {arXiv:2502.05843 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{hosseini_leveraging_2025,
	title = {Leveraging {LLMs} and {Knowledge} {Graphs} to {Design} {Secure} {Automation} {Systems}},
	volume = {6},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2644-1284},
	url = {https://ieeexplore.ieee.org/document/10904297/},
	doi = {10.1109/OJIES.2025.3545811},
	urldate = {2025-05-18},
	journal = {IEEE Open Journal of the Industrial Electronics Society},
	author = {Hosseini, Ali M. and Kastner, Wolfgang and Sauter, Thilo},
	year = {2025},
	pages = {380--395},
}

@misc{luo_large_2025,
	title = {Large {Language} {Model} {Agent}: {A} {Survey} on {Methodology}, {Applications} and {Challenges}},
	shorttitle = {Large {Language} {Model} {Agent}},
	url = {http://arxiv.org/abs/2503.21460},
	doi = {10.48550/arXiv.2503.21460},
	abstract = {The era of intelligent agents is upon us, driven by revolutionary advancements in large language models. Large Language Model (LLM) agents, with goal-driven behaviors and dynamic adaptation capabilities, potentially represent a critical pathway toward artificial general intelligence. This survey systematically deconstructs LLM agent systems through a methodology-centered taxonomy, linking architectural foundations, collaboration mechanisms, and evolutionary pathways. We unify fragmented research threads by revealing fundamental connections between agent design principles and their emergent behaviors in complex environments. Our work provides a unified architectural perspective, examining how agents are constructed, how they collaborate, and how they evolve over time, while also addressing evaluation methodologies, tool applications, practical challenges, and diverse application domains. By surveying the latest developments in this rapidly evolving field, we offer researchers a structured taxonomy for understanding LLM agents and identify promising directions for future research. The collection is available at https://github.com/luo-junyu/Awesome-Agent-Papers.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Luo, Junyu and Zhang, Weizhi and Yuan, Ye and Zhao, Yusheng and Yang, Junwei and Gu, Yiyang and Wu, Bohan and Chen, Binqi and Qiao, Ziyue and Long, Qingqing and Tu, Rongcheng and Luo, Xiao and Ju, Wei and Xiao, Zhiping and Wang, Yifan and Xiao, Meng and Liu, Chenwu and Yuan, Jingyang and Zhang, Shichang and Jin, Yiqiao and Zhang, Fan and Wu, Xian and Zhao, Hanqing and Tao, Dacheng and Yu, Philip S. and Zhang, Ming},
	month = mar,
	year = {2025},
	note = {arXiv:2503.21460 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@article{ramos_review_2025,
	title = {A review of large language models and autonomous agents in chemistry},
	volume = {16},
	issn = {2041-6520, 2041-6539},
	url = {https://xlink.rsc.org/?DOI=D4SC03921A},
	doi = {10.1039/D4SC03921A},
	abstract = {This review examines the roles of large language models (LLMs) and autonomous agents in chemistry, exploring advancements in molecule design, property prediction, and synthesis automation.
          , 
            Large language models (LLMs) have emerged as powerful tools in chemistry, significantly impacting molecule design, property prediction, and synthesis optimization. This review highlights LLM capabilities in these domains and their potential to accelerate scientific discovery through automation. We also review LLM-based autonomous agents: LLMs with a broader set of tools to interact with their surrounding environment. These agents perform diverse tasks such as paper scraping, interfacing with automated laboratories, and synthesis planning. As agents are an emerging topic, we extend the scope of our review of agents beyond chemistry and discuss across any scientific domains. This review covers the recent history, current capabilities, and design of LLMs and autonomous agents, addressing specific challenges, opportunities, and future directions in chemistry. Key challenges include data quality and integration, model interpretability, and the need for standard benchmarks, while future directions point towards more sophisticated multi-modal agents and enhanced collaboration between agents and experimental methods. Due to the quick pace of this field, a repository has been built to keep track of the latest studies: https://github.com/ur-whitelab/LLMs-in-science.},
	language = {en},
	number = {6},
	urldate = {2025-05-18},
	journal = {Chemical Science},
	author = {Ramos, Mayk Caldas and Collison, Christopher J. and White, Andrew D.},
	year = {2025},
	pages = {2514--2572},
}

@misc{li_automated_2024,
	title = {Automated {Clinical} {Data} {Extraction} with {Knowledge} {Conditioned} {LLMs}},
	url = {http://arxiv.org/abs/2406.18027},
	doi = {10.48550/arXiv.2406.18027},
	abstract = {The extraction of lung lesion information from clinical and medical imaging reports is crucial for research on and clinical care of lung-related diseases. Large language models (LLMs) can be effective at interpreting unstructured text in reports, but they often hallucinate due to a lack of domain-specific knowledge, leading to reduced accuracy and posing challenges for use in clinical settings. To address this, we propose a novel framework that aligns generated internal knowledge with external knowledge through in-context learning (ICL). Our framework employs a retriever to identify relevant units of internal or external knowledge and a grader to evaluate the truthfulness and helpfulness of the retrieved internal-knowledge rules, to align and update the knowledge bases. Experiments with expert-curated test datasets demonstrate that this ICL approach can increase the F1 score for key fields (lesion size, margin and solidity) by an average of 12.9\% over existing ICL methods.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Li, Diya and Kadav, Asim and Gao, Aijing and Li, Rui and Bourgon, Richard},
	month = nov,
	year = {2024},
	note = {arXiv:2406.18027 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@misc{xue_promptcast_2023,
	title = {{PromptCast}: {A} {New} {Prompt}-based {Learning} {Paradigm} for {Time} {Series} {Forecasting}},
	shorttitle = {{PromptCast}},
	url = {http://arxiv.org/abs/2210.08964},
	doi = {10.48550/arXiv.2210.08964},
	abstract = {This paper presents a new perspective on time series forecasting. In existing time series forecasting methods, the models take a sequence of numerical values as input and yield numerical values as output. The existing SOTA models are largely based on the Transformer architecture, modified with multiple encoding mechanisms to incorporate the context and semantics around the historical data. Inspired by the successes of pre-trained language foundation models, we pose a question about whether these models can also be adapted to solve time-series forecasting. Thus, we propose a new forecasting paradigm: prompt-based time series forecasting (PromptCast). In this novel task, the numerical input and output are transformed into prompts and the forecasting task is framed in a sentence-to-sentence manner, making it possible to directly apply language models for forecasting purposes. To support and facilitate the research of this task, we also present a large-scale dataset (PISA) that includes three real-world forecasting scenarios. We evaluate different SOTA numerical-based forecasting methods and language generation models. The benchmark results with various forecasting settings demonstrate the proposed PromptCast with language generation models is a promising research direction. Additionally, in comparison to conventional numerical-based forecasting, PromptCast shows a much better generalization ability under the zero-shot setting.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Xue, Hao and Salim, Flora D.},
	month = dec,
	year = {2023},
	note = {arXiv:2210.08964 [stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Methodology, Statistics - Statistics Theory},
}

@misc{ansari_chronos_2024,
	title = {Chronos: {Learning} the {Language} of {Time} {Series}},
	shorttitle = {Chronos},
	url = {http://arxiv.org/abs/2403.07815},
	doi = {10.48550/arXiv.2403.07815},
	abstract = {We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models. Chronos tokenizes time series values using scaling and quantization into a fixed vocabulary and trains existing transformer-based language model architectures on these tokenized time series via the cross-entropy loss. We pretrained Chronos models based on the T5 family (ranging from 20M to 710M parameters) on a large collection of publicly available datasets, complemented by a synthetic dataset that we generated via Gaussian processes to improve generalization. In a comprehensive benchmark consisting of 42 datasets, and comprising both classical local models and deep learning methods, we show that Chronos models: (a) significantly outperform other methods on datasets that were part of the training corpus; and (b) have comparable and occasionally superior zero-shot performance on new datasets, relative to methods that were trained specifically on them. Our results demonstrate that Chronos models can leverage time series data from diverse domains to improve zero-shot accuracy on unseen forecasting tasks, positioning pretrained models as a viable tool to greatly simplify forecasting pipelines.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Ansari, Abdul Fatir and Stella, Lorenzo and Turkmen, Caner and Zhang, Xiyuan and Mercado, Pedro and Shen, Huibin and Shchur, Oleksandr and Rangapuram, Syama Sundar and Arango, Sebastian Pineda and Kapoor, Shubham and Zschiegner, Jasper and Maddix, Danielle C. and Wang, Hao and Mahoney, Michael W. and Torkkola, Kari and Wilson, Andrew Gordon and Bohlke-Schneider, Michael and Wang, Yuyang},
	month = nov,
	year = {2024},
	note = {arXiv:2403.07815 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{jin_time-llm_2024,
	title = {Time-{LLM}: {Time} {Series} {Forecasting} by {Reprogramming} {Large} {Language} {Models}},
	shorttitle = {Time-{LLM}},
	url = {http://arxiv.org/abs/2310.01728},
	doi = {10.48550/arXiv.2310.01728},
	abstract = {Time series forecasting holds significant importance in many real-world dynamic systems and has been extensively studied. Unlike natural language process (NLP) and computer vision (CV), where a single large model can tackle multiple tasks, models for time series forecasting are often specialized, necessitating distinct designs for different tasks and applications. While pre-trained foundation models have made impressive strides in NLP and CV, their development in time series domains has been constrained by data sparsity. Recent studies have revealed that large language models (LLMs) possess robust pattern recognition and reasoning abilities over complex sequences of tokens. However, the challenge remains in effectively aligning the modalities of time series data and natural language to leverage these capabilities. In this work, we present Time-LLM, a reprogramming framework to repurpose LLMs for general time series forecasting with the backbone language models kept intact. We begin by reprogramming the input time series with text prototypes before feeding it into the frozen LLM to align the two modalities. To augment the LLM's ability to reason with time series data, we propose Prompt-as-Prefix (PaP), which enriches the input context and directs the transformation of reprogrammed input patches. The transformed time series patches from the LLM are finally projected to obtain the forecasts. Our comprehensive evaluations demonstrate that Time-LLM is a powerful time series learner that outperforms state-of-the-art, specialized forecasting models. Moreover, Time-LLM excels in both few-shot and zero-shot learning scenarios.},
	urldate = {2025-05-18},
	publisher = {arXiv},
	author = {Jin, Ming and Wang, Shiyu and Ma, Lintao and Chu, Zhixuan and Zhang, James Y. and Shi, Xiaoming and Chen, Pin-Yu and Liang, Yuxuan and Li, Yuan-Fang and Pan, Shirui and Wen, Qingsong},
	month = jan,
	year = {2024},
	note = {arXiv:2310.01728 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{xie_chatts_2025,
	title = {{ChatTS}: {Aligning} {Time} {Series} with {LLMs} via {Synthetic} {Data} for {Enhanced} {Understanding} and {Reasoning}},
	shorttitle = {{ChatTS}},
	url = {http://arxiv.org/abs/2412.03104},
	doi = {10.48550/arXiv.2412.03104},
	abstract = {Understanding time series is crucial for its application in real-world scenarios. Recently, large language models (LLMs) have been increasingly applied to time series tasks, leveraging their strong language capabilities to enhance various applications. However, research on multimodal LLMs (MLLMs) for time series understanding and reasoning remains limited, primarily due to the scarcity of high-quality datasets that align time series with textual information. This paper introduces ChatTS, a novel MLLM designed for time series analysis. ChatTS treats time series as a modality, similar to how vision MLLMs process images, enabling it to perform both understanding and reasoning with time series. To address the scarcity of training data, we propose an attribute-based method for generating synthetic time series with detailed attribute descriptions. We further introduce Time Series Evol-Instruct, a novel approach that generates diverse time series Q\&As, enhancing the model's reasoning capabilities. To the best of our knowledge, ChatTS is the first TS-MLLM that takes multivariate time series as input for understanding and reasoning, which is fine-tuned exclusively on synthetic datasets. We evaluate its performance using benchmark datasets with real-world data, including six alignment tasks and four reasoning tasks. Our results show that ChatTS significantly outperforms existing vision-based MLLMs (e.g., GPT-4o) and text/agent-based LLMs, achieving a 46.0\% improvement in alignment tasks and a 25.8\% improvement in reasoning tasks. We have open-sourced the source code, model checkpoint and datasets at https://github.com/NetManAIOps/ChatTS.},
	urldate = {2025-05-08},
	publisher = {arXiv},
	author = {Xie, Zhe and Li, Zeyan and He, Xiao and Xu, Longlong and Wen, Xidao and Zhang, Tieying and Chen, Jianjun and Shi, Rui and Pei, Dan},
	month = apr,
	year = {2025},
	note = {arXiv:2412.03104 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@misc{ma_causal_2025,
	title = {Causal {Inference} with {Large} {Language} {Model}: {A} {Survey}},
	shorttitle = {Causal {Inference} with {Large} {Language} {Model}},
	url = {http://arxiv.org/abs/2409.09822},
	doi = {10.48550/arXiv.2409.09822},
	abstract = {Causal inference has been a pivotal challenge across diverse domains such as medicine and economics, demanding a complicated integration of human knowledge, mathematical reasoning, and data mining capabilities. Recent advancements in natural language processing (NLP), particularly with the advent of large language models (LLMs), have introduced promising opportunities for traditional causal inference tasks. This paper reviews recent progress in applying LLMs to causal inference, encompassing various tasks spanning different levels of causation. We summarize the main causal problems and approaches, and present a comparison of their evaluation results in different causal scenarios. Furthermore, we discuss key findings and outline directions for future research, underscoring the potential implications of integrating LLMs in advancing causal inference methodologies.},
	urldate = {2025-05-08},
	publisher = {arXiv},
	author = {Ma, Jing},
	month = feb,
	year = {2025},
	note = {arXiv:2409.09822 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{rajendiran_leveraging_2023,
	title = {Leveraging {Large} {Language} {Models} to {Automate} {SOP} in {Warehouses} {Managed} by {Warehouse} {Management} {Systems}},
	volume = {5},
	url = {https://doi.org/10.36948/ijfmr.2023.v05i06.5857},
	doi = {10.36948/ijfmr.2023.v05i06.5857},
	number = {6},
	journal = {International Journal For Multidisciplinary Research},
	author = {Rajendiran, Gautham Ram},
	month = nov,
	year = {2023},
}

@misc{garg_generating_2025,
	title = {Generating {Structured} {Plan} {Representation} of {Procedures} with {LLMs}},
	url = {http://arxiv.org/abs/2504.00029},
	doi = {10.48550/arXiv.2504.00029},
	abstract = {In this paper, we address the challenges of managing Standard Operating Procedures (SOPs), which often suffer from inconsistencies in language, format, and execution, leading to operational inefficiencies. Traditional process modeling demands significant manual effort, domain expertise, and familiarity with complex languages like Business Process Modeling Notation (BPMN), creating barriers for non-techincal users. We introduce SOP Structuring (SOPStruct), a novel approach that leverages Large Language Models (LLMs) to transform SOPs into decision-tree-based structured representations. SOPStruct produces a standardized representation of SOPs across different domains, reduces cognitive load, and improves user comprehension by effectively capturing task dependencies and ensuring sequential integrity. Our approach enables leveraging the structured information to automate workflows as well as empower the human users. By organizing procedures into logical graphs, SOPStruct facilitates backtracking and error correction, offering a scalable solution for process optimization. We employ a novel evaluation framework, combining deterministic methods with the Planning Domain Definition Language (PDDL) to verify graph soundness, and non-deterministic assessment by an LLM to ensure completeness. We empirically validate the robustness of our LLM-based structured SOP representation methodology across SOPs from different domains and varying levels of complexity. Despite the current lack of automation readiness in many organizations, our research highlights the transformative potential of LLMs to streamline process modeling, paving the way for future advancements in automated procedure optimization.},
	urldate = {2025-05-08},
	publisher = {arXiv},
	author = {Garg, Deepeka and Zeng, Sihan and Ganesh, Sumitra and Ardon, Leo},
	month = mar,
	year = {2025},
	note = {arXiv:2504.00029 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Software Engineering},
}

@misc{kumar_llm-powered_2025,
	title = {{LLM}-{Powered} {Knowledge} {Graphs} for {Enterprise} {Intelligence} and {Analytics}},
	url = {http://arxiv.org/abs/2503.07993},
	doi = {10.48550/arXiv.2503.07993},
	abstract = {Disconnected data silos within enterprises obstruct the extraction of actionable insights, diminishing efficiency in areas such as product development, client engagement, meeting preparation, and analytics-driven decision-making. This paper introduces a framework that uses large language models (LLMs) to unify various data sources into a comprehensive, activity-centric knowledge graph. The framework automates tasks such as entity extraction, relationship inference, and semantic enrichment, enabling advanced querying, reasoning, and analytics across data types like emails, calendars, chats, documents, and logs. Designed for enterprise flexibility, it supports applications such as contextual search, task prioritization, expertise discovery, personalized recommendations, and advanced analytics to identify trends and actionable insights. Experimental results demonstrate its success in the discovery of expertise, task management, and data-driven decision making. By integrating LLMs with knowledge graphs, this solution bridges disconnected systems and delivers intelligent analytics-powered enterprise tools.},
	urldate = {2025-05-08},
	publisher = {arXiv},
	author = {Kumar, Rajeev and Ishan, Kumar and Kumar, Harishankar and Singla, Abhinandan},
	month = mar,
	year = {2025},
	note = {arXiv:2503.07993 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
}

@misc{noauthor_fine-tuning_nodate,
	title = {Fine-{Tuning} {1B} {LLaMA} 3.2: {A} {Comprehensive} {Step}-by-{Step} {Guide} with {Code}},
	url = {[https://huggingface.co/blog/ImranzamanML/fine-tuning-1b-llama-32-a-comprehensive-article](https://huggingface.co/blog/ImranzamanML/fine-tuning-1b-llama-32-a-comprehensive-article#:~:text=We%20are%20going%20to%20use,up%20both%20training%20and%20inference)},
}

@misc{noauthor_fine-tuning_nodate-1,
	title = {Fine-tuning},
	url = {https://huggingface.co/docs/transformers/en/training},
	urldate = {2025-05-07},
}

@misc{song_injecting_2025,
	title = {Injecting {Domain}-{Specific} {Knowledge} into {Large} {Language} {Models}: {A} {Comprehensive} {Survey}},
	shorttitle = {Injecting {Domain}-{Specific} {Knowledge} into {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2502.10708},
	doi = {10.48550/arXiv.2502.10708},
	abstract = {Large Language Models (LLMs) have demonstrated remarkable success in various tasks such as natural language understanding, text summarization, and machine translation. However, their general-purpose nature often limits their effectiveness in domain-specific applications that require specialized knowledge, such as healthcare, chemistry, or legal analysis. To address this, researchers have explored diverse methods to enhance LLMs by integrating domain-specific knowledge. In this survey, we provide a comprehensive overview of these methods, which we categorize into four key approaches: dynamic knowledge injection, static knowledge embedding, modular adapters, and prompt optimization. Each approach offers unique mechanisms to equip LLMs with domain expertise, balancing trade-offs between flexibility, scalability, and efficiency. We discuss how these methods enable LLMs to tackle specialized tasks, compare their advantages and disadvantages, evaluate domain-specific LLMs against general LLMs, and highlight the challenges and opportunities in this emerging field. For those interested in delving deeper into this area, we also summarize the commonly used datasets and benchmarks. To keep researchers updated on the latest studies, we maintain an open-source at: https://github.com/abilliyb/Knowledge\_Injection\_Survey\_Papers, dedicated to documenting research in the field of specialized LLM.},
	urldate = {2025-05-07},
	publisher = {arXiv},
	author = {Song, Zirui and Yan, Bin and Liu, Yuhan and Fang, Miao and Li, Mingzhe and Yan, Rui and Chen, Xiuying},
	month = feb,
	year = {2025},
	note = {arXiv:2502.10708 [cs]},
	keywords = {Computer Science - Computation and Language},
}

@inproceedings{ovadia_fine-tuning_2024,
	address = {Miami, Florida, USA},
	title = {Fine-{Tuning} or {Retrieval}? {Comparing} {Knowledge} {Injection} in {LLMs}},
	shorttitle = {Fine-{Tuning} or {Retrieval}?},
	url = {https://aclanthology.org/2024.emnlp-main.15},
	doi = {10.18653/v1/2024.emnlp-main.15},
	language = {en},
	urldate = {2025-05-07},
	booktitle = {Proceedings of the 2024 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	publisher = {Association for Computational Linguistics},
	author = {Ovadia, Oded and Brief, Menachem and Mishaeli, Moshik and Elisha, Oren},
	year = {2024},
	pages = {237--250},
}

@article{zhang_domain-specific_2025,
	title = {Domain-specific large language models for fault diagnosis of heating, ventilation, and air conditioning systems by labeled-data-supervised fine-tuning},
	volume = {377},
	issn = {03062619},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306261924017616},
	doi = {10.1016/j.apenergy.2024.124378},
	language = {en},
	urldate = {2025-05-07},
	journal = {Applied Energy},
	author = {Zhang, Jian and Zhang, Chaobo and Lu, Jie and Zhao, Yang},
	month = jan,
	year = {2025},
	pages = {124378},
}

@misc{xiao_llm-named_2024,
	title = {{LLM}-{DER}:{A} {Named} {Entity} {Recognition} {Method} {Based} on {Large} {Language} {Models} for {Chinese} {Coal} {Chemical} {Domain}},
	shorttitle = {{LLM}-{DER}},
	url = {http://arxiv.org/abs/2409.10077},
	doi = {10.48550/arXiv.2409.10077},
	abstract = {Domain-specific Named Entity Recognition (NER), whose goal is to recognize domain-specific entities and their categories, provides an important support for constructing domain knowledge graphs. Currently, deep learning-based methods are widely used and effective in NER tasks, but due to the reliance on large-scale labeled data. As a result, the scarcity of labeled data in a specific domain will limit its application.Therefore, many researches started to introduce few-shot methods and achieved some results. However, the entity structures in specific domains are often complex, and the current few-shot methods are difficult to adapt to NER tasks with complex features.Taking the Chinese coal chemical industry domain as an example,there exists a complex structure of multiple entities sharing a single entity, as well as multiple relationships for the same pair of entities, which affects the NER task under the sample less condition.In this paper, we propose a Large Language Models (LLMs)-based entity recognition framework LLM-DER for the domain-specific entity recognition problem in Chinese, which enriches the entity information by generating a list of relationships containing entity types through LLMs, and designing a plausibility and consistency evaluation method to remove misrecognized entities, which can effectively solve the complex structural entity recognition problem in a specific domain.The experimental results of this paper on the Resume dataset and the self-constructed coal chemical dataset Coal show that LLM-DER performs outstandingly in domain-specific entity recognition, not only outperforming the existing GPT-3.5-turbo baseline, but also exceeding the fully-supervised baseline, verifying its effectiveness in entity recognition.},
	urldate = {2025-05-07},
	publisher = {arXiv},
	author = {Xiao, Le and Xu, Yunfei and Zhao, Jing},
	month = sep,
	year = {2024},
	note = {arXiv:2409.10077 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}

@article{dagdelen_structured_2024,
	title = {Structured information extraction from scientific text with large language models},
	volume = {15},
	copyright = {2024 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-024-45563-x},
	doi = {10.1038/s41467-024-45563-x},
	abstract = {Extracting structured knowledge from scientific text remains a challenging task for machine learning models. Here, we present a simple approach to joint named entity recognition and relation extraction and demonstrate how pretrained large language models (GPT-3, Llama-2) can be fine-tuned to extract useful records of complex scientific knowledge. We test three representative tasks in materials chemistry: linking dopants and host materials, cataloging metal-organic frameworks, and general composition/phase/morphology/application information extraction. Records are extracted from single sentences or entire paragraphs, and the output can be returned as simple English sentences or a more structured format such as a list of JSON objects. This approach represents a simple, accessible, and highly flexible route to obtaining large databases of structured specialized scientific knowledge extracted from research papers.},
	language = {en},
	number = {1},
	urldate = {2025-05-07},
	journal = {Nature Communications},
	author = {Dagdelen, John and Dunn, Alexander and Lee, Sanghoon and Walker, Nicholas and Rosen, Andrew S. and Ceder, Gerbrand and Persson, Kristin A. and Jain, Anubhav},
	month = feb,
	year = {2024},
	keywords = {Databases, Materials science, Scientific data, Theory and computation},
	pages = {1418},
}

@article{zhang_fine-tuning_2024,
	title = {Fine-tuning large language models for chemical text mining},
	volume = {15},
	url = {https://pubs.rsc.org/en/content/articlelanding/2024/sc/d4sc00924j},
	doi = {10.1039/D4SC00924J},
	language = {en},
	number = {27},
	urldate = {2025-05-07},
	journal = {Chemical Science},
	author = {Zhang, Wei and Wang, Qinggong and Kong, Xiangtai and Xiong, Jiacheng and Ni, Shengkun and Cao, Duanhua and Niu, Buying and Chen, Mingan and Li, Yameng and Zhang, Runze and Wang, Yitian and Zhang, Lehan and Li, Xutong and Xiong, Zhaoping and Shi, Qian and Huang, Ziming and Fu, Zunyun and Zheng, Mingyue},
	year = {2024},
	pages = {10600--10611},
}

@article{lu_fine-tuning_2025,
	title = {Fine-tuning large language models for domain adaptation: exploration of training strategies, scaling, model merging and synergistic capabilities},
	volume = {11},
	copyright = {2025 The Author(s)},
	issn = {2057-3960},
	shorttitle = {Fine-tuning large language models for domain adaptation},
	url = {https://www.nature.com/articles/s41524-025-01564-y},
	doi = {10.1038/s41524-025-01564-y},
	abstract = {The advancement of Large Language Models (LLMs) for domain applications in fields such as materials science and engineering depends on the development of fine-tuning strategies that adapt models for specialized, technical capabilities. In this work, we explore the effects of Continued Pretraining (CPT), Supervised Fine-Tuning (SFT), and various preference-based optimization approaches, including Direct Preference Optimization (DPO) and Odds Ratio Preference Optimization (ORPO), on fine-tuned LLM performance. Our analysis shows how these strategies influence model outcomes and reveals that the merging of multiple fine-tuned models can lead to the emergence of capabilities that surpass the individual contributions of the parent models. We find that model merging is not merely a process of aggregation, but a transformative method that can drive substantial advancements in model capabilities characterized by highly nonlinear interactions between model parameters, resulting in new functionalities that neither parent model could achieve alone, leading to improved performance in domain-specific assessments. We study critical factors that influence the success of model merging, such as the diversity between parent models and the fine-tuning techniques employed. The insights underscore the potential of strategic model merging to unlock novel capabilities in LLMs, offering an effective tool for advancing AI systems to meet complex challenges. Experiments with different model architectures are presented, including the Llama 3.1 8B and Mistral 7B family of models, where similar behaviors are observed. Exploring whether the results hold also for much smaller models, we use a tiny LLM with 1.7 billion parameters and show that very small LLMs do not necessarily feature emergent capabilities under model merging, suggesting that model scaling may be a key component. In open-ended yet consistent chat conversations between a human and AI models, our assessment reveals detailed insights into how different model variants perform, and shows that the smallest model achieves a high intelligence score across key criteria including reasoning depth, creativity, clarity, and quantitative precision. Other experiments include the development of image generation prompts that seek to reason over disparate biological material design concepts, to create new microstructures, architectural concepts, and urban design based on biological materials-inspired construction principles. We conclude with a series of questions about scaling and emergence that could be addressed in future research.},
	language = {en},
	number = {1},
	urldate = {2025-05-07},
	journal = {npj Computational Materials},
	author = {Lu, Wei and Luu, Rachel K. and Buehler, Markus J.},
	month = mar,
	year = {2025},
	keywords = {Computational methods, Engineering, Materials science, Theory and computation},
	pages = {1--43},
}
