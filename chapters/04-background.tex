% =============================================================================
% CHAPTER 2: BACKGROUND AND STATE OF THE ART
% =============================================================================

\chapter{Background and State of the Art}\label{background-and-state-of-the-art}

This chapter reviews the existing literature relevant to the automated generation of process safety rules. It begins by examining the limitations of current data-driven anomaly detection in safety-critical environments (\cref{anomaly-detection-in-industrial-processes}). Subsequently, it analyzes the evolution of Information Extraction (IE) techniques, from traditional Natural Language Processing (NLP) to modern Procedural Text Mining (\cref{knowledge-extraction-ie}). Finally, it discusses the recent paradigm shift introduced by Large Language Models (LLMs), focusing on their ability to interpret engineering documentation and generate executable logic (\cref{llm-based-rule-generation}), and the critical challenges of trust and verification (\cref{sec:trust}).

\section{Anomaly Detection in Industrial Processes}\label{anomaly-detection-in-industrial-processes}

Anomaly detection (AD) in industrial control systems (ICS) is the process of identifying operational states that deviate from expected behavior. Approaches are generally categorized into \textit{data-driven} and \textit{knowledge-driven} methods.

\subsection{Data-Driven Approaches and the ``Zero-Shot'' Problem}

Data-driven methods, particularly those based on Machine Learning (ML) and Deep Learning (DL), currently dominate the state of the art. Techniques such as Autoencoders (AE), Long Short-Term Memory (LSTM) networks, and Generative Adversarial Networks (GANs) have shown significant success in predictive maintenance by learning representations of "normal" operation from historical sensor data \cite{li_zero-shot_2023, li_musc_2024}.

However, these approaches suffer from critical limitations when applied to process safety management in highly regulated industries:

\begin{enumerate} \item \textbf{The Cold Start \& Zero-Shot Problem:} Data-driven models typically require massive datasets containing labeled instances of failure to learn effectively. In high-reliability organizations (e.g., nuclear, oil \& gas), critical failures are essentially rare events. As noted by Li et al. \cite{li_zero-shot_2023}, safe plants face a ``zero-shot'' reality where algorithms must detect failure modes they have never seen before. \item \textbf{Lack of Interpretability:} Deep learning models often function as "black boxes." In safety-critical contexts, an operator must know \textit{why} an alarm was triggered (e.g., \textit{"Pressure implies tank rupture risk"}) rather than just a statistical deviation score. \end{enumerate}

\subsection{Knowledge-Driven (Rule-Based) Approaches} In contrast, knowledge-driven approaches rely on explicit rules derived from engineering principles (e.g., \textit{If Pressure > 10 bar, Then Alarm}). These systems offer high explainability and do not require training data. However, they face the Knowledge Acquisition Bottleneck: defining these rules is a manual, labor-intensive process dependent on scarce domain experts \cite{wagner_knowledge_2002}.

\textbf{Research Gap:} There is currently a lack of automated frameworks capable of generating these explicit rules without manual intervention, effectively leaving a gap between the scalability of ML and the reliability of rule-based systems.

\section{Knowledge Extraction from Industrial Text}\label{knowledge-extraction-ie}

To automate rule generation, operational knowledge must be extracted from technical documentation (Standard Operating Procedures, P\&IDs,\footnote{P\&IDs: Piping \& Instrumentation Diagrams} Manuals). This falls under the domain of Information Extraction (IE).

\subsection{Traditional NLP: Fact vs. Logic Extraction} Traditional IE techniques utilizing Named Entity Recognition (NER) and regular expressions have proven effective for extracting \textit{static facts} (e.g., extracting parameter values like "100 psi" or standard codes like "ISO-9001") from industrial specifications \cite{magnini_understanding_2024,tufek_semantic_2023}.

However, these methods struggle with \textit{procedural logic}. Industrial rules often involve complex conditional dependencies (nested \textit{if-then-else} structures) and temporal constraints (e.g., \textit{"Open valve A only after pump B has run for 10 minutes"}). Traditional pipeline-based NLP (e.g., spaCy chains) often fails to capture the long-range dependencies and implicit causal links required to form executable logic \cite{rula_procedural_2023}.

\subsection{Procedural Text Mining} Recent work in "Procedural Text Mining" attempts to address this by modeling documents as graphs of actions and states. While promising, existing systems often require rigid ontologies or extensive annotation to distinguish between descriptive text and prescriptive instructions \cite{rula_procedural_2023}. They rarely output executable code directly, stopping short at structured text representations.




\section{LLM-based Rule Generation}\label{llm-based-rule-generation}

The emergence of Large Language Models (LLMs) has fundamentally shifted the capabilities of automated rule generation. Unlike traditional NLP, LLMs demonstrate reasoning capabilities that allow them to infer implicit constraints and generate syntactically correct code.

\subsection{Role and Capabilities of LLMs in Industry}

Current research explores using LLMs to interpret complex engineering information—such as functional descriptions and Piping and Instrumentation Diagrams (P\&IDs)—and translate it into actionable rules for condition monitoring.

Prior research has identified key properties that make LLMs particularly suitable for this application:

\begin{itemize} \item \textbf{Versatile reasoning and generalization:} LLMs can infer physical relationships from system descriptions and adapt to various industrial control applications, unlike traditional machine learning models. Frameworks like INVARLLM \cite{abshari_llm-assisted_2024} leverage LLMs to automatically extract invariants from Cyber-Physical Systems' (CPS) deployment documentation. These invariants are consistent physical or logical relationships that capture procedural logic not easily discoverable from data alone. Furthermore, LLMs can generalize to new scenarios with minimal examples \cite{song_pre-trained_2023}. \item \textbf{Contextual understanding:} LLMs can process large amounts of unstructured data (maintenance logs, technical manuals) and scientific text \cite{dagdelen_structured_2024, xia_enhance_2024}. This allows them to identify subtle patterns and correlations that purely numerical models might overlook. \item \textbf{Code generation:} Beyond text, LLMs can translate natural language descriptions into executable code, including PLC (Programmable Logic Controller) code \cite{fakih_llm4plc_2024} and logical monitoring rules. \item \textbf{Automation and control:} These models can interpret user tasks in natural language to generate production plans or perform operations on physical systems, making industrial automation more flexible \cite{xia_control_2024}. \end{itemize}

\subsection{Information Extraction and Symbol Grounding}

A critical challenge in this domain is the "Symbol Grounding Problem": bridging the gap between natural language descriptions and the cryptic sensor tags found in control systems.

LLMs have shown success in extracting structured information from scientific literature, such as chemistry papers, and formatting it into structured JSON objects \cite{dagdelen_structured_2024}. More specifically to the industrial domain, recent work has applied LLMs to interpret P\&IDs, combining semantic information with image recognition to "read" the diagrams \cite{alimin_talking_2025}. This capability is essential for mapping a generic term like "Reflux Pump" to a specific tag like \texttt{P-101A}.

\subsection{From Text to Logic: Code-as-Policy}

While extraction is useful, the ultimate goal is executable logic. A pivotal development here is the concept of "Code-as-Policy" (CaP), introduced by Liang et al. \cite{liang_code_2023}. Originally developed for robotics, CaP treats LLMs as reasoning engines that map natural language instructions directly to executable control policies (Python code).

In the industrial context, this approach allows for the direct translation of safety constraints (e.g., \textit{"Shut down if temperature > 200"}) into monitoring code, bypassing intermediate formal representations. However, research specifically focusing on generating safety rules from documentation remains scarce compared to general code generation.

\subsection{LLMs for Time-Series Anomaly Detection}

It is worth noting that LLMs are also being applied directly to the sensor data itself. Recent studies show LLMs can be used for anomaly detection in time series \cite{russell-gilbert_aad-llm_2024, russell-gilbert_raad-llm_2025, ansari_chronos_2024}, improving upon classical algorithms by incorporating domain knowledge. While these methods are powerful, they focus on signal analysis rather than the definition of explicit engineering rules.

\section{Trust and Reliability}\label{sec:trust}

Ensuring the reliability and trustworthiness of LLM outputs is critical, especially in sensitive or high-stakes applications like process safety.

\subsection{Evaluation Frameworks} The ``gold standard'' for assessing LLM performance is considered to be human evaluation, as it provides a comprehensive benchmark that automated metrics might miss. Frameworks like HumanELY \cite{awasthi_humanely_2023} propose structured approaches with metrics like relevance, coverage, coherence, and harm to provide consistent evaluations.

In industrial settings, an emerging approach for verification is the use of \emph{digital twins}. By deploying generated rules into a simulated environment \cite{gill_leveraging_2025}, their behavior can be validated safely before implementation in the real plant.

\subsection{Explainability and Confidence} To increase trust, we must understand \emph{how} LLMs arrive at their decisions: \begin{itemize} \item \textbf{Language-Based Explanations (LBEs):} These leverage the LLM's NLP capabilities to translate decision-making into text, increasing transparency \cite{brown_enhancing_2024}. \item \textbf{Chain-of-Thought (CoT):} Prompting methods that encourage LLMs to show their work'' by generating intermediate reasoning steps have been shown to enhance both explainability and reliability. \item \textbf{Confidence Elicitation:} Frameworks like SteerConf \cite{zhou_steerconf_2025} allow for calibrating the model's responses by steering'' confidence scores (e.g., requesting a "very cautious" output). Consistency in confidence scores across different steering levels indicates higher certainty. \end{itemize}

\section{Positioning of this Work}

\Cref{tab:sota-comparison} summarizes the positioning of this thesis within the current landscape. While data-driven methods lack safety guarantees and traditional IE lacks logical depth, this work proposes a neuro-symbolic approach: leveraging the reasoning of LLMs (Code-as-Policy) grounded in industrial documentation to automate the generation of explicit, verifiable rules.



\begin{table}[h]
    \centering
    \begin{tabular}{l l l l}
        \toprule
        \textbf{Approach} & \textbf{Data requirement} & \textbf{Explainability} & \textbf{Scalability} \\
        \midrule
        Data-Driven (ML) & High & Low & Mid \\
        & (needs failure data) & (black box) & (generalization issues) \\[6pt]
        Manual Rule Definition & None & High & Low \\
        & & & (expert bottleneck) \\[6pt]
        \textbf{LLM Rule Extraction} & \textbf{None} & \textbf{High} & \textbf{High} \\
        & \textbf{(zero-shot)} & \textbf{(code/text)} & \textbf{(automated)} \\
        \bottomrule
    \end{tabular}
    \footnotesize
    \caption{Comparison of Approaches for Industrial Anomaly Management}
    \label{tab:sota-comparison}
\end{table}

