% =============================================================================
% CHAPTER 2: METHODOLOGY
% =============================================================================

\chapter{Methodology}\label{methodology}

This chapter details the methodological framework adopted for the development of this thesis. We follow a \textbf{hybrid, iterative methodology}. It combines \textbf{agile research practices} for the probabilistic components (LLM-based extraction) with \textbf{rigorous software engineering standards} for the deterministic components (streaming runtime), as well as the implementation. This distinction is necessary because the two subsystems operate under fundamentally different paradigms: one requires exploration and hypothesis testing to manage uncertainty, while the other requires optimization and strict type safety to ensure reliability.

\section{Methodological Approach: The Iterative Cycle}\label{sec:iterative-cycle}

The core of our methodology, particularly for the Rule Extraction engine, is an iterative \textit{``hypothesis -implementation - evaluation''} cycle. Unlike a linear ``waterfall'' approach where requirements are fixed, this project treats the capabilities of the LLM as a variable to be investigated.

The methodological process consists of repeated iterations of the following steps:
\begin{enumerate}
    \item \textbf{Baseline Implementation:} Establishing a naive solution (e.g., standard ``zero-shot'' prompting).
    \item \textbf{Qualitative Failure Analysis:} Testing against real industrial documentation to identify specific failure types (e.g., hallucination, loss of context).
    \item \textbf{Research-Driven Hypothesis:} Formulating a solution based on current literature (e.g., ``Chain of Thought will improve reasoning,'' ``grammar-constrained decoding will ensure valid output schema'').
    \item \textbf{Refinement and System Evolution:} Implementing the hypothesis and fundamentally altering the system architecture if successful.
\end{enumerate}

This cycle ensures that the final system is not just a collection of features, but a derived solution to specific, observed problems in applying LLMs to the industrial domain.

\section{Phases of Development}

The methodological work is structured into four distinct phases, executed sequentially but with internal iterative loops.

\subsection*{Phase 1: State of the Art and Feasibility Analysis}
The initial phase focused on a comprehensive review of existing approaches to industrial event detection. We analyzed traditional methods (expert systems, statistical anomaly detection) to identify their limitations. This phase is detailed in \Cref{background-and-state-of-the-art}.
\begin{description}
    \item[Objective:] Determine if LLMs possess the necessary semantic understanding to parse unstructured technical specifications.
    \item[Methodology:] Comparative analysis of traditional methods (expert systems, statistical anomaly) versus State of the Art LLM capabilities.
    \item[Outcome:] Validation of the LLM approach and definition of the system architecture.
\end{description}

\subsection*{Phase 2: Iterative Design of the Rule Extractor}
This phase represents the bulk of the investigative work. Following the iterative methodology described above, we evolved the system from a simple script into a multi-stage agentic pipeline. The findings of this phase are detailed in \Cref{ch:5-solution-design-and-implementation}.
\begin{description}
    \item[Objective:] Establish a robust mechanism to extract deterministic rules from non-deterministic natural language.
    \item[Methodology:] \textbf{Iterative cycles} (\Cref{sec:iterative-cycle}) using \textbf{actual Repsol technical documentation}. Each iteration addressed a specific limitation (e.g., hallucination) via a hypothesis-test cycle.
    \item[Outcome:] A certain architecture for rule extraction.
\end{description}

\subsection*{Phase 3: Engineering the Streaming Runtime}
In contrast to the research-heavy extraction phase, the development of the runtime engine followed a \textbf{pure engineering methodology}. This phase is laid out in \Cref{ch:6-operational-runtime-dynamic-verification}.
\begin{description}
    \item[Objective:] Create a high-performance execution environment for the extracted rules.
    \item[Methodology:] \textbf{Test-Driven Development (TDD)} and strict performance profiling, prioritizing time complexity and memory safety.
    \item[Outcome:] A fault-tolerant, streaming-native runtime engine backed by the River library.
\end{description}

\subsection*{Phase 4: Synthetic Evaluation Strategy}
Due to the unavailability of labeled historical anomaly logs (a common constraint in industrial projects), we developed a \textbf{synthetic evaluation methodology}. More details in \Cref{evaluation-and-results}.
\begin{description}
    \item[Objective:] Validate the correctness of extraction and the latency of execution without ground-truth plant data.
    \item[Methodology:] \textbf{Synthetic generation} for rule extraction validation.
    \item[Outcome:] Quantitative metrics for extraction precision/recall and runtime detection accuracy.
\end{description}

\section{Temporal Planning}

The development of this Master's Thesis was planned over a period of approximately 6 months, designed to meet the workload requirements of approx. 300-450 hours. The time distribution specified in \Cref{tab:temporal-planning} reflects the high uncertainty and complexity of the LLM research components. 

\begin{table}[h]
    \centering
    \begin{tabular}{l l c c }
        \toprule
        \textbf{Phase} & \textbf{Description} & \textbf{Est. Hours} & \textbf{\%} \\ \midrule
        Phase 1 & State of the Art \& Feasibility Study & 50 h & 14\% \\
        Phase 2 & Rule Extractor Dev. (Research \& Iteration) & 140 h & 39\% \\
        Phase 3 & Runtime Engine Dev. (Engineering) & 70 h & 19\% \\
        Phase 4 & Synthetic Evaluation \& Testing & 50 h & 14\% \\
        Phase 5 & Documentation \& Thesis Writing & 50 h & 14\% \\ \midrule
        \multicolumn{2}{r}{\textbf{Total}} & \textbf{360 h} & \textbf{100\%} \\ \bottomrule
    \end{tabular}
    \caption{Estimated apportionment of work hours per project phase}
    \label{tab:temporal-planning}
\end{table}

\section{Budget and Economic Estimation}

The economic analysis considers the cost of development as if it were a professional engineering project. The budget is primarily driven by personnel costs (Engineering hours) and operational costs (LLM tokens).

\begin{table}[h]
    \centering
    \begin{tabular}{l c c c}
        \toprule
        \textbf{Concept} & \textbf{Quantity} & \textbf{Unit Cost} & \textbf{Total} \\ \midrule
        \multicolumn{4}{l}{\textbf{Personnel}} \\
        AI Engineer & 360 hours & 25.00 €/h & 9,000.00 € \\ \midrule
        \multicolumn{4}{l}{\textbf{Materials \& Services}} \\
        LLM calls via Ollama & - & 0.00 € & 0.00 € \\
        Tavily (free tier) & 6000 credits & 0.00 € & 0.00 € \\
        \midrule
        \textbf{Total Estimated Budget} & & & \textbf{9,000.00 €} \\ \bottomrule
    \end{tabular}
    \caption{Budgetary estimation for the project development.}
    \label{tab:budget}
\end{table}

This budget assumes the mean salary of an AI Engineer in Spain (25€/hour). API costs represent the actual consumption during the iterative testing and evaluation phases. The abscence of material cost highlights the accessibility of modern AI research, where the primary investment is intellectual capital rather than physical infrastructure.
